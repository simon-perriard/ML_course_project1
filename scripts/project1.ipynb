{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data according to the value of column 24 (PRI_jet_num) \n",
    "\n",
    "def separate(y, tX, ids):\n",
    "    \n",
    "    split_x = []\n",
    "    split_y = []\n",
    "    split_ids = []\n",
    "    \n",
    "    jet_column_nbr = 22\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        split_x.append(tX[np.where(tX[:,jet_column_nbr] == i)])\n",
    "        split_y.append(y[np.where(tX[:,jet_column_nbr] == i)])\n",
    "        split_ids.append(ids[np.where(tX[:,jet_column_nbr] == i)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return split_x, split_y, split_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_x, split_y, split_ids = separate(y, tX, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the columns from each set of data given a boolean array\n",
    "\n",
    "def removeNone(data, selection):\n",
    "   \n",
    "    cleaned=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        curr_data = data[i]\n",
    "        \n",
    "        cleaned.append(curr_data[:,selection[i]])\n",
    "      \n",
    "    return cleaned\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print statistics about the None values (-999) for each columns\n",
    "#returns a boolean array that can be used to filter the columns that have 100% of undefined values (-999)\n",
    "def dataStatistics(data):\n",
    "    \n",
    "    stats=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        print(\"Statistics \")\n",
    "        print(\"Type :\")\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "        nones = (data[i] == -999)\n",
    "    \n",
    "        mean = np.sum(nones, axis=0)/nones.shape[0]\n",
    "        print(mean) \n",
    "        stats.append(mean != 1)\n",
    "    \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics \n",
      "Type :\n",
      "0\n",
      "[0.26145747 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 1.         1.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "1\n",
      "[0.09751883 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "2\n",
      "[0.05859584 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "3\n",
      "[0.0666396 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "selection = dataStatistics(split_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = removeNone(split_x, selection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can either drop the lines with residual Nones or replace the Nones by the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the value of column 0 (can be None sometimes) by the median value of this column\n",
    "\n",
    "def putMedianInsteadOfNone(cleaned):\n",
    "    \n",
    "    completed_data = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        #current PRI_jet_num\n",
    "        current = cleaned[i]\n",
    "        \n",
    "        median = np.median(current[np.where(current[:,0] != -999)], axis = 0)\n",
    "        \n",
    "        #replace -999 by median value\n",
    "        current[np.where(current[:,0] == -999)] = median\n",
    "        \n",
    "        completed_data.append(current)\n",
    "    \n",
    "    \n",
    "    return completed_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_with_median = putMedianInsteadOfNone(cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of putting the median we can simply drop the data where columns 0 == -999\n",
    "def dropLineIfNone(cleaned, split_y, split_ids):\n",
    "    \n",
    "    res_x=[]\n",
    "    res_y=[]\n",
    "    res_ids=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        current = cleaned[i]\n",
    "        \n",
    "        drop_indexes = np.where(current[:,0] != -999)\n",
    "        \n",
    "        res_x.append(current[drop_indexes])\n",
    "        res_y.append(current[drop_indexes])\n",
    "        res_ids.append(current[drop_indexes])\n",
    "        \n",
    "    return res_x, res_y, res_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropped_x, dropped_y, dropped_ids = dropLineIfNone(cleaned, split_y, split_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point, the first values in each of the split data has a PRI_jet_num = 0, then 1 and so on. The data is clean and we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(cleaned_with_median[0].shape[1])\n",
    "median_cleaned_x_0_lsq_GD = least_squares_GD(split_y[0], normalize(cleaned_with_median[0]), initial_w, 500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.2155689 , -0.53554557, -0.40401874,  0.03959931,  0.08147027,\n",
      "        0.03959934,  0.16148251,  0.03462872,  0.10957412,  0.5842968 ,\n",
      "        0.05218412,  0.04930115, -0.04715568,  0.05726908,  0.0508691 ,\n",
      "       -0.07238437,  0.03803752, -0.00064042,  0.05024209,  0.05024209]), 0.29714565802617193)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_lsq_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cleaned_x_0_lsq_SGD = least_squares_SGD(split_y[0], normalize(cleaned_with_median[0]), initial_w, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.03415192, -0.10838841, -0.02479375,  0.022209  ,  0.02761712,\n",
      "        0.022209  , -0.01267088,  0.02689357,  0.0322059 ,  0.0434371 ,\n",
      "        0.02972195,  0.03074625, -0.02174099,  0.03006534,  0.02920467,\n",
      "       -0.01581236,  0.03042716, -0.05358197,  0.02996181,  0.02996181]), 0.36323275355184187)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_lsq_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cleaned_x_0_lsq = least_squares(split_y[0], normalize(cleaned_with_median[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1.19348795e-01, -3.20910721e-01, -7.11010650e-01, -3.62337265e+03,\n",
      "        2.92434116e+01,  3.62345882e+03, -7.97192057e+00, -1.48451089e+01,\n",
      "       -9.21399478e-01,  8.74154019e+00,  1.22203119e-02,  9.00427055e-03,\n",
      "        8.51383345e+00,  1.42330453e-01,  1.82845411e-02, -8.31033254e-02,\n",
      "       -1.72379530e-01,  3.24837923e-02, -9.72705128e+00, -9.72705128e+00]), 0.2599109628358987)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_lsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cleaned_x_0_ridge = ridge_regression(split_y[0], normalize(cleaned_with_median[0]), 0.037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'median_cleaned_x_0_ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-a0c155227344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedian_cleaned_x_0_ridge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'median_cleaned_x_0_ridge' is not defined"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-0aec7208057b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmedian_cleaned_x_0_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_with_median\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic_regression' is not defined"
     ]
    }
   ],
   "source": [
    "median_cleaned_x_0_log = logistic_regression(split_y[0], normalize(cleaned_with_median[0]), initial_w, 10000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(median_cleaned_x_0_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to split the training set into a (new) training set and a test set (same as in lab03)\n",
    "\n",
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    " \n",
    "    # split the data based on the given ratio\n",
    "\n",
    "    training_nbr = int(x.shape[0] * ratio)\n",
    "    indexes = np.random.choice(x.shape[0],training_nbr, replace=False)\n",
    "    \n",
    "    x_train = x[indexes]\n",
    "    y_train = y[indexes]\n",
    "    x_test = np.delete(x, indexes, axis = 0)\n",
    "    y_test = np.delete(y, indexes, axis = 0)\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross-validation \n",
    "\n",
    "def crossValidation(x, y, splitRatio, seed =1):\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = split_data(x, y, splitRatio, seed)\n",
    "    \n",
    "    a_training = []\n",
    "    a_testing = []\n",
    "    weights = []\n",
    "    \n",
    "    #normalize data (DANGER: the test set must be normalized with the training set's mean and std)\n",
    "    mean = np.mean(x_train)\n",
    "    std = np.std(x_train)\n",
    "    \n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "    \n",
    "    # define parameter (just add more for loops if there are more parameters for the model)\n",
    "    lambdas = np.arange(0,0.03,0.0001)\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        \n",
    "        #train model with these parameters and compute the error (MSE or RMSE)\n",
    "        \n",
    "        #ideal : lambdas = np.arange(0,0.03,0.0001)\n",
    "        w_star, e_tr = ridge_regression(y_train,x_train, lambda_)\n",
    "        \n",
    "        #ideal : lambdas = np.arange(0,0.3,0.1)\n",
    "        #w_star, e_tr = logistic_regression(y_train, x_train,np.ones(x_train.shape[1])  ,400, lambda_)\n",
    "        \n",
    "        #don't usel least squares with lambda bigger than 0.35 ideal: lambdas = np.arange(0.001,0.13,0.01)\n",
    "        #w_star, e_tr = least_squares_GD(y_train, x_train,np.ones(x_train.shape[1])  ,400, lambda_)    \n",
    "        #w_star, e_tr = least_squares_SGD(y_train, x_train,np.ones(x_train.shape[1])  ,400, lambda_)\n",
    "        \n",
    "        #DON'T REALLY NEED TO DO CROSS VALIDATION FOR THIS ONE ;) BUT PRACTICAL TO RUN IT HERE\n",
    "        #w_star, e_tr = least_squares(y_train, x_train)  \n",
    "        \n",
    "        #compare the prediction with the reality\n",
    "        accuracy_training = np.count_nonzero(predict_labels(w_star, x_train) + y_train)/len(y_train)\n",
    "        accuracy_testing = np.count_nonzero(predict_labels(w_star, x_test) + y_test)/len(y_test)\n",
    "        \n",
    "        a_training.append(accuracy_training)\n",
    "        a_testing.append(accuracy_testing)\n",
    "        weights.append(w_star)\n",
    "        print(\"lambda={l:.3f}, Training Accuracy={tr}, Testing Accuracy={te}\".format(\n",
    "               l=lambda_, tr=a_training[ind], te=a_testing[ind]))\n",
    "        \n",
    "    plt.plot(lambdas, a_training,'r--' , lambdas, a_testing, 'g--')\n",
    "    plt.show\n",
    "    \n",
    "    return weights[np.argmax(a_testing)], a_testing[np.argmax(a_testing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.000, Training Accuracy=0.8244570233871954, Testing Accuracy=0.8282626100880705\n",
      "lambda=0.000, Training Accuracy=0.8089100432601951, Testing Accuracy=0.8145516413130505\n",
      "lambda=0.000, Training Accuracy=0.806552418233783, Testing Accuracy=0.8125500400320256\n",
      "lambda=0.000, Training Accuracy=0.8054959353210039, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.000, Training Accuracy=0.804784199463974, Testing Accuracy=0.8112489991993594\n",
      "lambda=0.001, Training Accuracy=0.8042948810622658, Testing Accuracy=0.8111489191353083\n",
      "lambda=0.001, Training Accuracy=0.8041280679707743, Testing Accuracy=0.8105484387510008\n",
      "lambda=0.001, Training Accuracy=0.8039834966248152, Testing Accuracy=0.8108486789431545\n",
      "lambda=0.001, Training Accuracy=0.8036832330601306, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.001, Training Accuracy=0.803494178223107, Testing Accuracy=0.8108486789431545\n",
      "lambda=0.001, Training Accuracy=0.8033940903682121, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.001, Training Accuracy=0.8032383981494867, Testing Accuracy=0.811048839071257\n",
      "lambda=0.001, Training Accuracy=0.8030827059307615, Testing Accuracy=0.8111489191353083\n",
      "lambda=0.001, Training Accuracy=0.8029047719665039, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.001, Training Accuracy=0.8027713214933108, Testing Accuracy=0.8103482786228983\n",
      "lambda=0.002, Training Accuracy=0.8027490797477786, Testing Accuracy=0.8104483586869495\n",
      "lambda=0.002, Training Accuracy=0.8027602006205447, Testing Accuracy=0.8101481184947958\n",
      "lambda=0.002, Training Accuracy=0.8027157171294803, Testing Accuracy=0.8100480384307446\n",
      "lambda=0.002, Training Accuracy=0.8026489918928837, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.002, Training Accuracy=0.8025266622924567, Testing Accuracy=0.8097477982385909\n",
      "lambda=0.002, Training Accuracy=0.802448816183094, Testing Accuracy=0.8100480384307446\n",
      "lambda=0.002, Training Accuracy=0.8023042448371348, Testing Accuracy=0.8098478783026422\n",
      "lambda=0.002, Training Accuracy=0.8022263987277721, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.002, Training Accuracy=0.8022820030916026, Testing Accuracy=0.8098478783026422\n",
      "lambda=0.002, Training Accuracy=0.8021151900001112, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.003, Training Accuracy=0.802092948254579, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.003, Training Accuracy=0.8020262230179824, Testing Accuracy=0.8098478783026422\n",
      "lambda=0.003, Training Accuracy=0.8020039812724503, Testing Accuracy=0.8096477181745396\n",
      "lambda=0.003, Training Accuracy=0.8020039812724503, Testing Accuracy=0.8096477181745396\n",
      "lambda=0.003, Training Accuracy=0.8020262230179824, Testing Accuracy=0.8095476381104884\n",
      "lambda=0.003, Training Accuracy=0.8019372560358536, Testing Accuracy=0.8094475580464372\n",
      "lambda=0.003, Training Accuracy=0.8018260473081927, Testing Accuracy=0.8094475580464372\n",
      "lambda=0.003, Training Accuracy=0.8017370803260639, Testing Accuracy=0.8091473178542834\n",
      "lambda=0.003, Training Accuracy=0.8016369924711692, Testing Accuracy=0.8091473178542834\n",
      "lambda=0.003, Training Accuracy=0.8015369046162742, Testing Accuracy=0.8090472377902321\n",
      "lambda=0.004, Training Accuracy=0.8014590585069116, Testing Accuracy=0.8090472377902321\n",
      "lambda=0.004, Training Accuracy=0.8013589706520168, Testing Accuracy=0.8088470776621297\n",
      "lambda=0.004, Training Accuracy=0.8013478497792507, Testing Accuracy=0.8088470776621297\n",
      "lambda=0.004, Training Accuracy=0.8013033662881863, Testing Accuracy=0.8088470776621297\n",
      "lambda=0.004, Training Accuracy=0.8012477619243559, Testing Accuracy=0.808546837469976\n",
      "lambda=0.004, Training Accuracy=0.8012588827971219, Testing Accuracy=0.8086469175340272\n",
      "lambda=0.004, Training Accuracy=0.8012143993060575, Testing Accuracy=0.808546837469976\n",
      "lambda=0.004, Training Accuracy=0.8011031905783966, Testing Accuracy=0.8083466773418735\n",
      "lambda=0.004, Training Accuracy=0.8010364653418001, Testing Accuracy=0.8082465972778222\n",
      "lambda=0.004, Training Accuracy=0.8010142235962678, Testing Accuracy=0.8081465172137711\n",
      "lambda=0.005, Training Accuracy=0.8009919818507356, Testing Accuracy=0.8080464371497198\n",
      "lambda=0.005, Training Accuracy=0.8009363774869052, Testing Accuracy=0.8080464371497198\n",
      "lambda=0.005, Training Accuracy=0.8008696522503086, Testing Accuracy=0.8078462770216173\n",
      "lambda=0.005, Training Accuracy=0.8008696522503086, Testing Accuracy=0.8076461168935148\n",
      "lambda=0.005, Training Accuracy=0.8007806852681798, Testing Accuracy=0.8075460368294636\n",
      "lambda=0.005, Training Accuracy=0.8008251687592443, Testing Accuracy=0.8075460368294636\n",
      "lambda=0.005, Training Accuracy=0.8008362896320104, Testing Accuracy=0.807345876701361\n",
      "lambda=0.005, Training Accuracy=0.800802927013712, Testing Accuracy=0.8072457966373099\n",
      "lambda=0.005, Training Accuracy=0.8008140478864781, Testing Accuracy=0.807345876701361\n",
      "lambda=0.005, Training Accuracy=0.8007584435226477, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.8007362017771155, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.8007473226498816, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.8006917182860511, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.800569388685624, Testing Accuracy=0.8071457165732586\n",
      "lambda=0.006, Training Accuracy=0.8005360260673258, Testing Accuracy=0.8071457165732586\n",
      "lambda=0.006, Training Accuracy=0.8004581799579631, Testing Accuracy=0.8070456365092074\n",
      "lambda=0.006, Training Accuracy=0.8004136964668987, Testing Accuracy=0.8070456365092074\n",
      "lambda=0.006, Training Accuracy=0.8003803338486004, Testing Accuracy=0.8070456365092074\n",
      "lambda=0.006, Training Accuracy=0.8003692129758343, Testing Accuracy=0.8069455564451561\n",
      "lambda=0.006, Training Accuracy=0.8003580921030683, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.8003469712303022, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.8003024877392377, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.800213520757109, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.8001579163932785, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.007, Training Accuracy=0.8001356746477464, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.007, Training Accuracy=0.8000467076656176, Testing Accuracy=0.8068454763811049\n",
      "lambda=0.007, Training Accuracy=0.7999911033017871, Testing Accuracy=0.8068454763811049\n",
      "lambda=0.007, Training Accuracy=0.7999243780651906, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.7998687737013601, Testing Accuracy=0.8068454763811049\n",
      "lambda=0.007, Training Accuracy=0.7998798945741262, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.008, Training Accuracy=0.7998131693375297, Testing Accuracy=0.8069455564451561\n",
      "lambda=0.008, Training Accuracy=0.7997798067192313, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.008, Training Accuracy=0.7997686858464652, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7997019606098686, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7996797188643364, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7996685979915704, Testing Accuracy=0.8064451561248999\n",
      "lambda=0.008, Training Accuracy=0.7996463562460382, Testing Accuracy=0.8065452361889511\n",
      "lambda=0.008, Training Accuracy=0.7996685979915704, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7996352353732721, Testing Accuracy=0.8064451561248999\n",
      "lambda=0.008, Training Accuracy=0.7995351475183773, Testing Accuracy=0.8065452361889511\n",
      "lambda=0.009, Training Accuracy=0.7994684222817807, Testing Accuracy=0.8064451561248999\n",
      "lambda=0.009, Training Accuracy=0.7994239387907163, Testing Accuracy=0.8063450760608487\n",
      "lambda=0.009, Training Accuracy=0.799390576172418, Testing Accuracy=0.8061449159327462\n",
      "lambda=0.009, Training Accuracy=0.7993572135541197, Testing Accuracy=0.8060448358686949\n",
      "lambda=0.009, Training Accuracy=0.7993349718085876, Testing Accuracy=0.8060448358686949\n",
      "lambda=0.009, Training Accuracy=0.7992904883175231, Testing Accuracy=0.8059447558046438\n",
      "lambda=0.009, Training Accuracy=0.7993349718085876, Testing Accuracy=0.8058446757405925\n",
      "lambda=0.009, Training Accuracy=0.7992571256992249, Testing Accuracy=0.8055444355484388\n",
      "lambda=0.009, Training Accuracy=0.7992237630809266, Testing Accuracy=0.8051441152922338\n",
      "lambda=0.009, Training Accuracy=0.79915703784433, Testing Accuracy=0.8050440352281826\n",
      "lambda=0.009, Training Accuracy=0.7991347960987978, Testing Accuracy=0.8050440352281826\n",
      "lambda=0.010, Training Accuracy=0.7990903126077334, Testing Accuracy=0.8051441152922338\n",
      "lambda=0.010, Training Accuracy=0.7990903126077334, Testing Accuracy=0.805244195356285\n",
      "lambda=0.010, Training Accuracy=0.7991125543532657, Testing Accuracy=0.8050440352281826\n",
      "lambda=0.010, Training Accuracy=0.7990569499894352, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7989902247528387, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7989791038800725, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7989012577707099, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7988122907885811, Testing Accuracy=0.8047437950360288\n",
      "lambda=0.010, Training Accuracy=0.7987233238064523, Testing Accuracy=0.8047437950360288\n",
      "lambda=0.011, Training Accuracy=0.798689961188154, Testing Accuracy=0.8047437950360288\n",
      "lambda=0.011, Training Accuracy=0.7987122029336863, Testing Accuracy=0.80484387510008\n",
      "lambda=0.011, Training Accuracy=0.7987010820609202, Testing Accuracy=0.8049439551641313\n",
      "lambda=0.011, Training Accuracy=0.7986454776970897, Testing Accuracy=0.8049439551641313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.011, Training Accuracy=0.7986009942060253, Testing Accuracy=0.8049439551641313\n",
      "lambda=0.011, Training Accuracy=0.798567631587727, Testing Accuracy=0.80484387510008\n",
      "lambda=0.011, Training Accuracy=0.7985120272238966, Testing Accuracy=0.8046437149719776\n",
      "lambda=0.011, Training Accuracy=0.7984453019873, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.011, Training Accuracy=0.7984008184962356, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.011, Training Accuracy=0.7983674558779373, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.011, Training Accuracy=0.7983118515141068, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7982784888958085, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7982006427864459, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.798211763659212, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7981450384226154, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7981339175498493, Testing Accuracy=0.8046437149719776\n",
      "lambda=0.012, Training Accuracy=0.7980671923132527, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.012, Training Accuracy=0.7979559835855918, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.012, Training Accuracy=0.7979226209672935, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.012, Training Accuracy=0.7979003792217613, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.013, Training Accuracy=0.7978002913668665, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7977558078758021, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7977224452575038, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7976779617664395, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.797633478275375, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.013, Training Accuracy=0.7976112365298429, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.013, Training Accuracy=0.7976001156570768, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7975445112932463, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7975222695477141, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.013, Training Accuracy=0.797511148674948, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.797511148674948, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.014, Training Accuracy=0.7975222695477141, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7974889069294159, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7974333025655853, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7974221816928192, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7973443355834566, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7973220938379244, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7972998520923922, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.014, Training Accuracy=0.7972553686013278, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.014, Training Accuracy=0.7971997642374974, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7971441598736669, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.015, Training Accuracy=0.7971107972553686, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.015, Training Accuracy=0.7970885555098364, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7969995885277077, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7969328632911111, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7968438963089823, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7968438963089823, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7968327754362162, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7966993249630231, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7966103579808943, Testing Accuracy=0.8040432345876701\n",
      "lambda=0.015, Training Accuracy=0.7966103579808943, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.016, Training Accuracy=0.7965436327442977, Testing Accuracy=0.8039431545236189\n",
      "lambda=0.016, Training Accuracy=0.7965213909987656, Testing Accuracy=0.8039431545236189\n",
      "lambda=0.016, Training Accuracy=0.7964657866349351, Testing Accuracy=0.8038430744595677\n",
      "lambda=0.016, Training Accuracy=0.7963656987800403, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.016, Training Accuracy=0.7963656987800403, Testing Accuracy=0.8038430744595677\n",
      "lambda=0.016, Training Accuracy=0.7963768196528064, Testing Accuracy=0.8038430744595677\n",
      "lambda=0.016, Training Accuracy=0.7963768196528064, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.016, Training Accuracy=0.7963323361617419, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.016, Training Accuracy=0.7962878526706776, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.017, Training Accuracy=0.7962544900523794, Testing Accuracy=0.8036429143314652\n",
      "lambda=0.017, Training Accuracy=0.7961988856885488, Testing Accuracy=0.8036429143314652\n",
      "lambda=0.017, Training Accuracy=0.7961766439430167, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.017, Training Accuracy=0.796098797833654, Testing Accuracy=0.8035428342674139\n",
      "lambda=0.017, Training Accuracy=0.7960765560881218, Testing Accuracy=0.8035428342674139\n",
      "lambda=0.017, Training Accuracy=0.7960431934698236, Testing Accuracy=0.8036429143314652\n",
      "lambda=0.017, Training Accuracy=0.7959987099787591, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.017, Training Accuracy=0.795987589105993, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.017, Training Accuracy=0.7959097429966304, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.017, Training Accuracy=0.7958430177600339, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.018, Training Accuracy=0.7957874133962033, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.7957651716506712, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.018, Training Accuracy=0.7956650837957763, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.795631721177478, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.795642842050244, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.7955983585591797, Testing Accuracy=0.8032425940752602\n",
      "lambda=0.018, Training Accuracy=0.7955983585591797, Testing Accuracy=0.803142514011209\n",
      "lambda=0.018, Training Accuracy=0.7955983585591797, Testing Accuracy=0.8030424339471577\n",
      "lambda=0.018, Training Accuracy=0.7955427541953493, Testing Accuracy=0.8029423538831065\n",
      "lambda=0.018, Training Accuracy=0.7955649959408815, Testing Accuracy=0.8029423538831065\n",
      "lambda=0.019, Training Accuracy=0.7955427541953493, Testing Accuracy=0.8028422738190553\n",
      "lambda=0.019, Training Accuracy=0.795520512449817, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7955093915770509, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7954649080859866, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7954426663404544, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7954093037221561, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7954204245949222, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7953536993583257, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7953203367400273, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7953425784855596, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7953648202310918, Testing Accuracy=0.8025420336269016\n",
      "lambda=0.020, Training Accuracy=0.7953536993583257, Testing Accuracy=0.8025420336269016\n",
      "lambda=0.020, Training Accuracy=0.7953203367400273, Testing Accuracy=0.802341873498799\n",
      "lambda=0.020, Training Accuracy=0.7953314576127934, Testing Accuracy=0.802341873498799\n",
      "lambda=0.020, Training Accuracy=0.7952202488851325, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.020, Training Accuracy=0.795164644521302, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.020, Training Accuracy=0.795164644521302, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.020, Training Accuracy=0.795164644521302, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.020, Training Accuracy=0.7951424027757699, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.020, Training Accuracy=0.7950979192847054, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.021, Training Accuracy=0.7950756775391733, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.021, Training Accuracy=0.7950756775391733, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.021, Training Accuracy=0.7950534357936411, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.021, Training Accuracy=0.7950311940481088, Testing Accuracy=0.8019415532425941\n",
      "lambda=0.021, Training Accuracy=0.7949755896842784, Testing Accuracy=0.8020416333066454\n",
      "lambda=0.021, Training Accuracy=0.7949088644476818, Testing Accuracy=0.8018414731785428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.021, Training Accuracy=0.7948643809566175, Testing Accuracy=0.8017413931144916\n",
      "lambda=0.021, Training Accuracy=0.7948310183383192, Testing Accuracy=0.8017413931144916\n",
      "lambda=0.021, Training Accuracy=0.7947976557200209, Testing Accuracy=0.8015412329863891\n",
      "lambda=0.021, Training Accuracy=0.7947309304834244, Testing Accuracy=0.8013410728582866\n",
      "lambda=0.022, Training Accuracy=0.7946864469923599, Testing Accuracy=0.8013410728582866\n",
      "lambda=0.022, Training Accuracy=0.7946419635012956, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7946642052468278, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7946642052468278, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7946642052468278, Testing Accuracy=0.8015412329863891\n",
      "lambda=0.022, Training Accuracy=0.7946197217557633, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7944862712825702, Testing Accuracy=0.8012409927942354\n",
      "lambda=0.022, Training Accuracy=0.7944862712825702, Testing Accuracy=0.8011409127301842\n",
      "lambda=0.022, Training Accuracy=0.7944640295370381, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.022, Training Accuracy=0.7944195460459736, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.023, Training Accuracy=0.7943973043004415, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.023, Training Accuracy=0.7943861834276754, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.023, Training Accuracy=0.7944195460459736, Testing Accuracy=0.8009407526020816\n",
      "lambda=0.023, Training Accuracy=0.7943639416821432, Testing Accuracy=0.800640512409928\n",
      "lambda=0.023, Training Accuracy=0.7943750625549093, Testing Accuracy=0.8004403522818254\n",
      "lambda=0.023, Training Accuracy=0.7944195460459736, Testing Accuracy=0.8001401120896717\n",
      "lambda=0.023, Training Accuracy=0.7943639416821432, Testing Accuracy=0.8000400320256205\n",
      "lambda=0.023, Training Accuracy=0.794330579063845, Testing Accuracy=0.799839871897518\n",
      "lambda=0.023, Training Accuracy=0.7943083373183127, Testing Accuracy=0.8001401120896717\n",
      "lambda=0.023, Training Accuracy=0.7942527329544823, Testing Accuracy=0.7999399519615693\n",
      "lambda=0.024, Training Accuracy=0.7941860077178857, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.7941304033540553, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.7940970407357569, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.7940747989902247, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.024, Training Accuracy=0.793985832008096, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.024, Training Accuracy=0.793985832008096, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.024, Training Accuracy=0.7940303154991604, Testing Accuracy=0.7997397918334668\n",
      "lambda=0.024, Training Accuracy=0.7939969528808621, Testing Accuracy=0.7997397918334668\n",
      "lambda=0.024, Training Accuracy=0.7939079858987333, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.793863502407669, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.025, Training Accuracy=0.7938968650259672, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7938857441532011, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.793874623280435, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.793863502407669, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7937967771710723, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7936744475706453, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.025, Training Accuracy=0.7936188432068149, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.025, Training Accuracy=0.793629964079581, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.025, Training Accuracy=0.7935854805885166, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7935854805885166, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7935298762246861, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7934631509880895, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.793407546624259, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7933408213876625, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.7933185796421303, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.793285217023832, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.7932407335327677, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7932629752782998, Testing Accuracy=0.7993394715772618\n",
      "lambda=0.026, Training Accuracy=0.7931406456778728, Testing Accuracy=0.7993394715772618\n",
      "lambda=0.026, Training Accuracy=0.7930627995685101, Testing Accuracy=0.7991393114491593\n",
      "lambda=0.027, Training Accuracy=0.7929404699680831, Testing Accuracy=0.7990392313851081\n",
      "lambda=0.027, Training Accuracy=0.7928848656042526, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.7927958986221239, Testing Accuracy=0.7990392313851081\n",
      "lambda=0.027, Training Accuracy=0.7927958986221239, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.7927736568765916, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.7927069316399951, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.792684689894463, Testing Accuracy=0.7990392313851081\n",
      "lambda=0.027, Training Accuracy=0.7926290855306325, Testing Accuracy=0.7988390712570056\n",
      "lambda=0.027, Training Accuracy=0.792584602039568, Testing Accuracy=0.7987389911929543\n",
      "lambda=0.027, Training Accuracy=0.7925178768029715, Testing Accuracy=0.7987389911929543\n",
      "lambda=0.028, Training Accuracy=0.7926068437851003, Testing Accuracy=0.7988390712570056\n",
      "lambda=0.028, Training Accuracy=0.7926179646578664, Testing Accuracy=0.7985388310648519\n",
      "lambda=0.028, Training Accuracy=0.7925289976757376, Testing Accuracy=0.7985388310648519\n",
      "lambda=0.028, Training Accuracy=0.7925178768029715, Testing Accuracy=0.7982385908726981\n",
      "lambda=0.028, Training Accuracy=0.7924400306936088, Testing Accuracy=0.7982385908726981\n",
      "lambda=0.028, Training Accuracy=0.792462272439141, Testing Accuracy=0.7979383506805444\n",
      "lambda=0.028, Training Accuracy=0.792462272439141, Testing Accuracy=0.7976381104883907\n",
      "lambda=0.028, Training Accuracy=0.7923733054570122, Testing Accuracy=0.7976381104883907\n",
      "lambda=0.028, Training Accuracy=0.7923065802204157, Testing Accuracy=0.7976381104883907\n",
      "lambda=0.028, Training Accuracy=0.7922732176021174, Testing Accuracy=0.7975380304243395\n",
      "lambda=0.029, Training Accuracy=0.7922398549838191, Testing Accuracy=0.7974379503602882\n",
      "lambda=0.029, Training Accuracy=0.7922398549838191, Testing Accuracy=0.7974379503602882\n",
      "lambda=0.029, Training Accuracy=0.7922398549838191, Testing Accuracy=0.797337870296237\n",
      "lambda=0.029, Training Accuracy=0.792217613238287, Testing Accuracy=0.797337870296237\n",
      "lambda=0.029, Training Accuracy=0.7921175253833921, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.029, Training Accuracy=0.7920841627650939, Testing Accuracy=0.797337870296237\n",
      "lambda=0.029, Training Accuracy=0.7920841627650939, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.029, Training Accuracy=0.7919729540374328, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.029, Training Accuracy=0.7919507122919006, Testing Accuracy=0.7970376301040832\n",
      "lambda=0.029, Training Accuracy=0.7919729540374328, Testing Accuracy=0.7971377101681345\n",
      "lambda=0.030, Training Accuracy=0.7919062288008363, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.030, Training Accuracy=0.7918617453097719, Testing Accuracy=0.7970376301040832\n",
      "lambda=0.030, Training Accuracy=0.7918506244370058, Testing Accuracy=0.7968374699759808\n",
      "lambda=0.030, Training Accuracy=0.7918395035642397, Testing Accuracy=0.7968374699759808\n",
      "lambda=0.030, Training Accuracy=0.7917505365821109, Testing Accuracy=0.796537229783827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([ 1.16496703e-01, -3.32022720e-01, -7.02323301e-01, -2.58364295e+03,\n",
       "         2.90250927e+01,  2.58372100e+03, -7.96694075e+00, -1.49032867e+01,\n",
       "        -9.17745403e-01,  8.71658689e+00,  2.80986232e-03,  3.37495184e-02,\n",
       "         8.52302851e+00,  1.30113359e-01,  3.23194784e-03, -6.94646766e-02,\n",
       "        -1.72429854e-01,  3.33841984e-02, -9.59010426e+00, -9.59010426e+00]),\n",
       " 0.8282626100880705)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4lNX58PHvnUkgbIFAgixhk0UIsmlAEItVFIGiqGgrBZeKRWRRqbYuVUQUX/1R9wUbFKm2FqhKi4BFUaoIqCSyKCAQkSVshn0n2/3+cZ6EELIMkGRmmPtzXXMx8zznOXNOY3Pn7KKqGGOMMRGBLoAxxpjgYAHBGGMMYAHBGGOMxwKCMcYYwAKCMcYYjwUEY4wxgJ8BQUR6i8gaEUkTkQeLuN9YROaLyFIRWSEifb3rXURkmfdaLiLX+ZunMcaYiiWlrUMQER+wFrgSSAeWAANVdVWBNMnAUlWdKCKJwBxVbSoiVYFMVc0WkfrAcqABoKXlaYwxpmL500LoAqSp6npVzQSmAv0LpVEgxntfE9gKoKqHVTXbux7tpfM3T2OMMRUo0o80DYHNBT6nAxcVSjMW+FhERgHVgCvybojIRcBkoAlws9da8CfPk8TFxWnTpk39KLIxxpg8qampO1U1vrR0/gQEKeJa4X6mgcAUVX1WRLoB74jI+aqaq6pfA21FpA3wNxH5yM883ZeLDAWGAjRu3JiUlBQ/imyMMSaPiGz0J50/XUbpQKMCnxPwuoQKGAJMB1DVxbjuobiCCVR1NXAION/PPPOeS1bVJFVNio8vNcAZY4w5Tf4EhCVASxFpJiKVgJuAmYXSbAJ6AngtgWggw3sm0rveBDgP2OBnnsYYYypQqV1GXp//SGAu4AMmq+pKERkHpKjqTOA+YJKIjMZ1/dymqioilwAPikgWkAsMV9WdAEXlWR4VNMYY459Sp50Gk6SkJLUxBGOMOTUikqqqSaWls5XKxhhjAAsIxhhjPBYQjDHGABYQjDHGeMIiIDw470HumHlHoIthjDFBzZ+VyiFv9c7VbNq3KdDFMMaYoBYWLQSf+MjOzS49oTHGhLGwCAiREZHk5OYEuhjGGBPUwiYgWAvBGGNKFhZjCC1qt+BI9pFAF8MYY4JaWASEcZeNC3QRjDEm6IVFl5ExxpjShUVAeGrBU/R8u2egi2GMMUEtLALClv1bWLFjRaCLYYwxQS0sAoIvwtYhGGNMacIjIIjP1iEYY0wpwiIg2DoEY4wpXVgEhJZ1WnJp00sDXQxjjAlqfgUEEektImtEJE1EHizifmMRmS8iS0VkhYj09a5fKSKpIvKd9+/lBZ75n5fnMu9Vt+yqdaKhFw7lo0EflVf2xhhzVih1YZqI+IBXgSuBdGCJiMxU1VUFkj0CTFfViSKSCMwBmgI7gatVdauInA/MBRoWeG6QqtohycYYEwT8aSF0AdJUdb2qZgJTgf6F0igQ472vCWwFUNWlqrrVu74SiBaRymde7FPz2pLXaP5ScxtHMMaYEvgTEBoCmwt8TufEv/IBxgKDRSQd1zoYVUQ+A4ClqnqswLW3vO6iR0VE/C/2qdl3dB/r96y3mUbGGFMCfwJCUb+otdDngcAUVU0A+gLviEh+3iLSFngGuLPAM4NUtR3wC+91c5FfLjJURFJEJCUjI8OP4p7MF+EDsBaCMcaUwJ+AkA40KvA5Aa9LqIAhwHQAVV0MRANxACKSAMwAblHVH/MeUNUt3r8HgHdxXVMnUdVkVU1S1aT4+Hh/6nSSyAg3VJKj1kIwxpji+BMQlgAtRaSZiFQCbgJmFkqzCegJICJtcAEhQ0RqAbOBh1R1YV5iEYkUkbyAEQX0A74/08oUx7fvAGAtBGOMKUmpAUFVs4GRuBlCq3GziVaKyDgRucZLdh/wexFZDvwTuE1V1XuuBfBooemllYG5IrICWAZsASaVdeXyNH9nFv231cxvKRhjjDmZuN/boSEpKUlTUk5jlmr//rBxIyxbVvaFMsaYICciqaqaVFq6sFipjM8HOTZ+YIwxJQmLgDAtdit1+61m075NgS6KMcYErbAICJk+yIjOITMnM9BFMcaYoBUWAcF3mdtCyRamGWNM8cIiIES27wjYOgRjjClJWAQE385dgK1DMMaYkoTFxPwm0+YyeF8ValauGeiiGGNM0AqLgJCUW4935tWAWk0CXRRjjAlaYdFlZOsQjDGmdGEREOZX3kbVYbtYuGlh6YmNMSZMhUVAwBfBkSjIys0KdEmMMSZohUVAiOzVB7B1CMYYU5KwCAi+1m0Am3ZqjDElCY+AsG0HYAvTjDGmJGEREOp9+BnDUqBRTKPSExtjTJgKi3UITXx1mDgLqHt+oItijDFBKyxaCBoRQY5AbrbNMjLGmOKERUBYE7mHyMdg2vdTA10UY4wJWn4FBBHpLSJrRCRNRB4s4n5jEZkvIktFZIWI9PWuXykiqSLynffv5QWeudC7niYiL4mIlF21TuSLiAIgx1oIxhhTrFIDgoj4gFeBPkAiMFBEEgslewSYrqqdgJuA17zrO4GrVbUdcCvwToFnJgJDgZbeq/cZ1KNEkX36ApDjK7eYY4wxIc+fFkIXIE1V16tqJjAV6F8ojQIx3vuawFYAVV2qqlu96yuBaBGpLCL1gRhVXayqCrwNXHuGdSmWr+m5AGSj5fUVxhgT8vyZZdQQ2FzgczpwUaE0Y4GPRWQUUA24ooh8BgBLVfWYiDT08imYZ0N/C32qItNdTMrJOlpeX2GMMSHPnxZCUf0shf/UHghMUdUEoC/wjojk5y0ibYFngDtPIc+8Z4eKSIqIpGRkZPhR3JPVmL+IPy6E9lWandbzxhgTDvwJCOlAwRVdCXhdQgUMAaYDqOpiIBqIAxCRBGAGcIuq/lggz4RS8sTLL1lVk1Q1KT4+3o/inqxGper83yfQtU6H03reGGPCgT8BYQnQUkSaiUgl3KDxzEJpNgE9AUSkDS4gZIhILWA28JCq5u89rarbgAMi0tWbXXQL8J8zrk0xNCKCvdFw9Nih8voKY4wJeaUGBFXNBkYCc4HVuNlEK0VknIhc4yW7D/i9iCwH/gnc5g0WjwRaAI+KyDLvVdd75i7gDSAN+BH4qCwrVtChiGxiH4RXVk0pr68wxpiQ59fWFao6B5hT6NqYAu9XAd2LeO5J4Mli8kwBKmQviUiftw4hx9YhGGNMccJipbLvyqsAyK5RLcAlMcaY4BUeAaF+AwCyI2xhmjHGFCcsAkJE+hYEIefIwUAXxRhjglZYBARSUxn3mXJ51HmBLokxxgStsDgPAZ+PR74AYjsFuiTGGBO0wqOF4POxpQbsObon0CUxxpigFTYBIXEEPL52UqBLYowxQStsAkJkLmTbOgRjjClWeASELl2IrFWbnLjagS6JMcYErfAICDEx+CpVtnUIxhhTgvAICNu3E3n4KDkH9wW6JMYYE7TCIyBs2MBjM/ZwU4Rtf22MMcUJm3UIQ5YC1S0gGGNMccKjheDzsT4WNh/ZHuiSGGNM0AqbgHDNQBid/magS2KMMUErbAKCLxeyNTvQJTHGmKAVHmMILVsS2aYtObFxgS6JMcYErfBoIVSujK9KVbLDo7bGGHNa/PoVKSK9RWSNiKSJyINF3G8sIvNFZKmIrBCRvt71Ot71gyLySqFn/uflWfis5bK3bx+R23eQvX9vuX2FMcaEulK7jETEB7wKXAmkA0tEZKZ3jnKeR4DpqjpRRBJx5y83BY4Cj+LOTi7q/ORB3tnK5WvvXh76+yai7r6+3L/KGGNClT9jCF2ANFVdDyAiU4H+QMGAoECM974msBVAVQ8BX4pIizIr8enw+bh6LVApMaDFMMaYYOZPl1FDYHOBz+netYLGAoNFJB3XOhjl5/e/5XUXPSoi5bfRkM/Hmjrw/bFN5fYVxhgT6vwJCEX9otZCnwcCU1Q1AegLvCMipeU9SFXbAb/wXjcX+eUiQ0UkRURSMjIy/ChuEXw+7ukDd+z7++k9b4wxYcCfgJAONCrwOQGvS6iAIcB0AFVdDEQDJc7xVNUt3r8HgHdxXVNFpUtW1SRVTYqPj/ejuEXIOw9Bc07veWOMCQP+BIQlQEsRaSYilYCbgJmF0mwCegKISBtcQCj2z3kRiRSROO99FNAP+P7Ui++n2Fgq9erD0djq5fYVxhgT6kodVFbVbBEZCcwFfMBkVV0pIuOAFFWdCdwHTBKR0bjupNtUVQFEZANuwLmSiFwL9AI2AnO9YOAD5gHld75lRATxtRuxMCO13L7CGGNCnV8rlVV1Dm6wuOC1MQXerwK6F/Ns02KyvdC/IpaBrCzqpawmIyKD7NxsIiPCY4G2McacivBYu5uby28mLuDfvkGBLokxxgSt8PhTOTKSxAxI1FZgrQNjjClSeLQQIiI4FAX/zf6B9P3pgS6NMcYEpfAICCJkVBf6RLzLJz9+EujSGGNMUAqPgACcc9QHwPaDdmqaMcYUJWwCQpWMvcRUjrGAYIwxxQibgEC1atSrXo/thywgGGNMUcInIDz8MPWORloLwRhjihE+AeH113khvR2v9X0t0CUxxpigFD6T8n0+OmXWhrptA10SY4wJSuHTQvD52MheklOT2Xd0X6BLY4wxQSesAsLyiAzunHUna3etDXRpjDEm6IRPQIiKonF2NQA27bOT04wxprDwGUPYsIHGR3bD/9WxgGCMMUUInxYCEBsdS/VK1VmwaQGfb/gc78gGY4wxhFNAGDMG+etfaVyzMTN+mMEv//ZLBn1w8nbYOw/v5L6593HV368i49BpnuFsjDEhKHy6jN5/H9q0YWbyTGpUrsHY/41lYspEnrniGWKrxHLvf++lfvX6vPj1ixzIPEB81Xhy7AxmY0wYCZ8Wgs8HOTk0r92cutXqcvdFdwMwc81MqkZVZcPeDTy54EmuOPcKVg5fyY77d1Cver0AF9oYYyqOXwFBRHqLyBoRSRORB4u431hE5ovIUhFZISJ9vet1vOsHReSVQs9cKCLfeXm+JCJSNlUqRmQkZGfnf2wd1xqAu/97N4Lw3q/fI21UGh/85gMS4xMREVK3pvLftP+Sq7nlWjRjjAkGpQYEEfEBrwJ9gERgoIgkFkr2CDBdVTsBNwF5+0McBR4F7i8i64nAUKCl9+p9OhXwm9dCOKEAv5rINeddQ47mUCu6Fs1rNz/h/kOfPkSff/QhfkI8G/ZuKNfiGWNMoPnTQugCpKnqelXNBKYC/QulUSDGe18T2AqgqodU9UtcYMgnIvWBGFVdrG6qz9vAtadfDT/ExECVKidcGpY0jBm/mUFkMcdqDksaRtNaTTmafZRhs4ZxNPtokemMMeZs4E9AaAhsLvA53btW0FhgsIikA3OAUX7kWfAsy6LyLFuffuoGlk/B9W2u56d7fuKZK55h7o9zWbZ9GQALNi7g4jcv5qv0r5j/03wyczIBNx5hQcMYE6r8CQhF9e0XnsA/EJiiqglAX+AdESkpb3/ydAlFhopIioikZGQEZhroyC4jWXbnMromdOVI1hF6TOnB4vTFdHuzG7f8+xZycl1X1MD3B9Lq5Vb5gcMYY0KJPwEhHWhU4HMCXpdQAUOA6QCquhiIBuJKyTOhlDzx8ktW1SRVTYqPj/ejuMV44gl47LHTfrxDvQ4ALNi0AIBX+77KHZ3u4K3+b1ElynVFffDrDwDo+XZP+r3bj/dXvW+L34wxIUNK+4UlIpHAWqAnsAVYAvxWVVcWSPMRME1Vp4hIG+BToKE3PoCI3AYkqerIAs8swXUtfY3rZnpZVeeUVJakpCRNSUk55UoCcMUVcOQILFx4es97cjWXbQe20TCm6B6utbvWcs9/7+GHnT+QlZPFulHr8gOGMcYEgoikqmpSaelKXZimqtkiMhKYC/iAyaq6UkTGASmqOhO4D5gkIqNxXT+3FQgGG3ADzpVE5Fqgl6quAu4CpgBVgI+8V/kpYpbR6YiQiGKDAUCrOq34aNBHZOdms37PeqpEVWHR5kX8Y8U/eLHPi8UOYBtjTKCV2kIIJmfUQujbFzIyYMmSsi2UH15b8hoj5oxAEAYkDqBLgy7c0uEWzql+ToWXxRgTfsqshXDW8PlOWJhWke688E6qRlVl2fZlvLn0Td5b9R6rdq7irf5vsWbnGurXqE9M5ZjSMzLGmHIUPgGhXj03hhAAvggft3W8DYBnez3Lt9u+JTHere17f/X7LE5fzPjLx9OwRkPqVK0TkDIaY0z4BIRJkwJdAsAFh84NO+d/joqIYtbaWcxaO4salWqQfHUyN51/UwBLaIwJV+ETEILU6G6j2bB3A01rNeU/a/7D018+zQ2JN9jgszGmwoXPoPLHH8Mzz8C0aRBX0hKJwDmYeZBj2ceoU9Wd6rZw00L6tuxLzeiagS6aMSaE+TuoHD7bX+/dC599Btu3B7okxapeqXr+GMKk1En89oPfUuuZWgyYPoCsnKwAl84Yc7YLn4CQ1yrYuTOw5fDT45c9zvu/fp/RXUfzweoPuPXft+ZvkWGMMeUhfAJC3rYXAdoP6VRFSATXt7me5656jqd7Ps0/v/8ni9MXB7pYxpizWPiMXIZYC6GgBy55gGaxzejeqDu5msuY+WMY3H4w1StV54edPwDQLaEb1SpVC3BJjTGhLLwCQmLiSWcihIpft/01AFv3b2XSt5P4y6K/kKu5ZOW6sYXVI1bTOq41c9PmEiERdKrfibiqwTl4bowJTuETEKKiYOXK0tMFuYYxDVny+yU8/eXTREZEMqDNAHwRPhrXbExmTibD5wxn/Z71REdG069VPyr7KnNxo4sZ3nn4KX1PZk4mlXyVyqkWxphgFD4B4SzSuGZjXvvVa0XeW3T7Ir7c9CUfrv2QLzd9Sa7m0v88d8BdTm4O6h07ESERRBQ4suJQ5iE+3/g5qzNWk3E4gxe/fpFZA2fR89ye5V8hY0xQCK+AcNddkJUFb7wR6JKUm3Oqn8OAxAEMSBxw0r3+U/sze91sAOKqxnFL+1sY1H4QF9S/gBe+eoFH5j9yQvoL6l8AwCvfvIJPfPyu0+/Yf2w/M9fMZOD5A23MwpizTHgFhPR02LQp0KUImMHtB9M1oSvgDvp57qvn3NGgw5YxIHEADWMa0rFeR1K3pnJrx1vzV0s/s/AZ0venM3nZZFZnrCamcgzXtr6WnYd38tfUv/Kn7n+iVnStQFbNGFMGwmelMsDo0fDXv8KBA2730zCXmZOJT3z4Ikr+3+JY9jGSU5O5d+69DGgzgMd/+Tht4tuQnJrMnbPuJDY6ln/d+C/rXjImSPm7Ujm8AsJbb8Htt8PatdCyZdkVLEwcyjx0UjfRsu3LuHnGzazfs57nr3qe/uf1t3MejAkytnVFUdq1c/+uWBHYcoSoosYMOtbryCc3f0KHczpw56w7+c+a/wCQnZtt50kbE2LCawwhMRF69oRqNhhalupVr8fC2xfyVfpXJMQkAG4g+lDmIf7c488BLp0xxl/hFRCqVoV58wJdirOSiNCtUbf8z6nbUvnXyn9xY9sbaVWnVQBLZozxl19dRiLSW0TWiEiaiDxYxP3GIjJfRJaKyAoR6Vvg3kPec2tE5KoC1zeIyHciskxEzmBg4DQcPAjWnVGuJlw5gShfFI9//nigi2KM8VOpAUFEfMCrQB8gERgoIomFkj0CTFfVTsBNwGves4ne57ZAb+A1L788l6lqR38GO8rMe+9BbCysX19hXxmO6lWvx7ALhzH1+6ms3bUWgO9//p5ub3bjucXPBbh0xpii+NNC6AKkqep6Vc0EpgL9C6VRIO+U+JrAVu99f2Cqqh5T1Z+ANC+/wGnXDrKz4dNPA1qMcDC622iiI6O58V83oqo0rNGQbQe2cd/H9/HakqJXWufZtG8T/9vwv4opqDEG8C8gNAQ2F/ic7l0raCwwWETSgTnAKD+eVeBjEUkVkaHFfbmIDBWRFBFJySiLratbtYKEBBtLqAANajQgdWgqL/V+CREhtkos60at45rzrmHEnBFc+c6VzF7rVk7nai7Lti8jdWsqw2cPp/lLzbn6n1fn57V532abtWRMOfNnUFmKuFb4/5kDgSmq+qyIdAPeEZHzS3m2u6puFZG6wCci8oOqfnFSYtVkIBncOgQ/ylsyEejVy3UdHT7sBppNuWkd15rWca3zP0f5oph2wzRGzB7ByoyVHMs5BsC/f/g3A6a77TYiIyIZesFQBrYbCMCanWtImpTE7y/4PX/o9of8FdRxVeOIjIjkUOYh9h/bz7z189i8fzMPXvLgCfs0GWP8409ASAcaFficwPEuoTxDcGMEqOpiEYkG4kp6VlXz/v1ZRGbgupJOCgjl4uabYfJk+OADGDy4Qr7SHBcdGc2b/d884VrruNa8/+v3AehUrxPNYpvl32tZpyWD2w3m+a+e5/mvns+/vmr4KtrEt2HSt5MYPXd0/vXF6Yu5utXVDL3QNTwLnjS3fMdy2tVtR5QvilzNZeXPK5n741w6N+jM11u+ZmSXkVSNsj8STHjyJyAsAVqKSDNgC26Q+LeF0mwCegJTRKQNEA1kADOBd0XkOaAB0BL4RkSqARGqesB73wsYVxYV8kuPHvDCC3D55RX2laZkifGJJMYXnqvgREgEE/tNZMgFQ0jZenxCWr3q9QC4vNnlTPzVRBrFNGLJ1iVMWDSBgee71sXY/43liS+eIFdz85974+o3GHLBEJ5a8BSPzn/0hO86nHWYsb8ce8K1vUf38o8V/6BVnVZc2fxK0nanMWP1DK5tfS0t69iKd3P28GvrCm8a6QuAD5isquNFZByQoqozvdlEk4DquC6hP6nqx96zfwZuB7KBe1X1IxE5F5jhZR8JvKuq40srxxlvXVGUtWvdoTmNGpWe1oSUPUf20OH1DiQ1SKJTvU4AxFaJ5ZYOtxBTOYYFGxeQui2Vy5pexpKtSwC4MfFGakbXpOsbXVm3ex3gtuw4lnOMkZ1H8nLfl5m1dhZX//NqIiTihE39lg9bTkJMAs8vfp5F6Yv4cfeP9GnRhycvfxKRonpPjakYtpeRP1Shc2d3rOZ330GNGmWXtwkKOw7uIK5qXKkb+BX25BdPsuPgDgAq+SoxuP1gzq97PlG+KHJyc9h+cDvJqcnsPrI7/5nHL3uc2lVq896q97hlxi1Uq1SNnYd30jy2OY//8nEGtR/E6ozVpO1Oo0O9DjSu2bhM62pMcSwg+GvRIrjkEhg1Cl58sWzzNmErKyeLCIngmYXP8M2Wb3il7yskxCTQ651efLL+E6IioujSsAsREsFFDS9iQq8JLN68mNnrZvPEZU9wIPMAx7KPEV8tPtBVMWcBfwNCeG1dUZSLL4YRI+Cll6BhQ7j/foiwGSrmzET5ogB4+BcPn3A9+epkth7YyrvfvcuqjFVk5Wbln2IXXy2e//fl/2PBpgUs374cX4SPL277grZ127L7yG584qN6pepk5WYRHRld4XUyZz8LCADPPQfbtsEDD8DRozBmTKBLZM5STWs1pWmtplzc6OL8a3mt9OaxzXm0x6O8v/p9ep7bk8WbFzNv/Tza1m3LhIUTePHrF6lXvR5bD2zlhsQb6NW8F7d0uCVQVTFnIesyypObCzNnQu/eEB3tVjNHWrw0gfPTnp9oUKMBlSMrk7o1lee/ep4NezfQpFYTPvvpM37T9je80PsFDmcd5uWvX2Z45+HUqGzjYOZkNoZwJvbuhUsvhXvucQfqGBPEZqyewfXTryeuahwjO4+kee3m3JB4g3UrmXx2QM6ZUIVzzoEhQ9zr9ddh0iQ4dCjQJTPmJNe1uY5v7viG9ue0Z+znY7l5xs20ebUNhzLdf69z1s1h1tpZ7D+2ny82fsGx7GMBLrEJVtZCKE52thtgfuklFyAqVYJ9+1x30qFDdsiOCUp7j+4lZWsKS7Ys4aFfPARA61das2bXGnziI0dzqF+9PlNvmEqPJj3YvG8zWw5syZ/xZM5O1kI4U5GRbjXzoUOQnu62y46OhmPH3NqFSy6BH34IdCmNOUGt6Fpcce4V+cEAYPZvZzPjNzO4vdPtJPdLpnvj7vndSR+s/oBub3bjrll38cPOH2wDwTBnLYRTdeQI/PWv8NRTLlj06gV79sDzz0OnToEtmzGnaMv+LTy7+Nn8PaIuqH8BD1/yMAMSB5CZk8meI3vYe3QvyanJ7Dqyi36t+jGgzQBbeR1ibB1CealSBe69F264AR55xG2jXbOm21IbYPZs2LXLrWXYuxeuvfb4PWOCTMOYhjzb61mubnU1KzNW8sa3b7Bx30YAUremcvFkNz22kq8SNSvX5J0V7zD/1vn0aNKDXYd3UadqnUAW35QxayGUJVVo1gw2bjx+rXJleOwxeOih4p8zJghtP7idGatnECER9GnZh4Y1GrIyYyXtz2nPG9++wQPzHuDDgR+esKbCBCdrIQSCCKxcCVu93cFzc+Evf4EGDdznI0dg/343g8mYIFevej3u6nzXCdfan9MegJ7NelItqhrdJ3cnrmocd3S6g6d6PmVdSSHOAkJZq1YNWhbYEnnSpOPvk5NdS2HECPjjH6Fu3YovnzFloFlsM74f/j2vp7zOgk0LeHrh09StVpfR3Ubzw84fSNudRnZuNtNXTicyIpKxvxzLubHnBrrYphTWZVSR1q6FJ56Ad991XUmtW8MvfnF8U70dO1yQsL+yTAhRVcYvGM8dF9xB7Sq1afJCE7Yf3A5ATOUYcnJzeKD7Azx66aOl5GTKi61UDmZr1sDLL8OPP0KtWvDPf7rrLVpAvXpuzOGSS9wAtjEhZtHmRURFRCEitKzdkqzcLOpUqYOI8PmGz2lQo0H+Majx1eKpXql6gEt89rOAEGpUXZB48knIyHDX4uNh3DgYNsyNPQDExLixCRFrSZiQcjjrMAnPJbDn6J78azGVY3jq8qcY0WVEAEt29rNB5VAjAnffDb//PcydC6tWucVw7d0gHl995aa6xsbC5s0uMNSs6Tbk69ABZs2CtDS4/npobAevmOBTNaoqn9/2Od9u+xYARZm9bja1q9QOcMlMHmshhIotW+Dhh9323Oed59Y6HDniBq19Pnj0Ude6iI6G4cPhiivcojnfqZ0UZkygZOdm53clmbJVpl1GItIbeBF3pvIKGjfvAAAU5UlEQVQbqvp0ofuNgb8Btbw0D6rqHO/eQ8AQIAe4W1Xn+pNnUcI6IPgjLc2d6fCf/0BODvTvD//+t7v37LMuWNSv7way4+0kLhM8JqVOyl/0dqrHnZrSlVmXkYj4gFeBK4F0YImIzFTVVQWSPQJMV9WJIpIIzAGaeu9vAtoCDYB5ItLKe6a0PM2patEC3n/ftSJmzXLjEuD+feABFyQAoqLgppvgvvtcd5MxAVYlqgoLNi3glW9e4Z6u9wS6OGHLn83tugBpqrpeVTOBqUD/QmkUiPHe1wS8lVn0B6aq6jFV/QlI8/LzJ09zuqKj3XjDjTe6zyJu36UdO2DxYrjzTjf2kNfa2rgRJk48vqDOmAo2qN0g+rTow71z72XIf4aQlZNFruay8ueVgS5aWPGnw64hsLnA53TgokJpxgIfi8gooBpwRYFnvyr0bEPvfWl5AiAiQ4GhAI1tsPT0Va7s1jjUrQtdu7pjQ495++LPmePGHYYPhzZtoGpV6NvXtSpsm29TAUSEaTdMY9zn4/jL4r/QOq41x3KOMfZ/Y7n6vKuJqRxDo5hGjLl0DJV8lQDYfWQ3S7ct5eMfP+bPPf5MTOWYUr7FlMafgFDU3MbCAw8DgSmq+qyIdAPeEZHzS3i2qJZJkYMZqpoMJIMbQ/CjvMYfUVHuBW5a66WXwowZ8M03sHs3TJjgBqoBxo93LYr69aF2bXcuRMuWbr2ErZUwZaRG5RpM6DWBRjUb8VX6V7zS9xV+PvQzs9fNJic3h437NpKruTzV8ynmps2l9z965z+7OH0x7w54l4QYt5Fk3thoaVtpFBxDtW03/AsI6UCjAp8TON4llGcI0BtAVReLSDQQV8qzpeVpKooIJCa6V57Dh48HjKNH3QK6H3+EJUugRg04cMB1TQG8/bbb1K9DBzcd1pgzcPdFd3P3RXcD8FKfl3ipz0sAvPz1y/lrGK449wqe7fUsdavVJVdzuWPmHYyZP4bJ/ScDEPlEJJERkdza4VZa1G7Blv1bGHXRKFrUbsGHaz5k2OxhdDinA4vTF7P36F76terHhwM/DEyFg4g/AWEJ0FJEmgFbcIPEvy2UZhPQE5giIm2AaCADmAm8KyLP4QaVWwLf4FoOpeVpAqlq1ePvn3ji5PuqLpAcPeqOGc3OdtebNHHTYocMgV//2qXbtQvi4iqm3OasNeqiUfnvfRE+/tDtD/mfezTpwQ87jx9Y9dilj/HT3p94a9lbZOdmIwit41rTonYL0nan0TquNV9v+ZpfNP4FF9a/kFZ13FyX1Rmruexvl3H/xfdz/8X3V1zlgoS/0077Ai/gpohOVtXxIjIOSFHVmd5soklAdVzXz59U9WPv2T8DtwPZwL2q+lFxeZZWDpt2GqR27HAD1CtWuNeaNXD77TByJCxaBD16QPPm0LGjm+66c6c7U6Jr10CX3JzlMnMyyc7Nxic+KkdWBiBXc4s9LnTrga3cPONmPvvpM0Z1GcWYS8fkb7uRZ83ONcRWiaVutdDZnNK2rjDBYeNGePNNty14aqrbgiMmBr74wq2ofvZZ+PBDGD0a+vWzhXQm4LJzsxk1ZxTJ3yaTq7mM++U4Hr30Ub7b8R2///D3fL3la5rWasqC3y3IH7MIdnamsgkOTZq4/Zjefx82bHAD1hs2HN9eo3Vr+Oknd7JcYiI8/jh88MHx5w8fDkSpTRiLjIhkYr+JfHfXd9zR6Y4TZi9ViarCPRfdw67Duzj/tfNJTk0GXKsjOzc7UEUuM9ZCMIGXne2CwLPPukHrpCQ32wlcV1NkJFx0kWtB9OrlBriNCaBVGasYM38MHet15N6u99LnH32oWbkmIzqPoE/LPoEu3kmsy8iEprwWQdWqLlBMmOCCwxdfuNaFzwf/93/whz9AVpa7ZifQmQAbNWcUU5ZPISsni++Hf0+L2i0CXaQTWEAwZ5ecHLfj66xZbi+mvn1h+XK48EI3WF2nDlx5pdu+46qrbH2EqXBbD2ylzattOJx1mJvOv4l3rnsn0EXKZwHBnP127HDdTMuXu63C09Lc9cWL3QymjRvdSmub8moqyKLNi0hOTea+bvfR7px2gS5OPgsIJryowp498N13bpqrCNxyC0ydCrfe6rYD79YNGjWyg4VMhQmWLb3tgBwTXkTcthqXXnr82qhRbizi7bfhjTfctV/9ynU7Abz2mltd3aSJezZvcZ2ttjZnSFW5febtLNmyhCa1mnBurXN54JIHgn6aqk07NWevzp3h9dfd3kspKe6I0t/85vj9P/3JnV3dqJHrWqpZE/74R3fv0CF46CH4+mvIzAxM+U3IEhG6N+pOlagq7Di4g+Rvk2nxUgumr5wOuAVzR7OPBriUJ7MuIxO+du1yK6m3bXOzlaKiXAsjKcmdUNe0qWs1iECDBnDxxS5gdO4c6JKbELNh7wYe//xxOjfozPDOw/l0/adcO+1amsc2Z93udQxuN5h257RjeOfhLNu+jAUbFzCiy4gy626yLiNjSlOnDlx9ddH3GjZ0AWPmTDdYvW4dfP65azkA/Pe/bo+n6693+zbZ2ghTgqa1mvJW/7fyP7eq04qrml/Fml1r6NW8F1OWT6Fd3Xbc2uFWvtz0JffOvZfUbalMuXZKsdtslAcLCMYUJyYGBg8+/ln1+Cl04LqS7r/fbQN+221u0HrQoAovpgk9jWo24r1fv5f/WVXJzMmkcmRl7kq6i/T96UxYNAERYVC7QVx57pUVsj23dRkZcya+/RZefNHNZoqPh/R0d33hQncYUZMmUKlSYMtoQo6q8sC8B5iwaAIA39zxDZ0bnn5XpU07NaYiHTzozoioX//E8YfYWLcmIikJbr7ZHSxkjJ/S96ezce9Gujfufkb52BiCMRWpenX3AjcAPXcubNoE8+e7LcHHj4eEBBcQZs6Eu+924xSXXOJe3bu7qa/GFJAQk1ChU1WthWBMRdi+3Q1iR0W5LThee+34CXRZWS7Nhg2ui2ntWjc+0bKlOwvbmDNkLQRjgkm9esffd+16/HCgI0dcUFiwwHU3ATzzDEye7MYeWreGVq3cqut+/WyVtSlX1kIwJtj88AMsXeoGrNeudYvj4uNd15MITJkC113nFtIZ4wcbVDbmbJGV5WYvNWvmpr3WqeMGsRs0cF1Q7dq5AevrrnMD2u++61Zfn3uueyYuzloWYa5Mu4xEpDfwIu784zdU9elC958HLvM+VgXqqmot794zwK+8e0+o6jTv+hTgUmCfd+82VV3mT3mMCStRUe4XO7hf7PPmwbRpboX1wYPuDOuMDHf/wAG3JUdB1arB3/4GAwa4HWJnznR7OO3a5fKoVs1tHW6D2mGv1IAgIj7gVeBKIB1YIiIzVXVVXhpVHV0g/Sigk/f+V8AFQEegMvC5iHykqvu95H9U1eOrM4wxpbvgAvcqSqtWbu+mzZvdluA//eReedNdZ86EoUNPfm7VKhcQvvzSnX9dt64LPuec41ogeTOozFnNnxZCFyBNVdcDiMhUoD+wqpj0A4HHvPeJwOeqmg1ki8hyoDcw/YxKbYwpWkSEW2Hdtq17FXbHHW5PpnXr3C/9+vVdKyMvYIwf77blKKhRIzeFFuDhh133VdeubufYJk3Ktz6mQvkTEBoCmwt8TgcuKiqhiDQBmgGfeZeWA4+JyHO4rqTLODGQjBeRMcCnwIOqeqyIPIcCQwEa5x3Mbow5PSLFBwuAOXPc3k2HD7tT6rZscd1MebZvh88+g3fegREjXOvhd7+D0aOLzs+EFH8CQlGjUcWNRN8EvKeqOQCq+rGIdAYWARnAYsDbdJ6HgO1AJSAZeAAYd9IXqSZ790lKSgqdEXBjQpHIiaupC3dNTZ7s/l271p0rMXu2CxLgBr+7dHHHmlav7loe4DYQ7N+//Mtuzpg/ASEdaFTgcwKwtZi0NwEjCl5Q1fHAeAAReRdY513f5iU5JiJvAff7X2xjTEC1agV/+IN75dmzx3UvffCBCw41a7pZUXmHFs2bB//6F7Rp4wa1zznHbe/Rvr27v369y6NjR/D5Kr5Oxq+AsARoKSLNgC24X/q/LZxIRM4DYnGtgLxrPqCWqu4SkfZAe+Bj7159Vd0mbgu/a4Hvz7QyxpgAqlvXDVrnTWUvPNX1559dsNi588TrO3a4Z596Ct580wWSCy5wLY2uXd102gg7y6si+LUOQUT6Ai/gpp1OVtXxIjIOSFHVmV6asUC0qj5Y4Llo4Fvv435gWN7UUhH5DIjHdUkt8+4dLKkctg7BmLPAli1uquyOHa4l0Lev62LKW4S3cKFblLdihdskcPVqF1xeecUFixtvdJ/T06FxYzct15TIFqYZY0JbVpZbJ5E3maRJEzfbKTraDXhnZbkFeW+/7a7PmAFVqrigER/vNgy0vaAA28vIGBPqoqKOBwNw6yk+/xw+/ND9om/eHHr0cPd+/hnuvffE52Nj4b334PLLXTeWrdYulQUEY0xoiIiAyy5zr8I6dnRB4dgxtzBvwwb4+9+hUyd3/667XFdUbKzbbvy669wZFRYkTmBdRsaYs9+//w1vvAG7d8M337gup/btYdkyFxTWr3czpCIjz8ogYV1GxhiT59pr3QtcUJg1Cw4dOv7Lv0cPN/spNxeuuQYmTDi+f1QYsRaCMcZMm+bOpTh82C2+y8yE5GS31cdZwGYZGWPM6UhPh4kT3SB1fLwbe5g3z23+1727G5cIsW4l6zIyxpjTkZDgNvnL85e/uDGIPDVquMAwZ47rYvrwQ3egUcuWcMMNblpsiLKAYIwxJfngA/eLf8cO+Oij4wPRIu4I1Ntvd1tugFsX0aqVm+HUubOb9ZSWVvxmgkHGAoIxxpRExK2obtAAhgw58V716u4MiZYt4dNPISUF5s6F7793AeH992HQILcVR8eObnFdRASMHAm1agWmPiWwMQRjjCkvO3e6QeqPP4bvvnNrJcCtk2jSxG3HsXAhNGwI99/vNvzLzS3zzf38HUOwHaOMMaa8xMW5I03nzXNdTllZ7pW3Ajs93c1ueukld1hR9equZZFn2jT45BO3K2wFsBaCMcYE2tq1MHUq7N3rttro189dj4524xAPPABPP11yHiWwWUbGGBMqWrWCMWNOvr5ypZvBVNwZ2mXMAoIxxgSr5s3dq4LYGIIxxhjAAoIxxhiPBQRjjDGABQRjjDEevwKCiPQWkTUikiYiDxZx/3kRWea91orI3gL3nhGR773XbwpcbyYiX4vIOhGZJiKVyqZKxhhjTkepAUFEfMCrQB8gERgoIokF06jqaFXtqKodgZeBD7xnfwVcAHQELgL+KCIx3mPPAM+raktgD1BoTbgxxpiK5E8LoQuQpqrrVTUTmAr0LyH9QOCf3vtE4HNVzVbVQ8ByoLeICHA58J6X7m/AtadTAWOMMWXDn4DQENhc4HO6d+0kItIEaAZ85l1aDvQRkaoiEgdcBjQC6gB7VTVvPXZJeQ4VkRQRScnIyPCjuMYYY06HPwvTijoJorj9Lm4C3lPVHABV/VhEOgOLgAxgMZB9KnmqajKQDCAiGSKy0Y8yFyUO2HmazwYbq0twsroEp7OlLmdSjyb+JPInIKTj/qrPkwBsLSbtTcCIghdUdTwwHkBE3gXW4SpVS0QivVZCSXkWzCvej/IWSURS/NnLIxRYXYKT1SU4nS11qYh6+NNltARo6c0KqoT7pT+zcCIROQ+IxbUC8q75RKSO97490B74WN2OevOBG7yktwL/OZOKGGOMOTOlthBUNVtERgJzAR8wWVVXisg4IEVV84LDQGCqnrh9ahSwwI0hsx8YXGDc4AFgqog8CSwF3iyTGhljjDktfm1up6pzgDmFro0p9HlsEc8dxc00KirP9bgZTBUluQK/q7xZXYKT1SU4nS11Kfd6hNR5CMYYY8qPbV1hjDEGCOGA4Md2GpW9LTHSvC0ymha495B3fY2IXOVvniFUjw0i8p23lUiFHTF3unURkToiMl9EDorIK4WeudCrS5qIvOQtagzVuvzPyzNvm5e6QV6XK0Uk1fvfP1VELi/wTKj9XEqqS6j9XLoUKOtyEbnO3zxLpaoh98INbv8InAtUwi2ASyyUZjjwuvf+JmCa9z7RS18Zt4juRy+/UvMMhXp49zYAcSH0M6kGXAIMA14p9Mw3QDfc2pWPgD4hXJf/AUkh9HPpBDTw3p8PbAnhn0tJdQm1n0tVINJ7Xx/4GTcefMa/w0K1heDPdhr9cVtigNsio6f3V0x/3GyoY6r6E5Dm5XeqW3QEaz0C5bTroqqHVPVL4GjBxCJSH4hR1cXq/ut/m4rZ4qTM6xJAZ1KXpaqatz5oJRDt/dUaij+XIutSAWUuzpnU5bAen60ZzfFFvWf8OyxUA4I/22nkp/H+x9uH2zKjuGf93qKjDJVHPcD9B/Kx1zQeWg7lLsqZ1KWkPNNLybM8lEdd8rzlNfUfraBulrKqywBgqaoeI/R/LgXrkiekfi4icpGIrAS+A4Z598/4d1ioBgR/tr4oLs2pXi9P5VEPgO6qegFuh9oRItLj9IvotzOpy5nkWR7Koy4Ag1S1HfAL73XzaZTtVJ1xXUSkLW534jtPIc/yUB51gRD8uajq16raFugMPCQi0X7mWaJQDQj+bKeRn0ZEIoGawO4Snj2VLTrKSnnUg7ymsar+DMygYrqSzqQuJeWZUEqe5aE86oKqbvH+PQC8Swj8XEQkAfff0C2q+mOB9CH3cymmLiH5c8mjqquBQ7hxkTP/HVaRAyllOCATCazHDabmDZ60LZRmBCcOyEz33rflxMHY9bjBmFLzDJF6VANqeGmq4TYW7B3MP5MC92/j5IHYJUBXjg9e9g3Funh5xnnvo3B9wsOCuS5ALS/9gCLyDamfS3F1CdGfSzOODyo3wf3Sj/Mnz1LLVd4VL8f/QfsCa3Gj6n/2ro0DrvHeRwP/wg22fgOcW+DZP3vPraHA7Iii8gy1euBmGCz3Xisrqh5lUJcNuL9+DuL+0kn0ricB33t5voK3mDLU6oILzqnACu/n8iLerLBgrQvwCO6vz2UFXnVD8edSXF1C9Odys1fWZcC3wLUl5XkqL1upbIwxBgjdMQRjjDFlzAKCMcYYwAKCMcYYjwUEY4wxgAUEY4wxHgsIxhhjAAsIxhhjPBYQjDHGAPD/AagZz9/J2A72AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "crossValidation(cleaned_with_median[0], split_y[0], 0.9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "y_donotUse, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics \n",
      "Type :\n",
      "0\n",
      "[0.2605448 0.        0.        0.        1.        1.        1.\n",
      " 0.        0.        0.        0.        0.        1.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        1.        1.        1.        1.        1.\n",
      " 1.        0.       ]\n",
      "Statistics \n",
      "Type :\n",
      "1\n",
      "[0.09834149 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "2\n",
      "[0.05881481 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "3\n",
      "[0.06376737 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "lambda=0.000, Training Accuracy=0.8244570233871954, Testing Accuracy=0.8282626100880705\n",
      "lambda=0.000, Training Accuracy=0.8089100432601951, Testing Accuracy=0.8145516413130505\n",
      "lambda=0.000, Training Accuracy=0.806552418233783, Testing Accuracy=0.8125500400320256\n",
      "lambda=0.000, Training Accuracy=0.8054959353210039, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.000, Training Accuracy=0.804784199463974, Testing Accuracy=0.8112489991993594\n",
      "lambda=0.001, Training Accuracy=0.8042948810622658, Testing Accuracy=0.8111489191353083\n",
      "lambda=0.001, Training Accuracy=0.8041280679707743, Testing Accuracy=0.8105484387510008\n",
      "lambda=0.001, Training Accuracy=0.8039834966248152, Testing Accuracy=0.8108486789431545\n",
      "lambda=0.001, Training Accuracy=0.8036832330601306, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.001, Training Accuracy=0.803494178223107, Testing Accuracy=0.8108486789431545\n",
      "lambda=0.001, Training Accuracy=0.8033940903682121, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.001, Training Accuracy=0.8032383981494867, Testing Accuracy=0.811048839071257\n",
      "lambda=0.001, Training Accuracy=0.8030827059307615, Testing Accuracy=0.8111489191353083\n",
      "lambda=0.001, Training Accuracy=0.8029047719665039, Testing Accuracy=0.8109487590072058\n",
      "lambda=0.001, Training Accuracy=0.8027713214933108, Testing Accuracy=0.8103482786228983\n",
      "lambda=0.002, Training Accuracy=0.8027490797477786, Testing Accuracy=0.8104483586869495\n",
      "lambda=0.002, Training Accuracy=0.8027602006205447, Testing Accuracy=0.8101481184947958\n",
      "lambda=0.002, Training Accuracy=0.8027157171294803, Testing Accuracy=0.8100480384307446\n",
      "lambda=0.002, Training Accuracy=0.8026489918928837, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.002, Training Accuracy=0.8025266622924567, Testing Accuracy=0.8097477982385909\n",
      "lambda=0.002, Training Accuracy=0.802448816183094, Testing Accuracy=0.8100480384307446\n",
      "lambda=0.002, Training Accuracy=0.8023042448371348, Testing Accuracy=0.8098478783026422\n",
      "lambda=0.002, Training Accuracy=0.8022263987277721, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.002, Training Accuracy=0.8022820030916026, Testing Accuracy=0.8098478783026422\n",
      "lambda=0.002, Training Accuracy=0.8021151900001112, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.003, Training Accuracy=0.802092948254579, Testing Accuracy=0.8099479583666933\n",
      "lambda=0.003, Training Accuracy=0.8020262230179824, Testing Accuracy=0.8098478783026422\n",
      "lambda=0.003, Training Accuracy=0.8020039812724503, Testing Accuracy=0.8096477181745396\n",
      "lambda=0.003, Training Accuracy=0.8020039812724503, Testing Accuracy=0.8096477181745396\n",
      "lambda=0.003, Training Accuracy=0.8020262230179824, Testing Accuracy=0.8095476381104884\n",
      "lambda=0.003, Training Accuracy=0.8019372560358536, Testing Accuracy=0.8094475580464372\n",
      "lambda=0.003, Training Accuracy=0.8018260473081927, Testing Accuracy=0.8094475580464372\n",
      "lambda=0.003, Training Accuracy=0.8017370803260639, Testing Accuracy=0.8091473178542834\n",
      "lambda=0.003, Training Accuracy=0.8016369924711692, Testing Accuracy=0.8091473178542834\n",
      "lambda=0.003, Training Accuracy=0.8015369046162742, Testing Accuracy=0.8090472377902321\n",
      "lambda=0.004, Training Accuracy=0.8014590585069116, Testing Accuracy=0.8090472377902321\n",
      "lambda=0.004, Training Accuracy=0.8013589706520168, Testing Accuracy=0.8088470776621297\n",
      "lambda=0.004, Training Accuracy=0.8013478497792507, Testing Accuracy=0.8088470776621297\n",
      "lambda=0.004, Training Accuracy=0.8013033662881863, Testing Accuracy=0.8088470776621297\n",
      "lambda=0.004, Training Accuracy=0.8012477619243559, Testing Accuracy=0.808546837469976\n",
      "lambda=0.004, Training Accuracy=0.8012588827971219, Testing Accuracy=0.8086469175340272\n",
      "lambda=0.004, Training Accuracy=0.8012143993060575, Testing Accuracy=0.808546837469976\n",
      "lambda=0.004, Training Accuracy=0.8011031905783966, Testing Accuracy=0.8083466773418735\n",
      "lambda=0.004, Training Accuracy=0.8010364653418001, Testing Accuracy=0.8082465972778222\n",
      "lambda=0.004, Training Accuracy=0.8010142235962678, Testing Accuracy=0.8081465172137711\n",
      "lambda=0.005, Training Accuracy=0.8009919818507356, Testing Accuracy=0.8080464371497198\n",
      "lambda=0.005, Training Accuracy=0.8009363774869052, Testing Accuracy=0.8080464371497198\n",
      "lambda=0.005, Training Accuracy=0.8008696522503086, Testing Accuracy=0.8078462770216173\n",
      "lambda=0.005, Training Accuracy=0.8008696522503086, Testing Accuracy=0.8076461168935148\n",
      "lambda=0.005, Training Accuracy=0.8007806852681798, Testing Accuracy=0.8075460368294636\n",
      "lambda=0.005, Training Accuracy=0.8008251687592443, Testing Accuracy=0.8075460368294636\n",
      "lambda=0.005, Training Accuracy=0.8008362896320104, Testing Accuracy=0.807345876701361\n",
      "lambda=0.005, Training Accuracy=0.800802927013712, Testing Accuracy=0.8072457966373099\n",
      "lambda=0.005, Training Accuracy=0.8008140478864781, Testing Accuracy=0.807345876701361\n",
      "lambda=0.005, Training Accuracy=0.8007584435226477, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.8007362017771155, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.8007473226498816, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.8006917182860511, Testing Accuracy=0.807345876701361\n",
      "lambda=0.006, Training Accuracy=0.800569388685624, Testing Accuracy=0.8071457165732586\n",
      "lambda=0.006, Training Accuracy=0.8005360260673258, Testing Accuracy=0.8071457165732586\n",
      "lambda=0.006, Training Accuracy=0.8004581799579631, Testing Accuracy=0.8070456365092074\n",
      "lambda=0.006, Training Accuracy=0.8004136964668987, Testing Accuracy=0.8070456365092074\n",
      "lambda=0.006, Training Accuracy=0.8003803338486004, Testing Accuracy=0.8070456365092074\n",
      "lambda=0.006, Training Accuracy=0.8003692129758343, Testing Accuracy=0.8069455564451561\n",
      "lambda=0.006, Training Accuracy=0.8003580921030683, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.8003469712303022, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.8003024877392377, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.800213520757109, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.8001579163932785, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.007, Training Accuracy=0.8001356746477464, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.007, Training Accuracy=0.8000467076656176, Testing Accuracy=0.8068454763811049\n",
      "lambda=0.007, Training Accuracy=0.7999911033017871, Testing Accuracy=0.8068454763811049\n",
      "lambda=0.007, Training Accuracy=0.7999243780651906, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.007, Training Accuracy=0.7998687737013601, Testing Accuracy=0.8068454763811049\n",
      "lambda=0.007, Training Accuracy=0.7998798945741262, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.008, Training Accuracy=0.7998131693375297, Testing Accuracy=0.8069455564451561\n",
      "lambda=0.008, Training Accuracy=0.7997798067192313, Testing Accuracy=0.8067453963170537\n",
      "lambda=0.008, Training Accuracy=0.7997686858464652, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7997019606098686, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7996797188643364, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7996685979915704, Testing Accuracy=0.8064451561248999\n",
      "lambda=0.008, Training Accuracy=0.7996463562460382, Testing Accuracy=0.8065452361889511\n",
      "lambda=0.008, Training Accuracy=0.7996685979915704, Testing Accuracy=0.8066453162530024\n",
      "lambda=0.008, Training Accuracy=0.7996352353732721, Testing Accuracy=0.8064451561248999\n",
      "lambda=0.008, Training Accuracy=0.7995351475183773, Testing Accuracy=0.8065452361889511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.009, Training Accuracy=0.7994684222817807, Testing Accuracy=0.8064451561248999\n",
      "lambda=0.009, Training Accuracy=0.7994239387907163, Testing Accuracy=0.8063450760608487\n",
      "lambda=0.009, Training Accuracy=0.799390576172418, Testing Accuracy=0.8061449159327462\n",
      "lambda=0.009, Training Accuracy=0.7993572135541197, Testing Accuracy=0.8060448358686949\n",
      "lambda=0.009, Training Accuracy=0.7993349718085876, Testing Accuracy=0.8060448358686949\n",
      "lambda=0.009, Training Accuracy=0.7992904883175231, Testing Accuracy=0.8059447558046438\n",
      "lambda=0.009, Training Accuracy=0.7993349718085876, Testing Accuracy=0.8058446757405925\n",
      "lambda=0.009, Training Accuracy=0.7992571256992249, Testing Accuracy=0.8055444355484388\n",
      "lambda=0.009, Training Accuracy=0.7992237630809266, Testing Accuracy=0.8051441152922338\n",
      "lambda=0.009, Training Accuracy=0.79915703784433, Testing Accuracy=0.8050440352281826\n",
      "lambda=0.009, Training Accuracy=0.7991347960987978, Testing Accuracy=0.8050440352281826\n",
      "lambda=0.010, Training Accuracy=0.7990903126077334, Testing Accuracy=0.8051441152922338\n",
      "lambda=0.010, Training Accuracy=0.7990903126077334, Testing Accuracy=0.805244195356285\n",
      "lambda=0.010, Training Accuracy=0.7991125543532657, Testing Accuracy=0.8050440352281826\n",
      "lambda=0.010, Training Accuracy=0.7990569499894352, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7989902247528387, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7989791038800725, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7989012577707099, Testing Accuracy=0.80484387510008\n",
      "lambda=0.010, Training Accuracy=0.7988122907885811, Testing Accuracy=0.8047437950360288\n",
      "lambda=0.010, Training Accuracy=0.7987233238064523, Testing Accuracy=0.8047437950360288\n",
      "lambda=0.011, Training Accuracy=0.798689961188154, Testing Accuracy=0.8047437950360288\n",
      "lambda=0.011, Training Accuracy=0.7987122029336863, Testing Accuracy=0.80484387510008\n",
      "lambda=0.011, Training Accuracy=0.7987010820609202, Testing Accuracy=0.8049439551641313\n",
      "lambda=0.011, Training Accuracy=0.7986454776970897, Testing Accuracy=0.8049439551641313\n",
      "lambda=0.011, Training Accuracy=0.7986009942060253, Testing Accuracy=0.8049439551641313\n",
      "lambda=0.011, Training Accuracy=0.798567631587727, Testing Accuracy=0.80484387510008\n",
      "lambda=0.011, Training Accuracy=0.7985120272238966, Testing Accuracy=0.8046437149719776\n",
      "lambda=0.011, Training Accuracy=0.7984453019873, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.011, Training Accuracy=0.7984008184962356, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.011, Training Accuracy=0.7983674558779373, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.011, Training Accuracy=0.7983118515141068, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7982784888958085, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7982006427864459, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.798211763659212, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7981450384226154, Testing Accuracy=0.8045436349079264\n",
      "lambda=0.012, Training Accuracy=0.7981339175498493, Testing Accuracy=0.8046437149719776\n",
      "lambda=0.012, Training Accuracy=0.7980671923132527, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.012, Training Accuracy=0.7979559835855918, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.012, Training Accuracy=0.7979226209672935, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.012, Training Accuracy=0.7979003792217613, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.013, Training Accuracy=0.7978002913668665, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7977558078758021, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7977224452575038, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7976779617664395, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.797633478275375, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.013, Training Accuracy=0.7976112365298429, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.013, Training Accuracy=0.7976001156570768, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7975445112932463, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.7975222695477141, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.013, Training Accuracy=0.797511148674948, Testing Accuracy=0.8043434747798238\n",
      "lambda=0.013, Training Accuracy=0.797511148674948, Testing Accuracy=0.8044435548438751\n",
      "lambda=0.014, Training Accuracy=0.7975222695477141, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7974889069294159, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7974333025655853, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7974221816928192, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7973443355834566, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7973220938379244, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.014, Training Accuracy=0.7972998520923922, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.014, Training Accuracy=0.7972553686013278, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.014, Training Accuracy=0.7971997642374974, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7971441598736669, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.015, Training Accuracy=0.7971107972553686, Testing Accuracy=0.8042433947157727\n",
      "lambda=0.015, Training Accuracy=0.7970885555098364, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7969995885277077, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7969328632911111, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7968438963089823, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7968438963089823, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7968327754362162, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7966993249630231, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.015, Training Accuracy=0.7966103579808943, Testing Accuracy=0.8040432345876701\n",
      "lambda=0.015, Training Accuracy=0.7966103579808943, Testing Accuracy=0.8041433146517214\n",
      "lambda=0.016, Training Accuracy=0.7965436327442977, Testing Accuracy=0.8039431545236189\n",
      "lambda=0.016, Training Accuracy=0.7965213909987656, Testing Accuracy=0.8039431545236189\n",
      "lambda=0.016, Training Accuracy=0.7964657866349351, Testing Accuracy=0.8038430744595677\n",
      "lambda=0.016, Training Accuracy=0.7963656987800403, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.016, Training Accuracy=0.7963656987800403, Testing Accuracy=0.8038430744595677\n",
      "lambda=0.016, Training Accuracy=0.7963768196528064, Testing Accuracy=0.8038430744595677\n",
      "lambda=0.016, Training Accuracy=0.7963768196528064, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.016, Training Accuracy=0.7963323361617419, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.016, Training Accuracy=0.7962878526706776, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.017, Training Accuracy=0.7962544900523794, Testing Accuracy=0.8036429143314652\n",
      "lambda=0.017, Training Accuracy=0.7961988856885488, Testing Accuracy=0.8036429143314652\n",
      "lambda=0.017, Training Accuracy=0.7961766439430167, Testing Accuracy=0.8037429943955164\n",
      "lambda=0.017, Training Accuracy=0.796098797833654, Testing Accuracy=0.8035428342674139\n",
      "lambda=0.017, Training Accuracy=0.7960765560881218, Testing Accuracy=0.8035428342674139\n",
      "lambda=0.017, Training Accuracy=0.7960431934698236, Testing Accuracy=0.8036429143314652\n",
      "lambda=0.017, Training Accuracy=0.7959987099787591, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.017, Training Accuracy=0.795987589105993, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.017, Training Accuracy=0.7959097429966304, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.017, Training Accuracy=0.7958430177600339, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.018, Training Accuracy=0.7957874133962033, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.7957651716506712, Testing Accuracy=0.8034427542033626\n",
      "lambda=0.018, Training Accuracy=0.7956650837957763, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.795631721177478, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.795642842050244, Testing Accuracy=0.8033426741393115\n",
      "lambda=0.018, Training Accuracy=0.7955983585591797, Testing Accuracy=0.8032425940752602\n",
      "lambda=0.018, Training Accuracy=0.7955983585591797, Testing Accuracy=0.803142514011209\n",
      "lambda=0.018, Training Accuracy=0.7955983585591797, Testing Accuracy=0.8030424339471577\n",
      "lambda=0.018, Training Accuracy=0.7955427541953493, Testing Accuracy=0.8029423538831065\n",
      "lambda=0.018, Training Accuracy=0.7955649959408815, Testing Accuracy=0.8029423538831065\n",
      "lambda=0.019, Training Accuracy=0.7955427541953493, Testing Accuracy=0.8028422738190553\n",
      "lambda=0.019, Training Accuracy=0.795520512449817, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7955093915770509, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7954649080859866, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7954426663404544, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7954093037221561, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7954204245949222, Testing Accuracy=0.802742193755004\n",
      "lambda=0.019, Training Accuracy=0.7953536993583257, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7953203367400273, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7953425784855596, Testing Accuracy=0.8026421136909527\n",
      "lambda=0.019, Training Accuracy=0.7953648202310918, Testing Accuracy=0.8025420336269016\n",
      "lambda=0.020, Training Accuracy=0.7953536993583257, Testing Accuracy=0.8025420336269016\n",
      "lambda=0.020, Training Accuracy=0.7953203367400273, Testing Accuracy=0.802341873498799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.020, Training Accuracy=0.7953314576127934, Testing Accuracy=0.802341873498799\n",
      "lambda=0.020, Training Accuracy=0.7952202488851325, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.020, Training Accuracy=0.795164644521302, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.020, Training Accuracy=0.795164644521302, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.020, Training Accuracy=0.795164644521302, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.020, Training Accuracy=0.7951424027757699, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.020, Training Accuracy=0.7950979192847054, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.021, Training Accuracy=0.7950756775391733, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.021, Training Accuracy=0.7950756775391733, Testing Accuracy=0.8022417934347478\n",
      "lambda=0.021, Training Accuracy=0.7950534357936411, Testing Accuracy=0.8021417133706965\n",
      "lambda=0.021, Training Accuracy=0.7950311940481088, Testing Accuracy=0.8019415532425941\n",
      "lambda=0.021, Training Accuracy=0.7949755896842784, Testing Accuracy=0.8020416333066454\n",
      "lambda=0.021, Training Accuracy=0.7949088644476818, Testing Accuracy=0.8018414731785428\n",
      "lambda=0.021, Training Accuracy=0.7948643809566175, Testing Accuracy=0.8017413931144916\n",
      "lambda=0.021, Training Accuracy=0.7948310183383192, Testing Accuracy=0.8017413931144916\n",
      "lambda=0.021, Training Accuracy=0.7947976557200209, Testing Accuracy=0.8015412329863891\n",
      "lambda=0.021, Training Accuracy=0.7947309304834244, Testing Accuracy=0.8013410728582866\n",
      "lambda=0.022, Training Accuracy=0.7946864469923599, Testing Accuracy=0.8013410728582866\n",
      "lambda=0.022, Training Accuracy=0.7946419635012956, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7946642052468278, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7946642052468278, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7946642052468278, Testing Accuracy=0.8015412329863891\n",
      "lambda=0.022, Training Accuracy=0.7946197217557633, Testing Accuracy=0.8014411529223379\n",
      "lambda=0.022, Training Accuracy=0.7944862712825702, Testing Accuracy=0.8012409927942354\n",
      "lambda=0.022, Training Accuracy=0.7944862712825702, Testing Accuracy=0.8011409127301842\n",
      "lambda=0.022, Training Accuracy=0.7944640295370381, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.022, Training Accuracy=0.7944195460459736, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.023, Training Accuracy=0.7943973043004415, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.023, Training Accuracy=0.7943861834276754, Testing Accuracy=0.8010408326661329\n",
      "lambda=0.023, Training Accuracy=0.7944195460459736, Testing Accuracy=0.8009407526020816\n",
      "lambda=0.023, Training Accuracy=0.7943639416821432, Testing Accuracy=0.800640512409928\n",
      "lambda=0.023, Training Accuracy=0.7943750625549093, Testing Accuracy=0.8004403522818254\n",
      "lambda=0.023, Training Accuracy=0.7944195460459736, Testing Accuracy=0.8001401120896717\n",
      "lambda=0.023, Training Accuracy=0.7943639416821432, Testing Accuracy=0.8000400320256205\n",
      "lambda=0.023, Training Accuracy=0.794330579063845, Testing Accuracy=0.799839871897518\n",
      "lambda=0.023, Training Accuracy=0.7943083373183127, Testing Accuracy=0.8001401120896717\n",
      "lambda=0.023, Training Accuracy=0.7942527329544823, Testing Accuracy=0.7999399519615693\n",
      "lambda=0.024, Training Accuracy=0.7941860077178857, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.7941304033540553, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.7940970407357569, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.7940747989902247, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.024, Training Accuracy=0.793985832008096, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.024, Training Accuracy=0.793985832008096, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.024, Training Accuracy=0.7940303154991604, Testing Accuracy=0.7997397918334668\n",
      "lambda=0.024, Training Accuracy=0.7939969528808621, Testing Accuracy=0.7997397918334668\n",
      "lambda=0.024, Training Accuracy=0.7939079858987333, Testing Accuracy=0.799839871897518\n",
      "lambda=0.024, Training Accuracy=0.793863502407669, Testing Accuracy=0.7996397117694155\n",
      "lambda=0.025, Training Accuracy=0.7938968650259672, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7938857441532011, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.793874623280435, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.793863502407669, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7937967771710723, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7936744475706453, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.025, Training Accuracy=0.7936188432068149, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.025, Training Accuracy=0.793629964079581, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.025, Training Accuracy=0.7935854805885166, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.025, Training Accuracy=0.7935854805885166, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7935298762246861, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7934631509880895, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.793407546624259, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7933408213876625, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.7933185796421303, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.793285217023832, Testing Accuracy=0.7995396317053642\n",
      "lambda=0.026, Training Accuracy=0.7932407335327677, Testing Accuracy=0.7994395516413131\n",
      "lambda=0.026, Training Accuracy=0.7932629752782998, Testing Accuracy=0.7993394715772618\n",
      "lambda=0.026, Training Accuracy=0.7931406456778728, Testing Accuracy=0.7993394715772618\n",
      "lambda=0.026, Training Accuracy=0.7930627995685101, Testing Accuracy=0.7991393114491593\n",
      "lambda=0.027, Training Accuracy=0.7929404699680831, Testing Accuracy=0.7990392313851081\n",
      "lambda=0.027, Training Accuracy=0.7928848656042526, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.7927958986221239, Testing Accuracy=0.7990392313851081\n",
      "lambda=0.027, Training Accuracy=0.7927958986221239, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.7927736568765916, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.7927069316399951, Testing Accuracy=0.7989391513210569\n",
      "lambda=0.027, Training Accuracy=0.792684689894463, Testing Accuracy=0.7990392313851081\n",
      "lambda=0.027, Training Accuracy=0.7926290855306325, Testing Accuracy=0.7988390712570056\n",
      "lambda=0.027, Training Accuracy=0.792584602039568, Testing Accuracy=0.7987389911929543\n",
      "lambda=0.027, Training Accuracy=0.7925178768029715, Testing Accuracy=0.7987389911929543\n",
      "lambda=0.028, Training Accuracy=0.7926068437851003, Testing Accuracy=0.7988390712570056\n",
      "lambda=0.028, Training Accuracy=0.7926179646578664, Testing Accuracy=0.7985388310648519\n",
      "lambda=0.028, Training Accuracy=0.7925289976757376, Testing Accuracy=0.7985388310648519\n",
      "lambda=0.028, Training Accuracy=0.7925178768029715, Testing Accuracy=0.7982385908726981\n",
      "lambda=0.028, Training Accuracy=0.7924400306936088, Testing Accuracy=0.7982385908726981\n",
      "lambda=0.028, Training Accuracy=0.792462272439141, Testing Accuracy=0.7979383506805444\n",
      "lambda=0.028, Training Accuracy=0.792462272439141, Testing Accuracy=0.7976381104883907\n",
      "lambda=0.028, Training Accuracy=0.7923733054570122, Testing Accuracy=0.7976381104883907\n",
      "lambda=0.028, Training Accuracy=0.7923065802204157, Testing Accuracy=0.7976381104883907\n",
      "lambda=0.028, Training Accuracy=0.7922732176021174, Testing Accuracy=0.7975380304243395\n",
      "lambda=0.029, Training Accuracy=0.7922398549838191, Testing Accuracy=0.7974379503602882\n",
      "lambda=0.029, Training Accuracy=0.7922398549838191, Testing Accuracy=0.7974379503602882\n",
      "lambda=0.029, Training Accuracy=0.7922398549838191, Testing Accuracy=0.797337870296237\n",
      "lambda=0.029, Training Accuracy=0.792217613238287, Testing Accuracy=0.797337870296237\n",
      "lambda=0.029, Training Accuracy=0.7921175253833921, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.029, Training Accuracy=0.7920841627650939, Testing Accuracy=0.797337870296237\n",
      "lambda=0.029, Training Accuracy=0.7920841627650939, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.029, Training Accuracy=0.7919729540374328, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.029, Training Accuracy=0.7919507122919006, Testing Accuracy=0.7970376301040832\n",
      "lambda=0.029, Training Accuracy=0.7919729540374328, Testing Accuracy=0.7971377101681345\n",
      "lambda=0.030, Training Accuracy=0.7919062288008363, Testing Accuracy=0.7972377902321858\n",
      "lambda=0.030, Training Accuracy=0.7918617453097719, Testing Accuracy=0.7970376301040832\n",
      "lambda=0.030, Training Accuracy=0.7918506244370058, Testing Accuracy=0.7968374699759808\n",
      "lambda=0.030, Training Accuracy=0.7918395035642397, Testing Accuracy=0.7968374699759808\n",
      "lambda=0.030, Training Accuracy=0.7917505365821109, Testing Accuracy=0.796537229783827\n",
      "lambda=0.000, Training Accuracy=0.7147258163894024, Testing Accuracy=0.7120567375886525\n",
      "lambda=0.000, Training Accuracy=0.7048818581724914, Testing Accuracy=0.7009671179883946\n",
      "lambda=0.000, Training Accuracy=0.7029617848084941, Testing Accuracy=0.6991618310767247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.000, Training Accuracy=0.7018727879751824, Testing Accuracy=0.6977433913604126\n",
      "lambda=0.000, Training Accuracy=0.7013712762756308, Testing Accuracy=0.6981302385557705\n",
      "lambda=0.001, Training Accuracy=0.7005831864620499, Testing Accuracy=0.6986460348162475\n",
      "lambda=0.001, Training Accuracy=0.7001676481967072, Testing Accuracy=0.6990328820116054\n",
      "lambda=0.001, Training Accuracy=0.6997234521199616, Testing Accuracy=0.6980012894906512\n",
      "lambda=0.001, Training Accuracy=0.6995371763458424, Testing Accuracy=0.6978723404255319\n",
      "lambda=0.001, Training Accuracy=0.6990929802690968, Testing Accuracy=0.6983881366860091\n",
      "lambda=0.001, Training Accuracy=0.6989210334006792, Testing Accuracy=0.6983881366860091\n",
      "lambda=0.001, Training Accuracy=0.6987490865322615, Testing Accuracy=0.6973565441650548\n",
      "lambda=0.001, Training Accuracy=0.6985054951353366, Testing Accuracy=0.6973565441650548\n",
      "lambda=0.001, Training Accuracy=0.6984481795125306, Testing Accuracy=0.6967117988394584\n",
      "lambda=0.001, Training Accuracy=0.6983048904555159, Testing Accuracy=0.6968407479045777\n",
      "lambda=0.002, Training Accuracy=0.6982332459270085, Testing Accuracy=0.6964539007092199\n",
      "lambda=0.002, Training Accuracy=0.6980756279642923, Testing Accuracy=0.6963249516441006\n",
      "lambda=0.002, Training Accuracy=0.6979466678129791, Testing Accuracy=0.6958091553836234\n",
      "lambda=0.002, Training Accuracy=0.69776039203886, Testing Accuracy=0.6954223081882657\n",
      "lambda=0.002, Training Accuracy=0.6976314318875467, Testing Accuracy=0.6954223081882657\n",
      "lambda=0.002, Training Accuracy=0.6974594850191291, Testing Accuracy=0.6947775628626692\n",
      "lambda=0.002, Training Accuracy=0.6974164983020247, Testing Accuracy=0.6946486137975499\n",
      "lambda=0.002, Training Accuracy=0.6973448537735173, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.002, Training Accuracy=0.6973878404906217, Testing Accuracy=0.6943907156673114\n",
      "lambda=0.002, Training Accuracy=0.6972302225279056, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.003, Training Accuracy=0.6970726045651894, Testing Accuracy=0.6943907156673114\n",
      "lambda=0.003, Training Accuracy=0.6969436444138761, Testing Accuracy=0.6943907156673114\n",
      "lambda=0.003, Training Accuracy=0.6968719998853687, Testing Accuracy=0.6945196647324307\n",
      "lambda=0.003, Training Accuracy=0.6967430397340555, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.003, Training Accuracy=0.6966140795827422, Testing Accuracy=0.6942617666021922\n",
      "lambda=0.003, Training Accuracy=0.6965281061485334, Testing Accuracy=0.6943907156673114\n",
      "lambda=0.003, Training Accuracy=0.6965137772428319, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.003, Training Accuracy=0.6963418303744143, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.003, Training Accuracy=0.6962701858459069, Testing Accuracy=0.6942617666021922\n",
      "lambda=0.003, Training Accuracy=0.6961125678831908, Testing Accuracy=0.6942617666021922\n",
      "lambda=0.004, Training Accuracy=0.695940621014773, Testing Accuracy=0.6942617666021922\n",
      "lambda=0.004, Training Accuracy=0.6958116608634598, Testing Accuracy=0.6942617666021922\n",
      "lambda=0.004, Training Accuracy=0.6956540429007436, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.004, Training Accuracy=0.6956397139950422, Testing Accuracy=0.6941328175370729\n",
      "lambda=0.004, Training Accuracy=0.6955680694665348, Testing Accuracy=0.6940038684719536\n",
      "lambda=0.004, Training Accuracy=0.6954391093152216, Testing Accuracy=0.693745970341715\n",
      "lambda=0.004, Training Accuracy=0.6952958202582069, Testing Accuracy=0.6936170212765957\n",
      "lambda=0.004, Training Accuracy=0.6952241757296995, Testing Accuracy=0.6934880722114765\n",
      "lambda=0.004, Training Accuracy=0.6951095444840878, Testing Accuracy=0.6936170212765957\n",
      "lambda=0.004, Training Accuracy=0.6951095444840878, Testing Accuracy=0.6936170212765957\n",
      "lambda=0.005, Training Accuracy=0.6950092421441775, Testing Accuracy=0.6936170212765957\n",
      "lambda=0.005, Training Accuracy=0.6949089398042672, Testing Accuracy=0.6938749194068343\n",
      "lambda=0.005, Training Accuracy=0.6948802819928642, Testing Accuracy=0.6936170212765957\n",
      "lambda=0.005, Training Accuracy=0.6948229663700584, Testing Accuracy=0.6932301740812379\n",
      "lambda=0.005, Training Accuracy=0.6946940062187451, Testing Accuracy=0.6932301740812379\n",
      "lambda=0.005, Training Accuracy=0.694722664030148, Testing Accuracy=0.6931012250161186\n",
      "lambda=0.005, Training Accuracy=0.6946510195016407, Testing Accuracy=0.6934880722114765\n",
      "lambda=0.005, Training Accuracy=0.6943357835762083, Testing Accuracy=0.6933591231463572\n",
      "lambda=0.005, Training Accuracy=0.6941924945191935, Testing Accuracy=0.6933591231463572\n",
      "lambda=0.005, Training Accuracy=0.6940635343678804, Testing Accuracy=0.6931012250161186\n",
      "lambda=0.006, Training Accuracy=0.693991889839373, Testing Accuracy=0.6931012250161186\n",
      "lambda=0.006, Training Accuracy=0.6939345742165671, Testing Accuracy=0.6929722759509993\n",
      "lambda=0.006, Training Accuracy=0.693719640631045, Testing Accuracy=0.6928433268858801\n",
      "lambda=0.006, Training Accuracy=0.6937482984424479, Testing Accuracy=0.6927143778207608\n",
      "lambda=0.006, Training Accuracy=0.6937482984424479, Testing Accuracy=0.6928433268858801\n",
      "lambda=0.006, Training Accuracy=0.6935476937626274, Testing Accuracy=0.6928433268858801\n",
      "lambda=0.006, Training Accuracy=0.6934187336113141, Testing Accuracy=0.6925854287556416\n",
      "lambda=0.006, Training Accuracy=0.6933041023657023, Testing Accuracy=0.6925854287556416\n",
      "lambda=0.006, Training Accuracy=0.6931608133086876, Testing Accuracy=0.6925854287556416\n",
      "lambda=0.006, Training Accuracy=0.6930031953459714, Testing Accuracy=0.6925854287556416\n",
      "lambda=0.007, Training Accuracy=0.6929888664402699, Testing Accuracy=0.6927143778207608\n",
      "lambda=0.007, Training Accuracy=0.6929745375345685, Testing Accuracy=0.6927143778207608\n",
      "lambda=0.007, Training Accuracy=0.6928169195718523, Testing Accuracy=0.6927143778207608\n",
      "lambda=0.007, Training Accuracy=0.6926879594205391, Testing Accuracy=0.6925854287556416\n",
      "lambda=0.007, Training Accuracy=0.6926306437977332, Testing Accuracy=0.6927143778207608\n",
      "lambda=0.007, Training Accuracy=0.6925876570806287, Testing Accuracy=0.6924564796905223\n",
      "lambda=0.007, Training Accuracy=0.6925876570806287, Testing Accuracy=0.6924564796905223\n",
      "lambda=0.007, Training Accuracy=0.6925733281749272, Testing Accuracy=0.692327530625403\n",
      "lambda=0.007, Training Accuracy=0.692415710212211, Testing Accuracy=0.6921985815602837\n",
      "lambda=0.007, Training Accuracy=0.6923440656837038, Testing Accuracy=0.6920696324951644\n",
      "lambda=0.008, Training Accuracy=0.692200776626689, Testing Accuracy=0.6919406834300451\n",
      "lambda=0.008, Training Accuracy=0.6920001719468685, Testing Accuracy=0.6916827852998065\n",
      "lambda=0.008, Training Accuracy=0.6918138961727492, Testing Accuracy=0.6916827852998065\n",
      "lambda=0.008, Training Accuracy=0.6917565805499434, Testing Accuracy=0.6916827852998065\n",
      "lambda=0.008, Training Accuracy=0.6915989625872272, Testing Accuracy=0.6915538362346872\n",
      "lambda=0.008, Training Accuracy=0.6915129891530184, Testing Accuracy=0.6912959381044488\n",
      "lambda=0.008, Training Accuracy=0.691441344624511, Testing Accuracy=0.6914248871695681\n",
      "lambda=0.008, Training Accuracy=0.6913840290017051, Testing Accuracy=0.6914248871695681\n",
      "lambda=0.008, Training Accuracy=0.6912837266617948, Testing Accuracy=0.6911669890393295\n",
      "lambda=0.008, Training Accuracy=0.6912693977560934, Testing Accuracy=0.6909090909090909\n",
      "lambda=0.009, Training Accuracy=0.691226411038989, Testing Accuracy=0.6909090909090909\n",
      "lambda=0.009, Training Accuracy=0.6911547665104816, Testing Accuracy=0.6903932946486138\n",
      "lambda=0.009, Training Accuracy=0.6910831219819742, Testing Accuracy=0.6903932946486138\n",
      "lambda=0.009, Training Accuracy=0.6910114774534669, Testing Accuracy=0.6901353965183752\n",
      "lambda=0.009, Training Accuracy=0.6908252016793478, Testing Accuracy=0.6897485493230174\n",
      "lambda=0.009, Training Accuracy=0.6907822149622433, Testing Accuracy=0.6897485493230174\n",
      "lambda=0.009, Training Accuracy=0.6907822149622433, Testing Accuracy=0.6896196002578981\n",
      "lambda=0.009, Training Accuracy=0.6908252016793478, Testing Accuracy=0.689103803997421\n",
      "lambda=0.009, Training Accuracy=0.6908395305850492, Testing Accuracy=0.689103803997421\n",
      "lambda=0.009, Training Accuracy=0.6908538594907507, Testing Accuracy=0.6888459058671824\n",
      "lambda=0.009, Training Accuracy=0.6907822149622433, Testing Accuracy=0.6888459058671824\n",
      "lambda=0.010, Training Accuracy=0.6905099657539153, Testing Accuracy=0.6889748549323017\n",
      "lambda=0.010, Training Accuracy=0.6904956368482139, Testing Accuracy=0.6887169568020632\n",
      "lambda=0.010, Training Accuracy=0.6904526501311095, Testing Accuracy=0.688588007736944\n",
      "lambda=0.010, Training Accuracy=0.6903523477911991, Testing Accuracy=0.6884590586718247\n",
      "lambda=0.010, Training Accuracy=0.6902950321683933, Testing Accuracy=0.6884590586718247\n",
      "lambda=0.010, Training Accuracy=0.6901517431113786, Testing Accuracy=0.6883301096067054\n",
      "lambda=0.010, Training Accuracy=0.6901374142056771, Testing Accuracy=0.6884590586718247\n",
      "lambda=0.010, Training Accuracy=0.6900944274885727, Testing Accuracy=0.6884590586718247\n",
      "lambda=0.010, Training Accuracy=0.689922480620155, Testing Accuracy=0.6884590586718247\n",
      "lambda=0.011, Training Accuracy=0.6898508360916477, Testing Accuracy=0.688588007736944\n",
      "lambda=0.011, Training Accuracy=0.689707547034633, Testing Accuracy=0.6884590586718247\n",
      "lambda=0.011, Training Accuracy=0.6897218759403344, Testing Accuracy=0.6883301096067054\n",
      "lambda=0.011, Training Accuracy=0.6896359025061256, Testing Accuracy=0.6882011605415861\n",
      "lambda=0.011, Training Accuracy=0.6894496267320065, Testing Accuracy=0.6879432624113475\n",
      "lambda=0.011, Training Accuracy=0.6893779822034991, Testing Accuracy=0.6876853642811089\n",
      "lambda=0.011, Training Accuracy=0.6893636532977977, Testing Accuracy=0.6874274661508704\n",
      "lambda=0.011, Training Accuracy=0.6892776798635888, Testing Accuracy=0.686782720825274\n",
      "lambda=0.011, Training Accuracy=0.6892203642407829, Testing Accuracy=0.686782720825274\n",
      "lambda=0.011, Training Accuracy=0.6892920087692903, Testing Accuracy=0.6866537717601547\n",
      "lambda=0.011, Training Accuracy=0.6891343908065741, Testing Accuracy=0.686782720825274\n",
      "lambda=0.012, Training Accuracy=0.6891057329951712, Testing Accuracy=0.686782720825274\n",
      "lambda=0.012, Training Accuracy=0.6890340884666638, Testing Accuracy=0.6866537717601547\n",
      "lambda=0.012, Training Accuracy=0.6889337861267535, Testing Accuracy=0.6865248226950355\n",
      "lambda=0.012, Training Accuracy=0.688890799409649, Testing Accuracy=0.6863958736299162\n",
      "lambda=0.012, Training Accuracy=0.688890799409649, Testing Accuracy=0.6862669245647969\n",
      "lambda=0.012, Training Accuracy=0.6888621415982461, Testing Accuracy=0.6861379754996776\n",
      "lambda=0.012, Training Accuracy=0.6887475103526344, Testing Accuracy=0.6861379754996776\n",
      "lambda=0.012, Training Accuracy=0.688675865824127, Testing Accuracy=0.6862669245647969\n",
      "lambda=0.012, Training Accuracy=0.6885325767671123, Testing Accuracy=0.6862669245647969\n",
      "lambda=0.013, Training Accuracy=0.6884752611443065, Testing Accuracy=0.6862669245647969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.013, Training Accuracy=0.6884752611443065, Testing Accuracy=0.6861379754996776\n",
      "lambda=0.013, Training Accuracy=0.6884036166157991, Testing Accuracy=0.6860090264345583\n",
      "lambda=0.013, Training Accuracy=0.6883463009929932, Testing Accuracy=0.6858800773694391\n",
      "lambda=0.013, Training Accuracy=0.6882459986530829, Testing Accuracy=0.6856221792392005\n",
      "lambda=0.013, Training Accuracy=0.6882316697473814, Testing Accuracy=0.6854932301740813\n",
      "lambda=0.013, Training Accuracy=0.6882030119359784, Testing Accuracy=0.685364281108962\n",
      "lambda=0.013, Training Accuracy=0.688188683030277, Testing Accuracy=0.6852353320438427\n",
      "lambda=0.013, Training Accuracy=0.6880883806903667, Testing Accuracy=0.6849774339136041\n",
      "lambda=0.013, Training Accuracy=0.6879594205390535, Testing Accuracy=0.6851063829787234\n",
      "lambda=0.013, Training Accuracy=0.6879450916333519, Testing Accuracy=0.6851063829787234\n",
      "lambda=0.014, Training Accuracy=0.6877158291421284, Testing Accuracy=0.6852353320438427\n",
      "lambda=0.014, Training Accuracy=0.687672842425024, Testing Accuracy=0.6854932301740813\n",
      "lambda=0.014, Training Accuracy=0.6875582111794122, Testing Accuracy=0.6852353320438427\n",
      "lambda=0.014, Training Accuracy=0.6874292510280989, Testing Accuracy=0.6852353320438427\n",
      "lambda=0.014, Training Accuracy=0.6872716330653827, Testing Accuracy=0.6849774339136041\n",
      "lambda=0.014, Training Accuracy=0.6872429752539798, Testing Accuracy=0.6848484848484848\n",
      "lambda=0.014, Training Accuracy=0.6872143174425769, Testing Accuracy=0.6848484848484848\n",
      "lambda=0.014, Training Accuracy=0.6871140151026666, Testing Accuracy=0.6848484848484848\n",
      "lambda=0.014, Training Accuracy=0.6870853572912636, Testing Accuracy=0.6849774339136041\n",
      "lambda=0.015, Training Accuracy=0.686942068234249, Testing Accuracy=0.6849774339136041\n",
      "lambda=0.015, Training Accuracy=0.6869850549513533, Testing Accuracy=0.6849774339136041\n",
      "lambda=0.015, Training Accuracy=0.6868990815171445, Testing Accuracy=0.6848484848484848\n",
      "lambda=0.015, Training Accuracy=0.6867557924601299, Testing Accuracy=0.6847195357833655\n",
      "lambda=0.015, Training Accuracy=0.6867271346487269, Testing Accuracy=0.6847195357833655\n",
      "lambda=0.015, Training Accuracy=0.6867128057430254, Testing Accuracy=0.6845905867182462\n",
      "lambda=0.015, Training Accuracy=0.6866268323088166, Testing Accuracy=0.6847195357833655\n",
      "lambda=0.015, Training Accuracy=0.6866125034031151, Testing Accuracy=0.6848484848484848\n",
      "lambda=0.015, Training Accuracy=0.6865408588746077, Testing Accuracy=0.6845905867182462\n",
      "lambda=0.015, Training Accuracy=0.6864835432518018, Testing Accuracy=0.6842037395228885\n",
      "lambda=0.015, Training Accuracy=0.6864118987232946, Testing Accuracy=0.6840747904577692\n",
      "lambda=0.016, Training Accuracy=0.6863259252890856, Testing Accuracy=0.6840747904577692\n",
      "lambda=0.016, Training Accuracy=0.6863115963833842, Testing Accuracy=0.6836879432624113\n",
      "lambda=0.016, Training Accuracy=0.6863259252890856, Testing Accuracy=0.6839458413926499\n",
      "lambda=0.016, Training Accuracy=0.6862256229491753, Testing Accuracy=0.6836879432624113\n",
      "lambda=0.016, Training Accuracy=0.6862686096662798, Testing Accuracy=0.683558994197292\n",
      "lambda=0.016, Training Accuracy=0.6861253206092651, Testing Accuracy=0.6834300451321728\n",
      "lambda=0.016, Training Accuracy=0.6860106893636533, Testing Accuracy=0.6833010960670535\n",
      "lambda=0.016, Training Accuracy=0.6859677026465489, Testing Accuracy=0.6831721470019342\n",
      "lambda=0.016, Training Accuracy=0.6858387424952357, Testing Accuracy=0.6829142488716957\n",
      "lambda=0.017, Training Accuracy=0.6857097823439224, Testing Accuracy=0.6829142488716957\n",
      "lambda=0.017, Training Accuracy=0.685666795626818, Testing Accuracy=0.6826563507414571\n",
      "lambda=0.017, Training Accuracy=0.685666795626818, Testing Accuracy=0.6822695035460993\n",
      "lambda=0.017, Training Accuracy=0.6857241112496238, Testing Accuracy=0.6822695035460993\n",
      "lambda=0.017, Training Accuracy=0.685666795626818, Testing Accuracy=0.6820116054158607\n",
      "lambda=0.017, Training Accuracy=0.6855951510983106, Testing Accuracy=0.6822695035460993\n",
      "lambda=0.017, Training Accuracy=0.6854805198526989, Testing Accuracy=0.68214055448098\n",
      "lambda=0.017, Training Accuracy=0.6853802175127885, Testing Accuracy=0.6820116054158607\n",
      "lambda=0.017, Training Accuracy=0.6852942440785798, Testing Accuracy=0.6822695035460993\n",
      "lambda=0.017, Training Accuracy=0.6851652839272665, Testing Accuracy=0.6818826563507414\n",
      "lambda=0.018, Training Accuracy=0.6849933370588488, Testing Accuracy=0.681624758220503\n",
      "lambda=0.018, Training Accuracy=0.6849360214360429, Testing Accuracy=0.6812379110251451\n",
      "lambda=0.018, Training Accuracy=0.68490736362464, Testing Accuracy=0.6812379110251451\n",
      "lambda=0.018, Training Accuracy=0.6847927323790283, Testing Accuracy=0.6811089619600258\n",
      "lambda=0.018, Training Accuracy=0.6847497456619238, Testing Accuracy=0.6808510638297872\n",
      "lambda=0.018, Training Accuracy=0.684663772227715, Testing Accuracy=0.6807221147646679\n",
      "lambda=0.018, Training Accuracy=0.6846494433220135, Testing Accuracy=0.6807221147646679\n",
      "lambda=0.018, Training Accuracy=0.684606456604909, Testing Accuracy=0.6808510638297872\n",
      "lambda=0.018, Training Accuracy=0.6846207855106106, Testing Accuracy=0.6808510638297872\n",
      "lambda=0.018, Training Accuracy=0.6845921276992076, Testing Accuracy=0.6807221147646679\n",
      "lambda=0.019, Training Accuracy=0.6844774964535958, Testing Accuracy=0.6804642166344294\n",
      "lambda=0.019, Training Accuracy=0.6843198784908796, Testing Accuracy=0.6803352675693102\n",
      "lambda=0.019, Training Accuracy=0.6842768917737753, Testing Accuracy=0.6802063185041909\n",
      "lambda=0.019, Training Accuracy=0.6842052472452679, Testing Accuracy=0.6802063185041909\n",
      "lambda=0.019, Training Accuracy=0.6841622605281634, Testing Accuracy=0.6799484203739523\n",
      "lambda=0.019, Training Accuracy=0.6841336027167605, Testing Accuracy=0.6799484203739523\n",
      "lambda=0.019, Training Accuracy=0.6841192738110591, Testing Accuracy=0.679819471308833\n",
      "lambda=0.019, Training Accuracy=0.6840762870939546, Testing Accuracy=0.6796905222437137\n",
      "lambda=0.019, Training Accuracy=0.6840046425654472, Testing Accuracy=0.6795615731785944\n",
      "lambda=0.019, Training Accuracy=0.6839616558483429, Testing Accuracy=0.6794326241134752\n",
      "lambda=0.019, Training Accuracy=0.6838470246027311, Testing Accuracy=0.6794326241134752\n",
      "lambda=0.020, Training Accuracy=0.6836750777343135, Testing Accuracy=0.6793036750483559\n",
      "lambda=0.020, Training Accuracy=0.6835317886772987, Testing Accuracy=0.6793036750483559\n",
      "lambda=0.020, Training Accuracy=0.6834028285259854, Testing Accuracy=0.6794326241134752\n",
      "lambda=0.020, Training Accuracy=0.6833598418088811, Testing Accuracy=0.6794326241134752\n",
      "lambda=0.020, Training Accuracy=0.6833168550917766, Testing Accuracy=0.6793036750483559\n",
      "lambda=0.020, Training Accuracy=0.6832022238461649, Testing Accuracy=0.6794326241134752\n",
      "lambda=0.020, Training Accuracy=0.6831449082233589, Testing Accuracy=0.6794326241134752\n",
      "lambda=0.020, Training Accuracy=0.6831305793176575, Testing Accuracy=0.6793036750483559\n",
      "lambda=0.020, Training Accuracy=0.6830589347891501, Testing Accuracy=0.6791747259832366\n",
      "lambda=0.021, Training Accuracy=0.6830302769777472, Testing Accuracy=0.6791747259832366\n",
      "lambda=0.021, Training Accuracy=0.6829443035435384, Testing Accuracy=0.6791747259832366\n",
      "lambda=0.021, Training Accuracy=0.682901316826434, Testing Accuracy=0.6790457769181173\n",
      "lambda=0.021, Training Accuracy=0.682872659015031, Testing Accuracy=0.6789168278529981\n",
      "lambda=0.021, Training Accuracy=0.6827293699580163, Testing Accuracy=0.6786589297227595\n",
      "lambda=0.021, Training Accuracy=0.6827150410523148, Testing Accuracy=0.6786589297227595\n",
      "lambda=0.021, Training Accuracy=0.6827150410523148, Testing Accuracy=0.6786589297227595\n",
      "lambda=0.021, Training Accuracy=0.682629067618106, Testing Accuracy=0.6785299806576403\n",
      "lambda=0.021, Training Accuracy=0.6825144363724942, Testing Accuracy=0.6782720825274017\n",
      "lambda=0.021, Training Accuracy=0.6824571207496883, Testing Accuracy=0.6781431334622824\n",
      "lambda=0.022, Training Accuracy=0.6824284629382854, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.022, Training Accuracy=0.6824857785610913, Testing Accuracy=0.6781431334622824\n",
      "lambda=0.022, Training Accuracy=0.6825001074667928, Testing Accuracy=0.6778852353320438\n",
      "lambda=0.022, Training Accuracy=0.6825574230895987, Testing Accuracy=0.6778852353320438\n",
      "lambda=0.022, Training Accuracy=0.6825287652781957, Testing Accuracy=0.6782720825274017\n",
      "lambda=0.022, Training Accuracy=0.6824284629382854, Testing Accuracy=0.6785299806576403\n",
      "lambda=0.022, Training Accuracy=0.6822995027869722, Testing Accuracy=0.6785299806576403\n",
      "lambda=0.022, Training Accuracy=0.6822135293527634, Testing Accuracy=0.6785299806576403\n",
      "lambda=0.022, Training Accuracy=0.682141884824256, Testing Accuracy=0.678401031592521\n",
      "lambda=0.022, Training Accuracy=0.6820702402957486, Testing Accuracy=0.6781431334622824\n",
      "lambda=0.023, Training Accuracy=0.6820559113900472, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.023, Training Accuracy=0.6819699379558383, Testing Accuracy=0.6781431334622824\n",
      "lambda=0.023, Training Accuracy=0.6819556090501369, Testing Accuracy=0.6782720825274017\n",
      "lambda=0.023, Training Accuracy=0.6818123199931221, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.023, Training Accuracy=0.6817693332760177, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.023, Training Accuracy=0.6816833598418088, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.023, Training Accuracy=0.6816117153133016, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.023, Training Accuracy=0.6814970840676897, Testing Accuracy=0.6781431334622824\n",
      "lambda=0.023, Training Accuracy=0.6814684262562868, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.023, Training Accuracy=0.6814397684448839, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.024, Training Accuracy=0.6812964793878692, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.024, Training Accuracy=0.6812391637650632, Testing Accuracy=0.6780141843971631\n",
      "lambda=0.024, Training Accuracy=0.6811531903308544, Testing Accuracy=0.6776273372018052\n",
      "lambda=0.024, Training Accuracy=0.6810958747080486, Testing Accuracy=0.6777562862669245\n",
      "lambda=0.024, Training Accuracy=0.6811245325194515, Testing Accuracy=0.6777562862669245\n",
      "lambda=0.024, Training Accuracy=0.6810099012738398, Testing Accuracy=0.6776273372018052\n",
      "lambda=0.024, Training Accuracy=0.6809239278396308, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.024, Training Accuracy=0.6808092965940191, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.024, Training Accuracy=0.6807376520655117, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.024, Training Accuracy=0.6806516786313029, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.025, Training Accuracy=0.6805227184799897, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.025, Training Accuracy=0.6804367450457809, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.025, Training Accuracy=0.6803077848944676, Testing Accuracy=0.6774983881366861\n",
      "lambda=0.025, Training Accuracy=0.680322113800169, Testing Accuracy=0.6774983881366861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.025, Training Accuracy=0.6802361403659603, Testing Accuracy=0.6773694390715668\n",
      "lambda=0.025, Training Accuracy=0.6802361403659603, Testing Accuracy=0.6773694390715668\n",
      "lambda=0.025, Training Accuracy=0.6801788247431544, Testing Accuracy=0.6773694390715668\n",
      "lambda=0.025, Training Accuracy=0.680107180214647, Testing Accuracy=0.6773694390715668\n",
      "lambda=0.025, Training Accuracy=0.6800212067804382, Testing Accuracy=0.6773694390715668\n",
      "lambda=0.025, Training Accuracy=0.6799782200633337, Testing Accuracy=0.6768536428110896\n",
      "lambda=0.026, Training Accuracy=0.6799925489690353, Testing Accuracy=0.676595744680851\n",
      "lambda=0.026, Training Accuracy=0.6799782200633337, Testing Accuracy=0.676595744680851\n",
      "lambda=0.026, Training Accuracy=0.6799352333462293, Testing Accuracy=0.6764667956157318\n",
      "lambda=0.026, Training Accuracy=0.6797919442892146, Testing Accuracy=0.676595744680851\n",
      "lambda=0.026, Training Accuracy=0.6797202997607072, Testing Accuracy=0.676595744680851\n",
      "lambda=0.026, Training Accuracy=0.6797202997607072, Testing Accuracy=0.676595744680851\n",
      "lambda=0.026, Training Accuracy=0.6796343263264985, Testing Accuracy=0.676595744680851\n",
      "lambda=0.026, Training Accuracy=0.6795340239865881, Testing Accuracy=0.6764667956157318\n",
      "lambda=0.026, Training Accuracy=0.6794910372694837, Testing Accuracy=0.6764667956157318\n",
      "lambda=0.026, Training Accuracy=0.6794337216466778, Testing Accuracy=0.6764667956157318\n",
      "lambda=0.027, Training Accuracy=0.679376406023872, Testing Accuracy=0.6763378465506125\n",
      "lambda=0.027, Training Accuracy=0.6793334193067675, Testing Accuracy=0.6763378465506125\n",
      "lambda=0.027, Training Accuracy=0.6792044591554542, Testing Accuracy=0.6763378465506125\n",
      "lambda=0.027, Training Accuracy=0.679132814626947, Testing Accuracy=0.6764667956157318\n",
      "lambda=0.027, Training Accuracy=0.6790611700984396, Testing Accuracy=0.6763378465506125\n",
      "lambda=0.027, Training Accuracy=0.6790038544756337, Testing Accuracy=0.6763378465506125\n",
      "lambda=0.027, Training Accuracy=0.6789751966642308, Testing Accuracy=0.6762088974854932\n",
      "lambda=0.027, Training Accuracy=0.6789322099471263, Testing Accuracy=0.6759509993552547\n",
      "lambda=0.027, Training Accuracy=0.6788748943243205, Testing Accuracy=0.676079948420374\n",
      "lambda=0.027, Training Accuracy=0.6787889208901117, Testing Accuracy=0.676079948420374\n",
      "lambda=0.028, Training Accuracy=0.6787745919844101, Testing Accuracy=0.6762088974854932\n",
      "lambda=0.028, Training Accuracy=0.6786456318330969, Testing Accuracy=0.676079948420374\n",
      "lambda=0.028, Training Accuracy=0.6785596583988881, Testing Accuracy=0.676079948420374\n",
      "lambda=0.028, Training Accuracy=0.6785023427760822, Testing Accuracy=0.676079948420374\n",
      "lambda=0.028, Training Accuracy=0.6783877115304704, Testing Accuracy=0.6758220502901354\n",
      "lambda=0.028, Training Accuracy=0.6782444224734557, Testing Accuracy=0.676079948420374\n",
      "lambda=0.028, Training Accuracy=0.6781871068506499, Testing Accuracy=0.6759509993552547\n",
      "lambda=0.028, Training Accuracy=0.6782444224734557, Testing Accuracy=0.6759509993552547\n",
      "lambda=0.028, Training Accuracy=0.6782014357563513, Testing Accuracy=0.6758220502901354\n",
      "lambda=0.028, Training Accuracy=0.6782014357563513, Testing Accuracy=0.6758220502901354\n",
      "lambda=0.029, Training Accuracy=0.6781154623221425, Testing Accuracy=0.6756931012250161\n",
      "lambda=0.029, Training Accuracy=0.678072475605038, Testing Accuracy=0.6754352030947776\n",
      "lambda=0.029, Training Accuracy=0.6779721732651277, Testing Accuracy=0.6753062540296583\n",
      "lambda=0.029, Training Accuracy=0.6778145553024115, Testing Accuracy=0.675177304964539\n",
      "lambda=0.029, Training Accuracy=0.6777285818682027, Testing Accuracy=0.6750483558994197\n",
      "lambda=0.029, Training Accuracy=0.6776855951510983, Testing Accuracy=0.6749194068343004\n",
      "lambda=0.029, Training Accuracy=0.6776569373396953, Testing Accuracy=0.6749194068343004\n",
      "lambda=0.029, Training Accuracy=0.6775709639054865, Testing Accuracy=0.6747904577691812\n",
      "lambda=0.029, Training Accuracy=0.6775279771883821, Testing Accuracy=0.6747904577691812\n",
      "lambda=0.029, Training Accuracy=0.6775136482826807, Testing Accuracy=0.6746615087040619\n",
      "lambda=0.030, Training Accuracy=0.6774563326598748, Testing Accuracy=0.6746615087040619\n",
      "lambda=0.030, Training Accuracy=0.6773703592256659, Testing Accuracy=0.6745325596389427\n",
      "lambda=0.030, Training Accuracy=0.6773560303199645, Testing Accuracy=0.6744036105738234\n",
      "lambda=0.030, Training Accuracy=0.677341701414263, Testing Accuracy=0.6741457124435848\n",
      "lambda=0.030, Training Accuracy=0.6772413990743527, Testing Accuracy=0.6741457124435848\n",
      "lambda=0.000, Training Accuracy=0.7369488983480735, Testing Accuracy=0.722707423580786\n",
      "lambda=0.000, Training Accuracy=0.7185770053593877, Testing Accuracy=0.704049225883287\n",
      "lambda=0.000, Training Accuracy=0.7170110937120928, Testing Accuracy=0.7062326319968242\n",
      "lambda=0.000, Training Accuracy=0.7164817714651198, Testing Accuracy=0.7060341405319571\n",
      "lambda=0.000, Training Accuracy=0.7164156061842483, Testing Accuracy=0.703652242953553\n",
      "lambda=0.001, Training Accuracy=0.7159745043117708, Testing Accuracy=0.70385073441842\n",
      "lambda=0.001, Training Accuracy=0.7157098431882843, Testing Accuracy=0.7046447002778881\n",
      "lambda=0.001, Training Accuracy=0.7156436779074127, Testing Accuracy=0.7046447002778881\n",
      "lambda=0.001, Training Accuracy=0.7157318982819082, Testing Accuracy=0.7046447002778881\n",
      "lambda=0.001, Training Accuracy=0.7155554575329173, Testing Accuracy=0.703255260023819\n",
      "lambda=0.001, Training Accuracy=0.7150923005668159, Testing Accuracy=0.7034537514886859\n",
      "lambda=0.001, Training Accuracy=0.715070245473192, Testing Accuracy=0.703652242953553\n",
      "lambda=0.001, Training Accuracy=0.7148496945369534, Testing Accuracy=0.703255260023819\n",
      "lambda=0.001, Training Accuracy=0.7151805209413113, Testing Accuracy=0.703255260023819\n",
      "lambda=0.001, Training Accuracy=0.715246686222183, Testing Accuracy=0.7030567685589519\n",
      "lambda=0.002, Training Accuracy=0.7152907964094307, Testing Accuracy=0.7026597856292179\n",
      "lambda=0.002, Training Accuracy=0.715246686222183, Testing Accuracy=0.703255260023819\n",
      "lambda=0.002, Training Accuracy=0.7152687413158069, Testing Accuracy=0.7030567685589519\n",
      "lambda=0.002, Training Accuracy=0.7153349065966785, Testing Accuracy=0.7030567685589519\n",
      "lambda=0.002, Training Accuracy=0.7153569616903024, Testing Accuracy=0.7030567685589519\n",
      "lambda=0.002, Training Accuracy=0.7152246311285592, Testing Accuracy=0.7024612941643509\n",
      "lambda=0.002, Training Accuracy=0.7153128515030547, Testing Accuracy=0.7026597856292179\n",
      "lambda=0.002, Training Accuracy=0.715246686222183, Testing Accuracy=0.7026597856292179\n",
      "lambda=0.002, Training Accuracy=0.7151805209413113, Testing Accuracy=0.703255260023819\n",
      "lambda=0.002, Training Accuracy=0.7149158598178249, Testing Accuracy=0.702858277094085\n",
      "lambda=0.003, Training Accuracy=0.7150261352859443, Testing Accuracy=0.7030567685589519\n",
      "lambda=0.003, Training Accuracy=0.7148276394433294, Testing Accuracy=0.70385073441842\n",
      "lambda=0.003, Training Accuracy=0.7146511986943385, Testing Accuracy=0.70385073441842\n",
      "lambda=0.003, Training Accuracy=0.7146732537879623, Testing Accuracy=0.7042477173481541\n",
      "lambda=0.003, Training Accuracy=0.7145850334134668, Testing Accuracy=0.704446208813021\n",
      "lambda=0.003, Training Accuracy=0.7143203722899804, Testing Accuracy=0.7042477173481541\n",
      "lambda=0.003, Training Accuracy=0.7141218764473655, Testing Accuracy=0.7046447002778881\n",
      "lambda=0.003, Training Accuracy=0.7141218764473655, Testing Accuracy=0.7048431917427551\n",
      "lambda=0.003, Training Accuracy=0.7140777662601178, Testing Accuracy=0.7048431917427551\n",
      "lambda=0.003, Training Accuracy=0.7140336560728701, Testing Accuracy=0.7046447002778881\n",
      "lambda=0.004, Training Accuracy=0.7137469398557597, Testing Accuracy=0.7048431917427551\n",
      "lambda=0.004, Training Accuracy=0.7138351602302552, Testing Accuracy=0.704049225883287\n",
      "lambda=0.004, Training Accuracy=0.7137689949493835, Testing Accuracy=0.703652242953553\n",
      "lambda=0.004, Training Accuracy=0.7137248847621358, Testing Accuracy=0.7034537514886859\n",
      "lambda=0.004, Training Accuracy=0.7136366643876403, Testing Accuracy=0.703255260023819\n",
      "lambda=0.004, Training Accuracy=0.7134602236386494, Testing Accuracy=0.703255260023819\n",
      "lambda=0.004, Training Accuracy=0.7133940583577777, Testing Accuracy=0.702858277094085\n",
      "lambda=0.004, Training Accuracy=0.7134161134514017, Testing Accuracy=0.702858277094085\n",
      "lambda=0.004, Training Accuracy=0.7133058379832823, Testing Accuracy=0.7026597856292179\n",
      "lambda=0.004, Training Accuracy=0.7131073421406674, Testing Accuracy=0.7026597856292179\n",
      "lambda=0.005, Training Accuracy=0.7130632319534197, Testing Accuracy=0.7020643112346169\n",
      "lambda=0.005, Training Accuracy=0.7129088462980525, Testing Accuracy=0.7022628026994839\n",
      "lambda=0.005, Training Accuracy=0.7129750115789242, Testing Accuracy=0.7020643112346169\n",
      "lambda=0.005, Training Accuracy=0.7127985708299331, Testing Accuracy=0.7018658197697499\n",
      "lambda=0.005, Training Accuracy=0.7126882953618138, Testing Accuracy=0.7012703453751489\n",
      "lambda=0.005, Training Accuracy=0.7127324055490616, Testing Accuracy=0.7014688368400159\n",
      "lambda=0.005, Training Accuracy=0.7126882953618138, Testing Accuracy=0.7020643112346169\n",
      "lambda=0.005, Training Accuracy=0.7124236342383273, Testing Accuracy=0.7018658197697499\n",
      "lambda=0.005, Training Accuracy=0.7122913036765841, Testing Accuracy=0.7020643112346169\n",
      "lambda=0.005, Training Accuracy=0.7121148629275931, Testing Accuracy=0.7024612941643509\n",
      "lambda=0.006, Training Accuracy=0.7120486976467215, Testing Accuracy=0.7020643112346169\n",
      "lambda=0.006, Training Accuracy=0.7119163670849783, Testing Accuracy=0.7022628026994839\n",
      "lambda=0.006, Training Accuracy=0.7117840365232351, Testing Accuracy=0.7024612941643509\n",
      "lambda=0.006, Training Accuracy=0.7117399263359873, Testing Accuracy=0.7024612941643509\n",
      "lambda=0.006, Training Accuracy=0.7114973203061247, Testing Accuracy=0.7024612941643509\n",
      "lambda=0.006, Training Accuracy=0.7114090999316293, Testing Accuracy=0.7022628026994839\n",
      "lambda=0.006, Training Accuracy=0.7111885489953905, Testing Accuracy=0.7022628026994839\n",
      "lambda=0.006, Training Accuracy=0.7111664939017666, Testing Accuracy=0.7012703453751489\n",
      "lambda=0.006, Training Accuracy=0.7110782735272712, Testing Accuracy=0.7004763795156809\n",
      "lambda=0.006, Training Accuracy=0.710923887871904, Testing Accuracy=0.7000793965859468\n",
      "lambda=0.007, Training Accuracy=0.7108577225910324, Testing Accuracy=0.6996824136562128\n",
      "lambda=0.007, Training Accuracy=0.7107033369356653, Testing Accuracy=0.6996824136562128\n",
      "lambda=0.007, Training Accuracy=0.7105489512802982, Testing Accuracy=0.6990869392616118\n",
      "lambda=0.007, Training Accuracy=0.7105268961866743, Testing Accuracy=0.6990869392616118\n",
      "lambda=0.007, Training Accuracy=0.7103945656249311, Testing Accuracy=0.6988884477967447\n",
      "lambda=0.007, Training Accuracy=0.71021812487594, Testing Accuracy=0.6988884477967447\n",
      "lambda=0.007, Training Accuracy=0.7101740146886923, Testing Accuracy=0.6986899563318777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.007, Training Accuracy=0.7100857943141968, Testing Accuracy=0.6982929734021437\n",
      "lambda=0.007, Training Accuracy=0.7099975739397014, Testing Accuracy=0.6984914648670107\n",
      "lambda=0.007, Training Accuracy=0.7101078494078208, Testing Accuracy=0.6978959904724097\n",
      "lambda=0.008, Training Accuracy=0.709887298471582, Testing Accuracy=0.6978959904724097\n",
      "lambda=0.008, Training Accuracy=0.7098431882843342, Testing Accuracy=0.6980944819372767\n",
      "lambda=0.008, Training Accuracy=0.7098652433779581, Testing Accuracy=0.6978959904724097\n",
      "lambda=0.008, Training Accuracy=0.7097329128162149, Testing Accuracy=0.6969035331480746\n",
      "lambda=0.008, Training Accuracy=0.7097549679098388, Testing Accuracy=0.6971020246129417\n",
      "lambda=0.008, Training Accuracy=0.709710857722591, Testing Accuracy=0.6967050416832076\n",
      "lambda=0.008, Training Accuracy=0.7096888026289672, Testing Accuracy=0.6967050416832076\n",
      "lambda=0.008, Training Accuracy=0.7097329128162149, Testing Accuracy=0.6963080587534736\n",
      "lambda=0.008, Training Accuracy=0.709710857722591, Testing Accuracy=0.6963080587534736\n",
      "lambda=0.008, Training Accuracy=0.7095785271608478, Testing Accuracy=0.6959110758237396\n",
      "lambda=0.009, Training Accuracy=0.7095564720672239, Testing Accuracy=0.6959110758237396\n",
      "lambda=0.009, Training Accuracy=0.7096226373480955, Testing Accuracy=0.6959110758237396\n",
      "lambda=0.009, Training Accuracy=0.7096888026289672, Testing Accuracy=0.6957125843588726\n",
      "lambda=0.009, Training Accuracy=0.7096888026289672, Testing Accuracy=0.6961095672886066\n",
      "lambda=0.009, Training Accuracy=0.7095785271608478, Testing Accuracy=0.6961095672886066\n",
      "lambda=0.009, Training Accuracy=0.7094020864118569, Testing Accuracy=0.6953156014291385\n",
      "lambda=0.009, Training Accuracy=0.7094020864118569, Testing Accuracy=0.6951171099642716\n",
      "lambda=0.009, Training Accuracy=0.7092477007564897, Testing Accuracy=0.6949186184994045\n",
      "lambda=0.009, Training Accuracy=0.7091374252883703, Testing Accuracy=0.6947201270345376\n",
      "lambda=0.009, Training Accuracy=0.7091594803819942, Testing Accuracy=0.6947201270345376\n",
      "lambda=0.009, Training Accuracy=0.7089168743521316, Testing Accuracy=0.6947201270345376\n",
      "lambda=0.010, Training Accuracy=0.7088948192585077, Testing Accuracy=0.6943231441048034\n",
      "lambda=0.010, Training Accuracy=0.7088065988840123, Testing Accuracy=0.6941246526399365\n",
      "lambda=0.010, Training Accuracy=0.708674268322269, Testing Accuracy=0.6939261611750694\n",
      "lambda=0.010, Training Accuracy=0.708696323415893, Testing Accuracy=0.6939261611750694\n",
      "lambda=0.010, Training Accuracy=0.7085419377605258, Testing Accuracy=0.6939261611750694\n",
      "lambda=0.010, Training Accuracy=0.7084537173860304, Testing Accuracy=0.6933306867804684\n",
      "lambda=0.010, Training Accuracy=0.7082552215434155, Testing Accuracy=0.6935291782453354\n",
      "lambda=0.010, Training Accuracy=0.7082772766370393, Testing Accuracy=0.6933306867804684\n",
      "lambda=0.010, Training Accuracy=0.7082331664497916, Testing Accuracy=0.6931321953156014\n",
      "lambda=0.011, Training Accuracy=0.7080787807944244, Testing Accuracy=0.6931321953156014\n",
      "lambda=0.011, Training Accuracy=0.7080787807944244, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.011, Training Accuracy=0.7081228909816722, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.011, Training Accuracy=0.7080346706071767, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.011, Training Accuracy=0.7079685053263051, Testing Accuracy=0.6933306867804684\n",
      "lambda=0.011, Training Accuracy=0.7077700094836903, Testing Accuracy=0.6935291782453354\n",
      "lambda=0.011, Training Accuracy=0.7078361747645618, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.011, Training Accuracy=0.7077700094836903, Testing Accuracy=0.6933306867804684\n",
      "lambda=0.011, Training Accuracy=0.7075935687346993, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.011, Training Accuracy=0.7075494585474515, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.011, Training Accuracy=0.7075715136410754, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.012, Training Accuracy=0.7075494585474515, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.012, Training Accuracy=0.707461238172956, Testing Accuracy=0.6931321953156014\n",
      "lambda=0.012, Training Accuracy=0.7073730177984605, Testing Accuracy=0.6931321953156014\n",
      "lambda=0.012, Training Accuracy=0.7072847974239651, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.012, Training Accuracy=0.7072406872367173, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.012, Training Accuracy=0.7071965770494696, Testing Accuracy=0.6925367209210004\n",
      "lambda=0.012, Training Accuracy=0.7070863015813502, Testing Accuracy=0.6923382294561334\n",
      "lambda=0.012, Training Accuracy=0.7071745219558457, Testing Accuracy=0.6925367209210004\n",
      "lambda=0.012, Training Accuracy=0.7070863015813502, Testing Accuracy=0.6923382294561334\n",
      "lambda=0.013, Training Accuracy=0.7070201363004786, Testing Accuracy=0.6923382294561334\n",
      "lambda=0.013, Training Accuracy=0.7068216404578638, Testing Accuracy=0.6921397379912664\n",
      "lambda=0.013, Training Accuracy=0.7067554751769921, Testing Accuracy=0.6921397379912664\n",
      "lambda=0.013, Training Accuracy=0.7066451997088727, Testing Accuracy=0.6925367209210004\n",
      "lambda=0.013, Training Accuracy=0.7065349242407534, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.013, Training Accuracy=0.7065349242407534, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.013, Training Accuracy=0.7064908140535057, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.013, Training Accuracy=0.7065569793343772, Testing Accuracy=0.6925367209210004\n",
      "lambda=0.013, Training Accuracy=0.7066672548024966, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.013, Training Accuracy=0.7065128691471295, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.013, Training Accuracy=0.7064687589598818, Testing Accuracy=0.6929337038507344\n",
      "lambda=0.014, Training Accuracy=0.7063805385853863, Testing Accuracy=0.6931321953156014\n",
      "lambda=0.014, Training Accuracy=0.7062923182108908, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.014, Training Accuracy=0.7063143733045146, Testing Accuracy=0.6927352123858674\n",
      "lambda=0.014, Training Accuracy=0.7062702631172669, Testing Accuracy=0.6923382294561334\n",
      "lambda=0.014, Training Accuracy=0.7062040978363953, Testing Accuracy=0.6923382294561334\n",
      "lambda=0.014, Training Accuracy=0.7060497121810282, Testing Accuracy=0.6921397379912664\n",
      "lambda=0.014, Training Accuracy=0.7061158774618999, Testing Accuracy=0.6921397379912664\n",
      "lambda=0.014, Training Accuracy=0.706093822368276, Testing Accuracy=0.6919412465263993\n",
      "lambda=0.014, Training Accuracy=0.7060056019937805, Testing Accuracy=0.6917427550615324\n",
      "lambda=0.015, Training Accuracy=0.7059394367129088, Testing Accuracy=0.6917427550615324\n",
      "lambda=0.015, Training Accuracy=0.7059394367129088, Testing Accuracy=0.6915442635966653\n",
      "lambda=0.015, Training Accuracy=0.7059394367129088, Testing Accuracy=0.6915442635966653\n",
      "lambda=0.015, Training Accuracy=0.7060056019937805, Testing Accuracy=0.6915442635966653\n",
      "lambda=0.015, Training Accuracy=0.7060056019937805, Testing Accuracy=0.6913457721317984\n",
      "lambda=0.015, Training Accuracy=0.7059835469001566, Testing Accuracy=0.6913457721317984\n",
      "lambda=0.015, Training Accuracy=0.7059394367129088, Testing Accuracy=0.6907502977371973\n",
      "lambda=0.015, Training Accuracy=0.7059614918065327, Testing Accuracy=0.6905518062723303\n",
      "lambda=0.015, Training Accuracy=0.705917381619285, Testing Accuracy=0.6905518062723303\n",
      "lambda=0.015, Training Accuracy=0.7058953265256611, Testing Accuracy=0.6901548233425963\n",
      "lambda=0.015, Training Accuracy=0.7056968306830462, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.016, Training Accuracy=0.7055865552149269, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.016, Training Accuracy=0.7056747755894224, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.016, Training Accuracy=0.7055424450276792, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.016, Training Accuracy=0.7055865552149269, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.016, Training Accuracy=0.7056306654021747, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.016, Training Accuracy=0.7055203899340553, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.016, Training Accuracy=0.7054321695595598, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.016, Training Accuracy=0.705211618623321, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.016, Training Accuracy=0.7051675084360733, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7050131227807062, Testing Accuracy=0.6885668916236601\n",
      "lambda=0.017, Training Accuracy=0.7049469574998346, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7049249024062108, Testing Accuracy=0.6885668916236601\n",
      "lambda=0.017, Training Accuracy=0.7048807922189629, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7049249024062108, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7049028473125868, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7047705167508436, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7047925718444675, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.017, Training Accuracy=0.7047484616572197, Testing Accuracy=0.6885668916236601\n",
      "lambda=0.017, Training Accuracy=0.704704351469972, Testing Accuracy=0.6887653830885272\n",
      "lambda=0.018, Training Accuracy=0.704704351469972, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.018, Training Accuracy=0.7047925718444675, Testing Accuracy=0.6889638745533943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.018, Training Accuracy=0.704704351469972, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.018, Training Accuracy=0.7047264065635959, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.018, Training Accuracy=0.7046381861891003, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.018, Training Accuracy=0.7046602412827242, Testing Accuracy=0.6889638745533943\n",
      "lambda=0.018, Training Accuracy=0.7046161310954765, Testing Accuracy=0.6881699086939261\n",
      "lambda=0.018, Training Accuracy=0.704527910720981, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.018, Training Accuracy=0.7044617454401094, Testing Accuracy=0.6883684001587932\n",
      "lambda=0.018, Training Accuracy=0.7044617454401094, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.019, Training Accuracy=0.70435146997199, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.019, Training Accuracy=0.7042632495974945, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.019, Training Accuracy=0.704175029222999, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.019, Training Accuracy=0.7040426986612558, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.019, Training Accuracy=0.7040426986612558, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.019, Training Accuracy=0.7040206435676319, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.019, Training Accuracy=0.7039544782867603, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.019, Training Accuracy=0.70366776206965, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.019, Training Accuracy=0.7035574866015306, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.019, Training Accuracy=0.7035133764142829, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.019, Training Accuracy=0.7034472111334112, Testing Accuracy=0.6873759428344581\n",
      "lambda=0.020, Training Accuracy=0.7034251560397874, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.020, Training Accuracy=0.7034251560397874, Testing Accuracy=0.6883684001587932\n",
      "lambda=0.020, Training Accuracy=0.7033369356652919, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.020, Training Accuracy=0.7032928254780442, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.020, Training Accuracy=0.7034251560397874, Testing Accuracy=0.6873759428344581\n",
      "lambda=0.020, Training Accuracy=0.7033369356652919, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.020, Training Accuracy=0.7033810458525397, Testing Accuracy=0.6871774513695911\n",
      "lambda=0.020, Training Accuracy=0.7033589907589157, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.020, Training Accuracy=0.7032266601971725, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.021, Training Accuracy=0.7032707703844203, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.021, Training Accuracy=0.7031163847290531, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.021, Training Accuracy=0.7029840541673099, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.021, Training Accuracy=0.7028958337928144, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.021, Training Accuracy=0.7028296685119428, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.021, Training Accuracy=0.7027193930438235, Testing Accuracy=0.6883684001587932\n",
      "lambda=0.021, Training Accuracy=0.7027635032310712, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.021, Training Accuracy=0.702631172669328, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.021, Training Accuracy=0.7026532277629518, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.021, Training Accuracy=0.7024988421075847, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.022, Training Accuracy=0.7024106217330892, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.022, Training Accuracy=0.7023885666394654, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.022, Training Accuracy=0.7023665115458415, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.022, Training Accuracy=0.7023003462649698, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.022, Training Accuracy=0.7021900707968506, Testing Accuracy=0.6871774513695911\n",
      "lambda=0.022, Training Accuracy=0.7021900707968506, Testing Accuracy=0.6873759428344581\n",
      "lambda=0.022, Training Accuracy=0.7022341809840983, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.022, Training Accuracy=0.7021459606096028, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.022, Training Accuracy=0.7021459606096028, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.022, Training Accuracy=0.7020136300478595, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.023, Training Accuracy=0.7019474647669879, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.023, Training Accuracy=0.701925409673364, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.023, Training Accuracy=0.7018592443924925, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.023, Training Accuracy=0.7018592443924925, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.023, Training Accuracy=0.7018151342052447, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.023, Training Accuracy=0.7016607485498776, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.023, Training Accuracy=0.7015063628945105, Testing Accuracy=0.6875744342993251\n",
      "lambda=0.023, Training Accuracy=0.7015504730817582, Testing Accuracy=0.6877729257641921\n",
      "lambda=0.023, Training Accuracy=0.7015504730817582, Testing Accuracy=0.6879714172290592\n",
      "lambda=0.023, Training Accuracy=0.7015504730817582, Testing Accuracy=0.6871774513695911\n",
      "lambda=0.024, Training Accuracy=0.7015504730817582, Testing Accuracy=0.6871774513695911\n",
      "lambda=0.024, Training Accuracy=0.7015945832690059, Testing Accuracy=0.6871774513695911\n",
      "lambda=0.024, Training Accuracy=0.7016828036435014, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.024, Training Accuracy=0.7015504730817582, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.024, Training Accuracy=0.7015725281753821, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.024, Training Accuracy=0.7015504730817582, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.024, Training Accuracy=0.7015063628945105, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.024, Training Accuracy=0.7015945832690059, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.024, Training Accuracy=0.7014401976136388, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.024, Training Accuracy=0.701418142520015, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.025, Training Accuracy=0.7012637568646479, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.025, Training Accuracy=0.7011975915837763, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.025, Training Accuracy=0.7010873161156569, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.025, Training Accuracy=0.701065261022033, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.025, Training Accuracy=0.7010432059284092, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.025, Training Accuracy=0.700910875366666, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.025, Training Accuracy=0.7008447100857943, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.025, Training Accuracy=0.7007785448049227, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.025, Training Accuracy=0.7007564897112988, Testing Accuracy=0.6871774513695911\n",
      "lambda=0.025, Training Accuracy=0.7006903244304272, Testing Accuracy=0.6869789599047241\n",
      "lambda=0.026, Training Accuracy=0.7006462142431794, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.026, Training Accuracy=0.7004477184005646, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.026, Training Accuracy=0.700557993868684, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.026, Training Accuracy=0.7006021040559317, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.026, Training Accuracy=0.7006241591495556, Testing Accuracy=0.6867804684398571\n",
      "lambda=0.026, Training Accuracy=0.7006021040559317, Testing Accuracy=0.6865819769749901\n",
      "lambda=0.026, Training Accuracy=0.7006682693368034, Testing Accuracy=0.6863834855101231\n",
      "lambda=0.026, Training Accuracy=0.7006021040559317, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.026, Training Accuracy=0.7004697734941885, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.026, Training Accuracy=0.7004697734941885, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.7004918285878123, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.7004256633069408, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.7004256633069408, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.7001610021834542, Testing Accuracy=0.685788011115522\n",
      "lambda=0.027, Training Accuracy=0.7000948369025827, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.7000507267153349, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.700028671621711, Testing Accuracy=0.686184994045256\n",
      "lambda=0.027, Training Accuracy=0.7000066165280872, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.6999183961535916, Testing Accuracy=0.6859865025803891\n",
      "lambda=0.027, Training Accuracy=0.6998522308727201, Testing Accuracy=0.686184994045256\n",
      "lambda=0.028, Training Accuracy=0.6998081206854723, Testing Accuracy=0.686184994045256\n",
      "lambda=0.028, Training Accuracy=0.6997640104982246, Testing Accuracy=0.6863834855101231\n",
      "lambda=0.028, Training Accuracy=0.6997419554046007, Testing Accuracy=0.686184994045256\n",
      "lambda=0.028, Training Accuracy=0.6997199003109769, Testing Accuracy=0.686184994045256\n",
      "lambda=0.028, Training Accuracy=0.699675790123729, Testing Accuracy=0.686184994045256\n",
      "lambda=0.028, Training Accuracy=0.6996096248428575, Testing Accuracy=0.686184994045256\n",
      "lambda=0.028, Training Accuracy=0.6996316799364813, Testing Accuracy=0.6855895196506551\n",
      "lambda=0.028, Training Accuracy=0.6995655146556097, Testing Accuracy=0.685391028185788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.028, Training Accuracy=0.6993890739066188, Testing Accuracy=0.685391028185788\n",
      "lambda=0.028, Training Accuracy=0.6994772942811143, Testing Accuracy=0.685391028185788\n",
      "lambda=0.029, Training Accuracy=0.6994331840938665, Testing Accuracy=0.6855895196506551\n",
      "lambda=0.029, Training Accuracy=0.6994993493747381, Testing Accuracy=0.685391028185788\n",
      "lambda=0.029, Training Accuracy=0.6994993493747381, Testing Accuracy=0.685391028185788\n",
      "lambda=0.029, Training Accuracy=0.6996096248428575, Testing Accuracy=0.685192536720921\n",
      "lambda=0.029, Training Accuracy=0.6995875697492336, Testing Accuracy=0.685192536720921\n",
      "lambda=0.029, Training Accuracy=0.6995655146556097, Testing Accuracy=0.684994045256054\n",
      "lambda=0.029, Training Accuracy=0.699521404468362, Testing Accuracy=0.685192536720921\n",
      "lambda=0.029, Training Accuracy=0.6995655146556097, Testing Accuracy=0.685192536720921\n",
      "lambda=0.029, Training Accuracy=0.6995655146556097, Testing Accuracy=0.684994045256054\n",
      "lambda=0.029, Training Accuracy=0.6994552391874903, Testing Accuracy=0.684795553791187\n",
      "lambda=0.030, Training Accuracy=0.6994331840938665, Testing Accuracy=0.685391028185788\n",
      "lambda=0.030, Training Accuracy=0.6994331840938665, Testing Accuracy=0.685391028185788\n",
      "lambda=0.030, Training Accuracy=0.6993670188129949, Testing Accuracy=0.685391028185788\n",
      "lambda=0.030, Training Accuracy=0.6993670188129949, Testing Accuracy=0.685192536720921\n",
      "lambda=0.030, Training Accuracy=0.6994111290002426, Testing Accuracy=0.6855895196506551\n",
      "lambda=0.000, Training Accuracy=0.7264250263197474, Testing Accuracy=0.7392873252142534\n",
      "lambda=0.000, Training Accuracy=0.7158469945355191, Testing Accuracy=0.7284618854307623\n",
      "lambda=0.000, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.000, Training Accuracy=0.715897127387577, Testing Accuracy=0.7284618854307623\n",
      "lambda=0.000, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.001, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7280108254397835\n",
      "lambda=0.001, Training Accuracy=0.7159472602396351, Testing Accuracy=0.7284618854307623\n",
      "lambda=0.001, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7284618854307623\n",
      "lambda=0.001, Training Accuracy=0.7158469945355191, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.001, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.001, Training Accuracy=0.7155461974231714, Testing Accuracy=0.7298150654036987\n",
      "lambda=0.001, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7298150654036987\n",
      "lambda=0.001, Training Accuracy=0.7156965959793453, Testing Accuracy=0.7298150654036987\n",
      "lambda=0.001, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7298150654036987\n",
      "lambda=0.001, Training Accuracy=0.7155461974231714, Testing Accuracy=0.7298150654036987\n",
      "lambda=0.002, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.002, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.002, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.002, Training Accuracy=0.7153957988669976, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.002, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.002, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7284618854307623\n",
      "lambda=0.002, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.002, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.002, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.002, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.003, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.003, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.003, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.003, Training Accuracy=0.7150448689025919, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.003, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7289129454217411\n",
      "lambda=0.003, Training Accuracy=0.7150448689025919, Testing Accuracy=0.7293640054127198\n",
      "lambda=0.003, Training Accuracy=0.7150448689025919, Testing Accuracy=0.7298150654036987\n",
      "lambda=0.003, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.003, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.003, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.004, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.004, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.004, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.004, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.004, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.004, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.004, Training Accuracy=0.7156464631272873, Testing Accuracy=0.731168245376635\n",
      "lambda=0.004, Training Accuracy=0.7156464631272873, Testing Accuracy=0.731168245376635\n",
      "lambda=0.004, Training Accuracy=0.7156965959793453, Testing Accuracy=0.731168245376635\n",
      "lambda=0.004, Training Accuracy=0.7156464631272873, Testing Accuracy=0.731168245376635\n",
      "lambda=0.005, Training Accuracy=0.7155461974231714, Testing Accuracy=0.731168245376635\n",
      "lambda=0.005, Training Accuracy=0.7155461974231714, Testing Accuracy=0.731168245376635\n",
      "lambda=0.005, Training Accuracy=0.7155461974231714, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.005, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.005, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.005, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.005, Training Accuracy=0.7156965959793453, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.005, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.005, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.005, Training Accuracy=0.715897127387577, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7159472602396351, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.715897127387577, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7158469945355191, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7159472602396351, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.006, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.006, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.006, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156965959793453, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156965959793453, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156965959793453, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.007, Training Accuracy=0.7156965959793453, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7155461974231714, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7155461974231714, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.7158469945355191, Testing Accuracy=0.7302661253946775\n",
      "lambda=0.008, Training Accuracy=0.715897127387577, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.008, Training Accuracy=0.715897127387577, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.715997393091693, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.009, Training Accuracy=0.716047525943751, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.716047525943751, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.7159472602396351, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.7159472602396351, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.009, Training Accuracy=0.716047525943751, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.716047525943751, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.7159472602396351, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.7158469945355191, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.7157968616834611, Testing Accuracy=0.731168245376635\n",
      "lambda=0.009, Training Accuracy=0.7157968616834611, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.010, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.010, Training Accuracy=0.7158469945355191, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.010, Training Accuracy=0.715897127387577, Testing Accuracy=0.731168245376635\n",
      "lambda=0.010, Training Accuracy=0.715897127387577, Testing Accuracy=0.731168245376635\n",
      "lambda=0.010, Training Accuracy=0.7159472602396351, Testing Accuracy=0.731168245376635\n",
      "lambda=0.010, Training Accuracy=0.7159472602396351, Testing Accuracy=0.731168245376635\n",
      "lambda=0.010, Training Accuracy=0.716047525943751, Testing Accuracy=0.731168245376635\n",
      "lambda=0.010, Training Accuracy=0.7160976587958089, Testing Accuracy=0.731168245376635\n",
      "lambda=0.010, Training Accuracy=0.7162480573519827, Testing Accuracy=0.731168245376635\n",
      "lambda=0.011, Training Accuracy=0.7162981902040407, Testing Accuracy=0.731168245376635\n",
      "lambda=0.011, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.011, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.011, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.011, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.011, Training Accuracy=0.7161979244999248, Testing Accuracy=0.731168245376635\n",
      "lambda=0.011, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.011, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.011, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.011, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.011, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.012, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.013, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.013, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.013, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.013, Training Accuracy=0.7161477916478668, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.013, Training Accuracy=0.7160976587958089, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.013, Training Accuracy=0.716047525943751, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.013, Training Accuracy=0.716047525943751, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.013, Training Accuracy=0.716047525943751, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.013, Training Accuracy=0.715997393091693, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.013, Training Accuracy=0.715897127387577, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.013, Training Accuracy=0.715897127387577, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.014, Training Accuracy=0.716047525943751, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.014, Training Accuracy=0.716047525943751, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.014, Training Accuracy=0.7160976587958089, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.014, Training Accuracy=0.7161477916478668, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.014, Training Accuracy=0.7161979244999248, Testing Accuracy=0.731168245376635\n",
      "lambda=0.014, Training Accuracy=0.7161979244999248, Testing Accuracy=0.731168245376635\n",
      "lambda=0.014, Training Accuracy=0.715997393091693, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.014, Training Accuracy=0.715997393091693, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.014, Training Accuracy=0.7159472602396351, Testing Accuracy=0.731168245376635\n",
      "lambda=0.015, Training Accuracy=0.715897127387577, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.015, Training Accuracy=0.715897127387577, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.015, Training Accuracy=0.715997393091693, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.015, Training Accuracy=0.715997393091693, Testing Accuracy=0.731168245376635\n",
      "lambda=0.015, Training Accuracy=0.715997393091693, Testing Accuracy=0.731168245376635\n",
      "lambda=0.015, Training Accuracy=0.7161979244999248, Testing Accuracy=0.731168245376635\n",
      "lambda=0.015, Training Accuracy=0.7162480573519827, Testing Accuracy=0.731168245376635\n",
      "lambda=0.015, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.015, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.015, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.015, Training Accuracy=0.7164987216122726, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.016, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7307171853856563\n",
      "lambda=0.016, Training Accuracy=0.7163483230560986, Testing Accuracy=0.731168245376635\n",
      "lambda=0.016, Training Accuracy=0.7162981902040407, Testing Accuracy=0.731168245376635\n",
      "lambda=0.016, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.016, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.016, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.016, Training Accuracy=0.7164987216122726, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.016, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.016, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.017, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.017, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.017, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.017, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.017, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.017, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.017, Training Accuracy=0.7161979244999248, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.017, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.017, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.017, Training Accuracy=0.7163984559081567, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.018, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.018, Training Accuracy=0.7165488544643305, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.018, Training Accuracy=0.7165488544643305, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.018, Training Accuracy=0.7165488544643305, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.018, Training Accuracy=0.7165488544643305, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.018, Training Accuracy=0.7165488544643305, Testing Accuracy=0.731168245376635\n",
      "lambda=0.018, Training Accuracy=0.7164485887602146, Testing Accuracy=0.731168245376635\n",
      "lambda=0.018, Training Accuracy=0.7163984559081567, Testing Accuracy=0.731168245376635\n",
      "lambda=0.018, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.018, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7164987216122726, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7164485887602146, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7164987216122726, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.019, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7161979244999248, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7163483230560986, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7162981902040407, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7162480573519827, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.020, Training Accuracy=0.7161979244999248, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.021, Training Accuracy=0.7161477916478668, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.021, Training Accuracy=0.716047525943751, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.021, Training Accuracy=0.7160976587958089, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.021, Training Accuracy=0.7159472602396351, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.021, Training Accuracy=0.7158469945355191, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.021, Training Accuracy=0.715897127387577, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.021, Training Accuracy=0.715897127387577, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.021, Training Accuracy=0.715897127387577, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.021, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.021, Training Accuracy=0.7157467288314032, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.022, Training Accuracy=0.7155963302752294, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.022, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.022, Training Accuracy=0.7156464631272873, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.022, Training Accuracy=0.7155461974231714, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.022, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.022, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.022, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.022, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.022, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.022, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7153957988669976, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.023, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7334235453315291\n",
      "lambda=0.023, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7334235453315291\n",
      "lambda=0.023, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7334235453315291\n",
      "lambda=0.023, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7334235453315291\n",
      "lambda=0.024, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7334235453315291\n",
      "lambda=0.024, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7153957988669976, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7154960645711135, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.024, Training Accuracy=0.7154459317190555, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7153957988669976, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.025, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7150950017546498, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7329724853405503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.026, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7329724853405503\n",
      "lambda=0.026, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.026, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.026, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.027, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.027, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.027, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.027, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7325214253495715\n",
      "lambda=0.027, Training Accuracy=0.7151952674587657, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.027, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.027, Training Accuracy=0.7151451346067078, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.027, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.027, Training Accuracy=0.7152454003108237, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.027, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7153957988669976, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7153957988669976, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7152955331628816, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.028, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.029, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.029, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7320703653585927\n",
      "lambda=0.029, Training Accuracy=0.7153456660149395, Testing Accuracy=0.7316193053676139\n",
      "lambda=0.029, Training Accuracy=0.7153456660149395, Testing Accuracy=0.731168245376635\n",
      "lambda=0.029, Training Accuracy=0.7152955331628816, Testing Accuracy=0.731168245376635\n",
      "lambda=0.029, Training Accuracy=0.7152454003108237, Testing Accuracy=0.731168245376635\n",
      "lambda=0.029, Training Accuracy=0.7151952674587657, Testing Accuracy=0.731168245376635\n",
      "lambda=0.029, Training Accuracy=0.7150950017546498, Testing Accuracy=0.731168245376635\n",
      "lambda=0.029, Training Accuracy=0.7151451346067078, Testing Accuracy=0.731168245376635\n",
      "lambda=0.029, Training Accuracy=0.7151451346067078, Testing Accuracy=0.731168245376635\n",
      "lambda=0.030, Training Accuracy=0.7151952674587657, Testing Accuracy=0.731168245376635\n",
      "lambda=0.030, Training Accuracy=0.7152454003108237, Testing Accuracy=0.731168245376635\n",
      "lambda=0.030, Training Accuracy=0.7152454003108237, Testing Accuracy=0.731168245376635\n",
      "lambda=0.030, Training Accuracy=0.7152454003108237, Testing Accuracy=0.731168245376635\n",
      "lambda=0.030, Training Accuracy=0.7151952674587657, Testing Accuracy=0.731168245376635\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#separate data with respect to column 24 and remove None\n",
    "split_x_test, _, split_ids_test =  separate(y_donotUse, tX_test, ids_test)\n",
    "split_x_cleaned_test = removeNone(split_x, dataStatistics(split_x_test))\n",
    "\n",
    "#median instead of None\n",
    "split_x_with_median = putMedianInsteadOfNone(split_x_cleaned_test)\n",
    "\n",
    "#line dropped when None\n",
    "#split_x_drop_lines, split_y_dropped_split_indexes_dropped = dropLineIfNone(split_x_cleaned_test, _, split_ids_test)\n",
    "\n",
    "y_res = []\n",
    "\n",
    "for i in range(4):\n",
    "    w_star, accuracy = crossValidation(cleaned_with_median[i], split_y[i], 0.9, 6)\n",
    "    \n",
    "    y_res.append(predict_labels(w_star, normalize(split_x_with_median[i])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14a4e9702f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/submission.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "\n",
    "y_pred = putTogether(y_res, split_ids_test)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
