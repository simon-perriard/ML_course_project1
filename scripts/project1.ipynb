{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from validation_helpers import *\n",
    "from plots import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_x, split_y, split_ids = separate(y, tX, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics \n",
      "Type :\n",
      "0\n",
      "[0.26145747 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 1.         1.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "1\n",
      "[0.09751883 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "2\n",
      "[0.05859584 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "3\n",
      "[0.0666396 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "selection = dataStatistics(split_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = removeNone(split_x, selection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can either drop the lines with residual Nones or replace the Nones by the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_with_median = putMedianInsteadOfNone(cleaned)\n",
    "\n",
    "cleaned_with_median_with_momentum = add_momentum_vector(cleaned_with_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropped_x, dropped_y, dropped_ids = dropLineIfNone(cleaned, split_y, split_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point, the first values in each of the split data has a PRI_jet_num = 0, then 1 and so on. The data is clean and we can work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "y_donotUse, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics \n",
      "Type :\n",
      "0\n",
      "[0.2605448 0.        0.        0.        1.        1.        1.\n",
      " 0.        0.        0.        0.        0.        1.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        1.        1.        1.        1.        1.\n",
      " 1.        0.       ]\n",
      "Statistics \n",
      "Type :\n",
      "1\n",
      "[0.09834149 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "2\n",
      "[0.05881481 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "3\n",
      "[0.06376737 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "lambda=0.00000,degree=1, gamma=0.01000, Training Loss=16.13397545153902, Testing Loss=16.13397545153902\n",
      "lambda=0.00000,degree=1, gamma=0.21000, Training Loss=7130.089407178776, Testing Loss=7130.089407178776\n",
      "lambda=0.00000,degree=1, gamma=0.41000, Training Loss=27179.502414096638, Testing Loss=27179.502414096638\n",
      "lambda=0.00000,degree=1, gamma=0.61000, Training Loss=60163.922841741514, Testing Loss=60163.922841741514\n",
      "lambda=0.00000,degree=1, gamma=0.81000, Training Loss=106082.90054591344, Testing Loss=106082.90054591344\n",
      "lambda=0.00000,degree=2, gamma=0.01000, Training Loss=16.070494271399493, Testing Loss=16.070494271399493\n",
      "lambda=0.00000,degree=2, gamma=0.21000, Training Loss=7102.08503840607, Testing Loss=7102.08503840607\n",
      "lambda=0.00000,degree=2, gamma=0.41000, Training Loss=27072.756720093435, Testing Loss=27072.756720093435\n",
      "lambda=0.00000,degree=2, gamma=0.61000, Training Loss=59927.63715272719, Testing Loss=59927.63715272719\n",
      "lambda=0.00000,degree=2, gamma=0.81000, Training Loss=105666.27795992445, Testing Loss=105666.27795992445\n",
      "lambda=0.00000,degree=3, gamma=0.01000, Training Loss=15.393146640180639, Testing Loss=15.393146640180639\n",
      "lambda=0.00000,degree=3, gamma=0.21000, Training Loss=6803.40615828984, Testing Loss=6803.40615828984\n",
      "lambda=0.00000,degree=3, gamma=0.41000, Training Loss=25934.271706396215, Testing Loss=25934.271706396215\n",
      "lambda=0.00000,degree=3, gamma=0.61000, Training Loss=57407.56025917582, Testing Loss=57407.56025917582\n",
      "lambda=0.00000,degree=3, gamma=0.81000, Training Loss=101222.84229463851, Testing Loss=101222.84229463851\n",
      "lambda=0.00000,degree=4, gamma=0.01000, Training Loss=15.072777888682944, Testing Loss=15.072777888682944\n",
      "lambda=0.00000,degree=4, gamma=0.21000, Training Loss=6662.14640063427, Testing Loss=6662.14640063427\n",
      "lambda=0.00000,degree=4, gamma=0.41000, Training Loss=25395.827960352824, Testing Loss=25395.827960352824\n",
      "lambda=0.00000,degree=4, gamma=0.61000, Training Loss=56215.69684258364, Testing Loss=56215.69684258364\n",
      "lambda=0.00000,degree=4, gamma=0.81000, Training Loss=99121.3324424561, Testing Loss=99121.3324424561\n",
      "lambda=0.00000,degree=5, gamma=0.01000, Training Loss=14.297456954894464, Testing Loss=14.297456954894464\n",
      "lambda=0.00000,degree=5, gamma=0.21000, Training Loss=6320.333827602721, Testing Loss=6320.333827602721\n",
      "lambda=0.00000,degree=5, gamma=0.41000, Training Loss=24092.934911702567, Testing Loss=24092.934911702567\n",
      "lambda=0.00000,degree=5, gamma=0.61000, Training Loss=53331.701672323834, Testing Loss=53331.701672323834\n",
      "lambda=0.00000,degree=5, gamma=0.81000, Training Loss=94036.23508163392, Testing Loss=94036.23508163392\n",
      "lambda=0.00000,degree=6, gamma=0.01000, Training Loss=13.72422838484303, Testing Loss=13.72422838484303\n",
      "lambda=0.00000,degree=6, gamma=0.21000, Training Loss=6067.55036877794, Testing Loss=6067.55036877794\n",
      "lambda=0.00000,degree=6, gamma=0.41000, Training Loss=23129.389729363662, Testing Loss=23129.389729363662\n",
      "lambda=0.00000,degree=6, gamma=0.61000, Training Loss=51198.85923082248, Testing Loss=51198.85923082248\n",
      "lambda=0.00000,degree=6, gamma=0.81000, Training Loss=90275.57580256916, Testing Loss=90275.57580256916\n",
      "lambda=0.00000,degree=7, gamma=0.01000, Training Loss=12.729555743420212, Testing Loss=12.729555743420212\n",
      "lambda=0.00000,degree=7, gamma=0.21000, Training Loss=5629.020534789566, Testing Loss=5629.020534789566\n",
      "lambda=0.00000,degree=7, gamma=0.41000, Training Loss=21457.836396771603, Testing Loss=21457.836396771603\n",
      "lambda=0.00000,degree=7, gamma=0.61000, Training Loss=47498.821745397465, Testing Loss=47498.821745397465\n",
      "lambda=0.00000,degree=7, gamma=0.81000, Training Loss=83751.62119247789, Testing Loss=83751.62119247789\n",
      "lambda=0.00000,degree=8, gamma=0.01000, Training Loss=9.826820043199165, Testing Loss=9.826820043199165\n",
      "lambda=0.00000,degree=8, gamma=0.21000, Training Loss=4349.017959303516, Testing Loss=4349.017959303516\n",
      "lambda=0.00000,degree=8, gamma=0.41000, Training Loss=16578.799244264643, Testing Loss=16578.799244264643\n",
      "lambda=0.00000,degree=8, gamma=0.61000, Training Loss=36698.89608206029, Testing Loss=36698.89608206029\n",
      "lambda=0.00000,degree=8, gamma=0.81000, Training Loss=64709.03388608484, Testing Loss=64709.03388608484\n",
      "lambda=0.00100,degree=1, gamma=0.01000, Training Loss=16140.745391574292, Testing Loss=16140.745391574292\n",
      "lambda=0.00100,degree=1, gamma=0.21000, Training Loss=7050806.552308865, Testing Loss=7050806.552308865\n",
      "lambda=0.00100,degree=1, gamma=0.41000, Training Loss=26567209.720309634, Testing Loss=26567209.720309634\n",
      "lambda=0.00100,degree=1, gamma=0.61000, Training Loss=58129983.043764845, Testing Loss=58129983.043764845\n",
      "lambda=0.00100,degree=1, gamma=0.81000, Training Loss=101313666.81099968, Testing Loss=101313666.81099968\n",
      "lambda=0.00100,degree=2, gamma=0.01000, Training Loss=16077.237575239906, Testing Loss=16077.237575239906\n",
      "lambda=0.00100,degree=2, gamma=0.21000, Training Loss=7023113.578030669, Testing Loss=7023113.578030669\n",
      "lambda=0.00100,degree=2, gamma=0.41000, Training Loss=26462868.76755015, Testing Loss=26462868.76755015\n",
      "lambda=0.00100,degree=2, gamma=0.61000, Training Loss=57901685.3838618, Testing Loss=57901685.3838618\n",
      "lambda=0.00100,degree=2, gamma=0.81000, Training Loss=100915774.58971827, Testing Loss=100915774.58971827\n",
      "lambda=0.00100,degree=3, gamma=0.01000, Training Loss=15399.605739300328, Testing Loss=15399.605739300328\n",
      "lambda=0.00100,degree=3, gamma=0.21000, Training Loss=6727755.857364016, Testing Loss=6727755.857364016\n",
      "lambda=0.00100,degree=3, gamma=0.41000, Training Loss=25350031.271482136, Testing Loss=25350031.271482136\n",
      "lambda=0.00100,degree=3, gamma=0.61000, Training Loss=55466803.86807309, Testing Loss=55466803.86807309\n",
      "lambda=0.00100,degree=3, gamma=0.81000, Training Loss=96672105.27468258, Testing Loss=96672105.27468258\n",
      "lambda=0.00100,degree=4, gamma=0.01000, Training Loss=15079.102566057698, Testing Loss=15079.102566057698\n",
      "lambda=0.00100,degree=4, gamma=0.21000, Training Loss=6588066.837541275, Testing Loss=6588066.837541275\n",
      "lambda=0.00100,degree=4, gamma=0.41000, Training Loss=24823717.45763469, Testing Loss=24823717.45763469\n",
      "lambda=0.00100,degree=4, gamma=0.61000, Training Loss=54315233.37149966, Testing Loss=54315233.37149966\n",
      "lambda=0.00100,degree=4, gamma=0.81000, Training Loss=94665074.3332155, Testing Loss=94665074.3332155\n",
      "lambda=0.00100,degree=5, gamma=0.01000, Training Loss=14303.45632109415, Testing Loss=14303.45632109415\n",
      "lambda=0.00100,degree=5, gamma=0.21000, Training Loss=6250055.0496999975, Testing Loss=6250055.0496999975\n",
      "lambda=0.00100,degree=5, gamma=0.41000, Training Loss=23550175.674048647, Testing Loss=23550175.674048647\n",
      "lambda=0.00100,degree=5, gamma=0.61000, Training Loss=51528736.44545075, Testing Loss=51528736.44545075\n",
      "lambda=0.00100,degree=5, gamma=0.81000, Training Loss=89808590.92367093, Testing Loss=89808590.92367093\n",
      "lambda=0.00100,degree=6, gamma=0.01000, Training Loss=13729.987232673371, Testing Loss=13729.987232673371\n",
      "lambda=0.00100,degree=6, gamma=0.21000, Training Loss=6000082.416086718, Testing Loss=6000082.416086718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00100,degree=6, gamma=0.41000, Training Loss=22608337.006144874, Testing Loss=22608337.006144874\n",
      "lambda=0.00100,degree=6, gamma=0.61000, Training Loss=49467998.277732804, Testing Loss=49467998.277732804\n",
      "lambda=0.00100,degree=6, gamma=0.81000, Training Loss=86217001.98238134, Testing Loss=86217001.98238134\n",
      "lambda=0.00100,degree=7, gamma=0.01000, Training Loss=12734.897243669657, Testing Loss=12734.897243669657\n",
      "lambda=0.00100,degree=7, gamma=0.21000, Training Loss=5566428.814798247, Testing Loss=5566428.814798247\n",
      "lambda=0.00100,degree=7, gamma=0.41000, Training Loss=20974440.029324137, Testing Loss=20974440.029324137\n",
      "lambda=0.00100,degree=7, gamma=0.61000, Training Loss=45893046.70034401, Testing Loss=45893046.70034401\n",
      "lambda=0.00100,degree=7, gamma=0.81000, Training Loss=79986348.94041297, Testing Loss=79986348.94041297\n",
      "lambda=0.00100,degree=8, gamma=0.01000, Training Loss=9830.943599775544, Testing Loss=9830.943599775544\n",
      "lambda=0.00100,degree=8, gamma=0.21000, Training Loss=4300659.225823837, Testing Loss=4300659.225823837\n",
      "lambda=0.00100,degree=8, gamma=0.41000, Training Loss=16205316.654580547, Testing Loss=16205316.654580547\n",
      "lambda=0.00100,degree=8, gamma=0.61000, Training Loss=35458230.42567823, Testing Loss=35458230.42567823\n",
      "lambda=0.00100,degree=8, gamma=0.81000, Training Loss=61799871.27820824, Testing Loss=61799871.27820824\n",
      "lambda=0.00200,degree=1, gamma=0.01000, Training Loss=32246.658112537334, Testing Loss=32246.658112537334\n",
      "lambda=0.00200,degree=1, gamma=0.21000, Training Loss=13923885.571829889, Testing Loss=13923885.571829889\n",
      "lambda=0.00200,degree=1, gamma=0.41000, Training Loss=51859112.77071701, Testing Loss=51859112.77071701\n",
      "lambda=0.00200,degree=1, gamma=0.61000, Training Loss=112158914.2038711, Testing Loss=112158914.2038711\n",
      "lambda=0.00200,degree=1, gamma=0.81000, Training Loss=193220438.01876134, Testing Loss=193220438.01876134\n",
      "lambda=0.00200,degree=2, gamma=0.01000, Training Loss=32119.77953543265, Testing Loss=32119.77953543265\n",
      "lambda=0.00200,degree=2, gamma=0.21000, Training Loss=13869197.672825493, Testing Loss=13869197.672825493\n",
      "lambda=0.00200,degree=2, gamma=0.41000, Training Loss=51655439.551941045, Testing Loss=51655439.551941045\n",
      "lambda=0.00200,degree=2, gamma=0.61000, Training Loss=111718425.22126715, Testing Loss=111718425.22126715\n",
      "lambda=0.00200,degree=2, gamma=0.81000, Training Loss=192461597.5778214, Testing Loss=192461597.5778214\n",
      "lambda=0.00200,degree=3, gamma=0.01000, Training Loss=30765.978263668963, Testing Loss=30765.978263668963\n",
      "lambda=0.00200,degree=3, gamma=0.21000, Training Loss=13285927.237289984, Testing Loss=13285927.237289984\n",
      "lambda=0.00200,degree=3, gamma=0.41000, Training Loss=49483184.18699387, Testing Loss=49483184.18699387\n",
      "lambda=0.00200,degree=3, gamma=0.61000, Training Loss=107020442.41959627, Testing Loss=107020442.41959627\n",
      "lambda=0.00200,degree=3, gamma=0.81000, Training Loss=184368280.55184802, Testing Loss=184368280.55184802\n",
      "lambda=0.00200,degree=4, gamma=0.01000, Training Loss=30125.663596610026, Testing Loss=30125.663596610026\n",
      "lambda=0.00200,degree=4, gamma=0.21000, Training Loss=13010070.30294725, Testing Loss=13010070.30294725\n",
      "lambda=0.00200,degree=4, gamma=0.41000, Training Loss=48455821.244282104, Testing Loss=48455821.244282104\n",
      "lambda=0.00200,degree=4, gamma=0.61000, Training Loss=104798544.41441214, Testing Loss=104798544.41441214\n",
      "lambda=0.00200,degree=4, gamma=0.81000, Training Loss=180540570.03313452, Testing Loss=180540570.03313452\n",
      "lambda=0.00200,degree=5, gamma=0.01000, Training Loss=28576.045035397266, Testing Loss=28576.045035397266\n",
      "lambda=0.00200,degree=5, gamma=0.21000, Training Loss=12342566.904490167, Testing Loss=12342566.904490167\n",
      "lambda=0.00200,degree=5, gamma=0.41000, Training Loss=45969871.61014551, Testing Loss=45969871.61014551\n",
      "lambda=0.00200,degree=5, gamma=0.61000, Training Loss=99422137.17498313, Testing Loss=99422137.17498313\n",
      "lambda=0.00200,degree=5, gamma=0.81000, Training Loss=171278524.17933494, Testing Loss=171278524.17933494\n",
      "lambda=0.00200,degree=6, gamma=0.01000, Training Loss=27430.344463775575, Testing Loss=27430.344463775575\n",
      "lambda=0.00200,degree=6, gamma=0.21000, Training Loss=11848922.632583229, Testing Loss=11848922.632583229\n",
      "lambda=0.00200,degree=6, gamma=0.41000, Training Loss=44131405.42998036, Testing Loss=44131405.42998036\n",
      "lambda=0.00200,degree=6, gamma=0.61000, Training Loss=95446045.35535313, Testing Loss=95446045.35535313\n",
      "lambda=0.00200,degree=6, gamma=0.81000, Training Loss=164428822.7089878, Testing Loss=164428822.7089878\n",
      "lambda=0.00200,degree=7, gamma=0.01000, Training Loss=25442.311997390072, Testing Loss=25442.311997390072\n",
      "lambda=0.00200,degree=7, gamma=0.21000, Training Loss=10992546.425810346, Testing Loss=10992546.425810346\n",
      "lambda=0.00200,degree=7, gamma=0.41000, Training Loss=40942043.568792805, Testing Loss=40942043.568792805\n",
      "lambda=0.00200,degree=7, gamma=0.61000, Training Loss=88548354.07548818, Testing Loss=88548354.07548818\n",
      "lambda=0.00200,degree=7, gamma=0.81000, Training Loss=152546028.24063942, Testing Loss=152546028.24063942\n",
      "lambda=0.00200,degree=8, gamma=0.01000, Training Loss=19640.671743960524, Testing Loss=19640.671743960524\n",
      "lambda=0.00200,degree=8, gamma=0.21000, Training Loss=8492913.173874058, Testing Loss=8492913.173874058\n",
      "lambda=0.00200,degree=8, gamma=0.41000, Training Loss=31632729.425041724, Testing Loss=31632729.425041724\n",
      "lambda=0.00200,degree=8, gamma=0.61000, Training Loss=68414894.97173075, Testing Loss=68414894.97173075\n",
      "lambda=0.00200,degree=8, gamma=0.81000, Training Loss=117861674.10027811, Testing Loss=117861674.10027811\n",
      "lambda=0.00000,degree=1, gamma=0.01000, Training Loss=11.169790914326752, Testing Loss=11.169790914326752\n",
      "lambda=0.00000,degree=1, gamma=0.21000, Training Loss=4939.283450449679, Testing Loss=4939.283450449679\n",
      "lambda=0.00000,degree=1, gamma=0.41000, Training Loss=18828.553078781173, Testing Loss=18828.553078781173\n",
      "lambda=0.00000,degree=1, gamma=0.61000, Training Loss=41678.666827307134, Testing Loss=41678.666827307134\n",
      "lambda=0.00000,degree=1, gamma=0.81000, Training Loss=73489.31285453592, Testing Loss=73489.31285453592\n",
      "lambda=0.00000,degree=2, gamma=0.01000, Training Loss=11.13972605077394, Testing Loss=11.13972605077394\n",
      "lambda=0.00000,degree=2, gamma=0.21000, Training Loss=4926.014456215528, Testing Loss=4926.014456215528\n",
      "lambda=0.00000,degree=2, gamma=0.41000, Training Loss=18777.974923578033, Testing Loss=18777.974923578033\n",
      "lambda=0.00000,degree=2, gamma=0.61000, Training Loss=41566.71011718167, Testing Loss=41566.71011718167\n",
      "lambda=0.00000,degree=2, gamma=0.81000, Training Loss=73291.9090331608, Testing Loss=73291.9090331608\n",
      "lambda=0.00000,degree=3, gamma=0.01000, Training Loss=10.761758967924505, Testing Loss=10.761758967924505\n",
      "lambda=0.00000,degree=3, gamma=0.21000, Training Loss=4759.3431769548015, Testing Loss=4759.3431769548015\n",
      "lambda=0.00000,degree=3, gamma=0.41000, Training Loss=18142.667978124937, Testing Loss=18142.667978124937\n",
      "lambda=0.00000,degree=3, gamma=0.61000, Training Loss=40160.43567304824, Testing Loss=40160.43567304824\n",
      "lambda=0.00000,degree=3, gamma=0.81000, Training Loss=70812.34577914567, Testing Loss=70812.34577914567\n",
      "lambda=0.00000,degree=4, gamma=0.01000, Training Loss=9.917518212289671, Testing Loss=9.917518212289671\n",
      "lambda=0.00000,degree=4, gamma=0.21000, Training Loss=4387.042855983993, Testing Loss=4387.042855983993\n",
      "lambda=0.00000,degree=4, gamma=0.41000, Training Loss=16723.5546751246, Testing Loss=16723.5546751246\n",
      "lambda=0.00000,degree=4, gamma=0.61000, Training Loss=37019.175988652416, Testing Loss=37019.175988652416\n",
      "lambda=0.00000,degree=4, gamma=0.81000, Training Loss=65273.629815901, Testing Loss=65273.629815901\n",
      "lambda=0.00000,degree=5, gamma=0.01000, Training Loss=8.848759273251405, Testing Loss=8.848759273251405\n",
      "lambda=0.00000,degree=5, gamma=0.21000, Training Loss=3915.8277480732286, Testing Loss=3915.8277480732286\n",
      "lambda=0.00000,degree=5, gamma=0.41000, Training Loss=14927.41219256797, Testing Loss=14927.41219256797\n",
      "lambda=0.00000,degree=5, gamma=0.61000, Training Loss=33043.354852191216, Testing Loss=33043.354852191216\n",
      "lambda=0.00000,degree=5, gamma=0.81000, Training Loss=58263.40849201364, Testing Loss=58263.40849201364\n",
      "lambda=0.00000,degree=6, gamma=0.01000, Training Loss=7.7051213551801085, Testing Loss=7.7051213551801085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00000,degree=6, gamma=0.21000, Training Loss=3411.8247157883266, Testing Loss=3411.8247157883266\n",
      "lambda=0.00000,degree=6, gamma=0.41000, Training Loss=13006.312124023998, Testing Loss=13006.312124023998\n",
      "lambda=0.00000,degree=6, gamma=0.61000, Training Loss=28790.95192100404, Testing Loss=28790.95192100404\n",
      "lambda=0.00000,degree=6, gamma=0.81000, Training Loss=50765.5286865819, Testing Loss=50765.5286865819\n",
      "lambda=0.00000,degree=7, gamma=0.01000, Training Loss=7.158784910136294, Testing Loss=7.158784910136294\n",
      "lambda=0.00000,degree=7, gamma=0.21000, Training Loss=3171.0824041768515, Testing Loss=3171.0824041768515\n",
      "lambda=0.00000,degree=7, gamma=0.41000, Training Loss=12088.68177194678, Testing Loss=12088.68177194678\n",
      "lambda=0.00000,degree=7, gamma=0.61000, Training Loss=26759.756660063875, Testing Loss=26759.756660063875\n",
      "lambda=0.00000,degree=7, gamma=0.81000, Training Loss=47184.106844937225, Testing Loss=47184.106844937225\n",
      "lambda=0.00000,degree=8, gamma=0.01000, Training Loss=6.945618653838199, Testing Loss=6.945618653838199\n",
      "lambda=0.00000,degree=8, gamma=0.21000, Training Loss=3077.400839730834, Testing Loss=3077.400839730834\n",
      "lambda=0.00000,degree=8, gamma=0.41000, Training Loss=11731.622301141379, Testing Loss=11731.622301141379\n",
      "lambda=0.00000,degree=8, gamma=0.61000, Training Loss=25969.415687587414, Testing Loss=25969.415687587414\n",
      "lambda=0.00000,degree=8, gamma=0.81000, Training Loss=45790.586688201176, Testing Loss=45790.586688201176\n",
      "lambda=0.00100,degree=1, gamma=0.01000, Training Loss=11174.477916077807, Testing Loss=11174.477916077807\n",
      "lambda=0.00100,degree=1, gamma=0.21000, Training Loss=4884361.2401939025, Testing Loss=4884361.2401939025\n",
      "lambda=0.00100,degree=1, gamma=0.41000, Training Loss=18404388.496947713, Testing Loss=18404388.496947713\n",
      "lambda=0.00100,degree=1, gamma=0.61000, Training Loss=40269651.59623387, Testing Loss=40269651.59623387\n",
      "lambda=0.00100,degree=1, gamma=0.81000, Training Loss=70185409.3935921, Testing Loss=70185409.3935921\n",
      "lambda=0.00100,degree=2, gamma=0.01000, Training Loss=11144.400437276065, Testing Loss=11144.400437276065\n",
      "lambda=0.00100,degree=2, gamma=0.21000, Training Loss=4871239.790494708, Testing Loss=4871239.790494708\n",
      "lambda=0.00100,degree=2, gamma=0.41000, Training Loss=18354949.75420927, Testing Loss=18354949.75420927\n",
      "lambda=0.00100,degree=2, gamma=0.61000, Training Loss=40161479.76812024, Testing Loss=40161479.76812024\n",
      "lambda=0.00100,degree=2, gamma=0.81000, Training Loss=69996880.38044576, Testing Loss=69996880.38044576\n",
      "lambda=0.00100,degree=3, gamma=0.01000, Training Loss=10766.274764971673, Testing Loss=10766.274764971673\n",
      "lambda=0.00100,degree=3, gamma=0.21000, Training Loss=4706421.812317828, Testing Loss=4706421.812317828\n",
      "lambda=0.00100,degree=3, gamma=0.41000, Training Loss=17733954.851401564, Testing Loss=17733954.851401564\n",
      "lambda=0.00100,degree=3, gamma=0.61000, Training Loss=38802746.763198815, Testing Loss=38802746.763198815\n",
      "lambda=0.00100,degree=3, gamma=0.81000, Training Loss=67628792.4213642, Testing Loss=67628792.4213642\n",
      "lambda=0.00100,degree=4, gamma=0.01000, Training Loss=9921.679778130212, Testing Loss=9921.679778130212\n",
      "lambda=0.00100,degree=4, gamma=0.21000, Training Loss=4338261.284007528, Testing Loss=4338261.284007528\n",
      "lambda=0.00100,degree=4, gamma=0.41000, Training Loss=16346810.991719956, Testing Loss=16346810.991719956\n",
      "lambda=0.00100,degree=4, gamma=0.61000, Training Loss=35767682.568173036, Testing Loss=35767682.568173036\n",
      "lambda=0.00100,degree=4, gamma=0.81000, Training Loss=62339084.01362629, Testing Loss=62339084.01362629\n",
      "lambda=0.00100,degree=5, gamma=0.01000, Training Loss=8852.472405627674, Testing Loss=8852.472405627674\n",
      "lambda=0.00100,degree=5, gamma=0.21000, Training Loss=3872285.85249132, Testing Loss=3872285.85249132\n",
      "lambda=0.00100,degree=5, gamma=0.41000, Training Loss=14591131.578817608, Testing Loss=14591131.578817608\n",
      "lambda=0.00100,degree=5, gamma=0.61000, Training Loss=31926270.661934234, Testing Loss=31926270.661934234\n",
      "lambda=0.00100,degree=5, gamma=0.81000, Training Loss=55644025.65592636, Testing Loss=55644025.65592636\n",
      "lambda=0.00100,degree=6, gamma=0.01000, Training Loss=7708.354641521304, Testing Loss=7708.354641521304\n",
      "lambda=0.00100,degree=6, gamma=0.21000, Training Loss=3373887.084268427, Testing Loss=3373887.084268427\n",
      "lambda=0.00100,degree=6, gamma=0.41000, Training Loss=12713309.603459463, Testing Loss=12713309.603459463\n",
      "lambda=0.00100,degree=6, gamma=0.61000, Training Loss=27817627.286751755, Testing Loss=27817627.286751755\n",
      "lambda=0.00100,degree=6, gamma=0.81000, Training Loss=48483232.821973026, Testing Loss=48483232.821973026\n",
      "lambda=0.00100,degree=7, gamma=0.01000, Training Loss=7161.788965955163, Testing Loss=7161.788965955163\n",
      "lambda=0.00100,degree=7, gamma=0.21000, Training Loss=3135821.708262218, Testing Loss=3135821.708262218\n",
      "lambda=0.00100,degree=7, gamma=0.41000, Training Loss=11816351.414742678, Testing Loss=11816351.414742678\n",
      "lambda=0.00100,degree=7, gamma=0.61000, Training Loss=25855099.963923614, Testing Loss=25855099.963923614\n",
      "lambda=0.00100,degree=7, gamma=0.81000, Training Loss=45062823.25470094, Testing Loss=45062823.25470094\n",
      "lambda=0.00100,degree=8, gamma=0.01000, Training Loss=6948.533275692537, Testing Loss=6948.533275692537\n",
      "lambda=0.00100,degree=8, gamma=0.21000, Training Loss=3043181.839198908, Testing Loss=3043181.839198908\n",
      "lambda=0.00100,degree=8, gamma=0.41000, Training Loss=11467335.706744699, Testing Loss=11467335.706744699\n",
      "lambda=0.00100,degree=8, gamma=0.61000, Training Loss=25091477.805999592, Testing Loss=25091477.805999592\n",
      "lambda=0.00100,degree=8, gamma=0.81000, Training Loss=43731952.513909854, Testing Loss=43731952.513909854\n",
      "lambda=0.00200,degree=1, gamma=0.01000, Training Loss=22324.840799820122, Testing Loss=22324.840799820122\n",
      "lambda=0.00200,degree=1, gamma=0.21000, Training Loss=9645603.936465047, Testing Loss=9645603.936465047\n",
      "lambda=0.00200,degree=1, gamma=0.41000, Training Loss=35925310.73867863, Testing Loss=35925310.73867863\n",
      "lambda=0.00200,degree=1, gamma=0.61000, Training Loss=77698292.53131211, Testing Loss=77698292.53131211\n",
      "lambda=0.00200,degree=1, gamma=0.81000, Training Loss=133854158.66791724, Testing Loss=133854158.66791724\n",
      "lambda=0.00200,degree=2, gamma=0.01000, Training Loss=22264.750751568434, Testing Loss=22264.750751568434\n",
      "lambda=0.00200,degree=2, gamma=0.21000, Training Loss=9619691.786000712, Testing Loss=9619691.786000712\n",
      "lambda=0.00200,degree=2, gamma=0.41000, Training Loss=35828806.46492569, Testing Loss=35828806.46492569\n",
      "lambda=0.00200,degree=2, gamma=0.61000, Training Loss=77489580.36780164, Testing Loss=77489580.36780164\n",
      "lambda=0.00200,degree=2, gamma=0.81000, Training Loss=133494605.42248882, Testing Loss=133494605.42248882\n",
      "lambda=0.00200,degree=3, gamma=0.01000, Training Loss=21509.315441084516, Testing Loss=21509.315441084516\n",
      "lambda=0.00200,degree=3, gamma=0.21000, Training Loss=9294210.353851447, Testing Loss=9294210.353851447\n",
      "lambda=0.00200,degree=3, gamma=0.41000, Training Loss=34616626.32719115, Testing Loss=34616626.32719115\n",
      "lambda=0.00200,degree=3, gamma=0.61000, Training Loss=74867972.60253388, Testing Loss=74867972.60253388\n",
      "lambda=0.00200,degree=3, gamma=0.81000, Training Loss=128978304.74594313, Testing Loss=128978304.74594313\n",
      "lambda=0.00200,degree=4, gamma=0.01000, Training Loss=19821.94819003692, Testing Loss=19821.94819003692\n",
      "lambda=0.00200,degree=4, gamma=0.21000, Training Loss=8567169.423984822, Testing Loss=8567169.423984822\n",
      "lambda=0.00200,degree=4, gamma=0.41000, Training Loss=31908925.78299309, Testing Loss=31908925.78299309\n",
      "lambda=0.00200,degree=4, gamma=0.61000, Training Loss=69011967.16249059, Testing Loss=69011967.16249059\n",
      "lambda=0.00200,degree=4, gamma=0.81000, Training Loss=118890033.49363436, Testing Loss=118890033.49363436\n",
      "lambda=0.00200,degree=5, gamma=0.01000, Training Loss=17685.84090888283, Testing Loss=17685.84090888283\n",
      "lambda=0.00200,degree=5, gamma=0.21000, Training Loss=7646964.28445001, Testing Loss=7646964.28445001\n",
      "lambda=0.00200,degree=5, gamma=0.41000, Training Loss=28481844.980400465, Testing Loss=28481844.980400465\n",
      "lambda=0.00200,degree=5, gamma=0.61000, Training Loss=61600153.92609275, Testing Loss=61600153.92609275\n",
      "lambda=0.00200,degree=5, gamma=0.81000, Training Loss=106121548.08439809, Testing Loss=106121548.08439809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00200,degree=6, gamma=0.01000, Training Loss=15400.074519950651, Testing Loss=15400.074519950651\n",
      "lambda=0.00200,degree=6, gamma=0.21000, Training Loss=6662729.762881147, Testing Loss=6662729.762881147\n",
      "lambda=0.00200,degree=6, gamma=0.41000, Training Loss=24816342.289588455, Testing Loss=24816342.289588455\n",
      "lambda=0.00200,degree=6, gamma=0.61000, Training Loss=53672730.89726567, Testing Loss=53672730.89726567\n",
      "lambda=0.00200,degree=6, gamma=0.81000, Training Loss=92464836.89469951, Testing Loss=92464836.89469951\n",
      "lambda=0.00200,degree=7, gamma=0.01000, Training Loss=14308.122722304735, Testing Loss=14308.122722304735\n",
      "lambda=0.00200,degree=7, gamma=0.21000, Training Loss=6192599.866803826, Testing Loss=6192599.866803826\n",
      "lambda=0.00200,degree=7, gamma=0.41000, Training Loss=23065482.680666834, Testing Loss=23065482.680666834\n",
      "lambda=0.00200,degree=7, gamma=0.61000, Training Loss=49886132.04946032, Testing Loss=49886132.04946032\n",
      "lambda=0.00200,degree=7, gamma=0.81000, Training Loss=85941600.34475362, Testing Loss=85941600.34475362\n",
      "lambda=0.00200,degree=8, gamma=0.01000, Training Loss=13882.071584447474, Testing Loss=13882.071584447474\n",
      "lambda=0.00200,degree=8, gamma=0.21000, Training Loss=6009655.284529312, Testing Loss=6009655.284529312\n",
      "lambda=0.00200,degree=8, gamma=0.41000, Training Loss=22384205.1181553, Testing Loss=22384205.1181553\n",
      "lambda=0.00200,degree=8, gamma=0.61000, Training Loss=48412761.12272714, Testing Loss=48412761.12272714\n",
      "lambda=0.00200,degree=8, gamma=0.81000, Training Loss=83403429.3334627, Testing Loss=83403429.3334627\n",
      "lambda=0.00000,degree=1, gamma=0.01000, Training Loss=6.140269506872026, Testing Loss=6.140269506872026\n",
      "lambda=0.00000,degree=1, gamma=0.21000, Training Loss=2719.2268343689852, Testing Loss=2719.2268343689852\n",
      "lambda=0.00000,degree=1, gamma=0.41000, Training Loss=10366.067262335626, Testing Loss=10366.067262335626\n",
      "lambda=0.00000,degree=1, gamma=0.61000, Training Loss=22946.489858566536, Testing Loss=22946.489858566536\n",
      "lambda=0.00000,degree=1, gamma=0.81000, Training Loss=40460.32293213607, Testing Loss=40460.32293213607\n",
      "lambda=0.00000,degree=2, gamma=0.01000, Training Loss=6.1331876621193695, Testing Loss=6.1331876621193695\n",
      "lambda=0.00000,degree=2, gamma=0.21000, Training Loss=2716.090494567552, Testing Loss=2716.090494567552\n",
      "lambda=0.00000,degree=2, gamma=0.41000, Training Loss=10354.112235947732, Testing Loss=10354.112235947732\n",
      "lambda=0.00000,degree=2, gamma=0.61000, Training Loss=22920.026914954746, Testing Loss=22920.026914954746\n",
      "lambda=0.00000,degree=2, gamma=0.81000, Training Loss=40413.663038650804, Testing Loss=40413.663038650804\n",
      "lambda=0.00000,degree=3, gamma=0.01000, Training Loss=5.974312389018559, Testing Loss=5.974312389018559\n",
      "lambda=0.00000,degree=3, gamma=0.21000, Training Loss=2646.0258237560593, Testing Loss=2646.0258237560593\n",
      "lambda=0.00000,degree=3, gamma=0.41000, Training Loss=10087.044429978518, Testing Loss=10087.044429978518\n",
      "lambda=0.00000,degree=3, gamma=0.61000, Training Loss=22328.863057201208, Testing Loss=22328.863057201208\n",
      "lambda=0.00000,degree=3, gamma=0.81000, Training Loss=39371.31463537821, Testing Loss=39371.31463537821\n",
      "lambda=0.00000,degree=4, gamma=0.01000, Training Loss=5.347674657007592, Testing Loss=5.347674657007592\n",
      "lambda=0.00000,degree=4, gamma=0.21000, Training Loss=2369.708055065837, Testing Loss=2369.708055065837\n",
      "lambda=0.00000,degree=4, gamma=0.41000, Training Loss=9033.794542789918, Testing Loss=9033.794542789918\n",
      "lambda=0.00000,degree=4, gamma=0.61000, Training Loss=19997.457507181396, Testing Loss=19997.457507181396\n",
      "lambda=0.00000,degree=4, gamma=0.81000, Training Loss=35260.547321003934, Testing Loss=35260.547321003934\n",
      "lambda=0.00000,degree=5, gamma=0.01000, Training Loss=4.780920090608114, Testing Loss=4.780920090608114\n",
      "lambda=0.00000,degree=5, gamma=0.21000, Training Loss=2119.887231546171, Testing Loss=2119.887231546171\n",
      "lambda=0.00000,degree=5, gamma=0.41000, Training Loss=8081.552564687189, Testing Loss=8081.552564687189\n",
      "lambda=0.00000,degree=5, gamma=0.61000, Training Loss=17889.64305909929, Testing Loss=17889.64305909929\n",
      "lambda=0.00000,degree=5, gamma=0.81000, Training Loss=31544.024857420092, Testing Loss=31544.024857420092\n",
      "lambda=0.00000,degree=6, gamma=0.01000, Training Loss=4.459869586527208, Testing Loss=4.459869586527208\n",
      "lambda=0.00000,degree=6, gamma=0.21000, Training Loss=1978.5471618615718, Testing Loss=1978.5471618615718\n",
      "lambda=0.00000,degree=6, gamma=0.41000, Training Loss=7542.823555080856, Testing Loss=7542.823555080856\n",
      "lambda=0.00000,degree=6, gamma=0.61000, Training Loss=16697.16411051397, Testing Loss=16697.16411051397\n",
      "lambda=0.00000,degree=6, gamma=0.81000, Training Loss=29441.443892279054, Testing Loss=29441.443892279054\n",
      "lambda=0.00000,degree=7, gamma=0.01000, Training Loss=4.173309764882256, Testing Loss=4.173309764882256\n",
      "lambda=0.00000,degree=7, gamma=0.21000, Training Loss=1852.345518761476, Testing Loss=1852.345518761476\n",
      "lambda=0.00000,degree=7, gamma=0.41000, Training Loss=7061.791726032141, Testing Loss=7061.791726032141\n",
      "lambda=0.00000,degree=7, gamma=0.61000, Training Loss=15632.39495910157, Testing Loss=15632.39495910157\n",
      "lambda=0.00000,degree=7, gamma=0.81000, Training Loss=27564.038248161552, Testing Loss=27564.038248161552\n",
      "lambda=0.00000,degree=8, gamma=0.01000, Training Loss=3.976889221662225, Testing Loss=3.976889221662225\n",
      "lambda=0.00000,degree=8, gamma=0.21000, Training Loss=1765.9761571458027, Testing Loss=1765.9761571458027\n",
      "lambda=0.00000,degree=8, gamma=0.41000, Training Loss=6732.598043424873, Testing Loss=6732.598043424873\n",
      "lambda=0.00000,degree=8, gamma=0.61000, Training Loss=14903.731027058166, Testing Loss=14903.731027058166\n",
      "lambda=0.00000,degree=8, gamma=0.81000, Training Loss=26279.263589587623, Testing Loss=26279.263589587623\n",
      "lambda=0.00100,degree=1, gamma=0.01000, Training Loss=6142.846145444361, Testing Loss=6142.846145444361\n",
      "lambda=0.00100,degree=1, gamma=0.21000, Training Loss=2688990.5168536366, Testing Loss=2688990.5168536366\n",
      "lambda=0.00100,degree=1, gamma=0.41000, Training Loss=10132543.44245944, Testing Loss=10132543.44245944\n",
      "lambda=0.00100,degree=1, gamma=0.61000, Training Loss=22170746.729202986, Testing Loss=22170746.729202986\n",
      "lambda=0.00100,degree=1, gamma=0.81000, Training Loss=38641324.3336255, Testing Loss=38641324.3336255\n",
      "lambda=0.00100,degree=2, gamma=0.01000, Training Loss=6135.7613286506175, Testing Loss=6135.7613286506175\n",
      "lambda=0.00100,degree=2, gamma=0.21000, Training Loss=2685889.051561628, Testing Loss=2685889.051561628\n",
      "lambda=0.00100,degree=2, gamma=0.41000, Training Loss=10120857.735999605, Testing Loss=10120857.735999605\n",
      "lambda=0.00100,degree=2, gamma=0.61000, Training Loss=22145178.409201268, Testing Loss=22145178.409201268\n",
      "lambda=0.00100,degree=2, gamma=0.81000, Training Loss=38596762.158395074, Testing Loss=38596762.158395074\n",
      "lambda=0.00100,degree=3, gamma=0.01000, Training Loss=5976.8193934789715, Testing Loss=5976.8193934789715\n",
      "lambda=0.00100,degree=3, gamma=0.21000, Training Loss=2616603.464794831, Testing Loss=2616603.464794831\n",
      "lambda=0.00100,degree=3, gamma=0.41000, Training Loss=9859806.369679423, Testing Loss=9859806.369679423\n",
      "lambda=0.00100,degree=3, gamma=0.61000, Training Loss=21573999.826064102, Testing Loss=21573999.826064102\n",
      "lambda=0.00100,degree=3, gamma=0.81000, Training Loss=37601275.27259891, Testing Loss=37601275.27259891\n",
      "lambda=0.00100,degree=4, gamma=0.01000, Training Loss=5349.918733746445, Testing Loss=5349.918733746445\n",
      "lambda=0.00100,degree=4, gamma=0.21000, Training Loss=2343358.2112543676, Testing Loss=2343358.2112543676\n",
      "lambda=0.00100,degree=4, gamma=0.41000, Training Loss=8830283.843815029, Testing Loss=8830283.843815029\n",
      "lambda=0.00100,degree=4, gamma=0.61000, Training Loss=19321411.306668688, Testing Loss=19321411.306668688\n",
      "lambda=0.00100,degree=4, gamma=0.81000, Training Loss=33675318.32761385, Testing Loss=33675318.32761385\n",
      "lambda=0.00100,degree=5, gamma=0.01000, Training Loss=4782.926367843724, Testing Loss=4782.926367843724\n",
      "lambda=0.00100,degree=5, gamma=0.21000, Training Loss=2096315.2710892835, Testing Loss=2096315.2710892835\n",
      "lambda=0.00100,degree=5, gamma=0.41000, Training Loss=7899493.748659399, Testing Loss=7899493.748659399\n",
      "lambda=0.00100,degree=5, gamma=0.61000, Training Loss=17284855.029164214, Testing Loss=17284855.029164214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00100,degree=5, gamma=0.81000, Training Loss=30125881.931802038, Testing Loss=30125881.931802038\n",
      "lambda=0.00100,degree=6, gamma=0.01000, Training Loss=4461.741161117539, Testing Loss=4461.741161117539\n",
      "lambda=0.00100,degree=6, gamma=0.21000, Training Loss=1956546.8345962754, Testing Loss=1956546.8345962754\n",
      "lambda=0.00100,degree=6, gamma=0.41000, Training Loss=7372901.106381918, Testing Loss=7372901.106381918\n",
      "lambda=0.00100,degree=6, gamma=0.61000, Training Loss=16132689.828901686, Testing Loss=16132689.828901686\n",
      "lambda=0.00100,degree=6, gamma=0.81000, Training Loss=28117828.065590613, Testing Loss=28117828.065590613\n",
      "lambda=0.00100,degree=7, gamma=0.01000, Training Loss=4175.06110690511, Testing Loss=4175.06110690511\n",
      "lambda=0.00100,degree=7, gamma=0.21000, Training Loss=1831748.4922450369, Testing Loss=1831748.4922450369\n",
      "lambda=0.00100,degree=7, gamma=0.41000, Training Loss=6902705.853665199, Testing Loss=6902705.853665199\n",
      "lambda=0.00100,degree=7, gamma=0.61000, Training Loss=15103916.978384752, Testing Loss=15103916.978384752\n",
      "lambda=0.00100,degree=7, gamma=0.81000, Training Loss=26324826.1605083, Testing Loss=26324826.1605083\n",
      "lambda=0.00100,degree=8, gamma=0.01000, Training Loss=3978.558154182418, Testing Loss=3978.558154182418\n",
      "lambda=0.00100,degree=8, gamma=0.21000, Training Loss=1746339.5172661494, Testing Loss=1746339.5172661494\n",
      "lambda=0.00100,degree=8, gamma=0.41000, Training Loss=6580928.17737551, Testing Loss=6580928.17737551\n",
      "lambda=0.00100,degree=8, gamma=0.61000, Training Loss=14399886.760399098, Testing Loss=14399886.760399098\n",
      "lambda=0.00100,degree=8, gamma=0.81000, Training Loss=25097811.967429448, Testing Loss=25097811.967429448\n",
      "lambda=0.00200,degree=1, gamma=0.01000, Training Loss=12272.435938728668, Testing Loss=12272.435938728668\n",
      "lambda=0.00200,degree=1, gamma=0.21000, Training Loss=5310200.585045167, Testing Loss=5310200.585045167\n",
      "lambda=0.00200,degree=1, gamma=0.41000, Training Loss=19778694.490638617, Testing Loss=19778694.490638617\n",
      "lambda=0.00200,degree=1, gamma=0.61000, Training Loss=42777355.23745759, Testing Loss=42777355.23745759\n",
      "lambda=0.00200,degree=1, gamma=0.81000, Training Loss=73694833.20110843, Testing Loss=73694833.20110843\n",
      "lambda=0.00200,degree=2, gamma=0.01000, Training Loss=12258.281593701058, Testing Loss=12258.281593701058\n",
      "lambda=0.00200,degree=2, gamma=0.21000, Training Loss=5304075.832261875, Testing Loss=5304075.832261875\n",
      "lambda=0.00200,degree=2, gamma=0.41000, Training Loss=19755884.0275369, Testing Loss=19755884.0275369\n",
      "lambda=0.00200,degree=2, gamma=0.61000, Training Loss=42728022.43534377, Testing Loss=42728022.43534377\n",
      "lambda=0.00200,degree=2, gamma=0.81000, Training Loss=73609846.41592996, Testing Loss=73609846.41592996\n",
      "lambda=0.00200,degree=3, gamma=0.01000, Training Loss=11940.74073575196, Testing Loss=11940.74073575196\n",
      "lambda=0.00200,degree=3, gamma=0.21000, Training Loss=5167251.122665615, Testing Loss=5167251.122665615\n",
      "lambda=0.00200,degree=3, gamma=0.41000, Training Loss=19246312.564676434, Testing Loss=19246312.564676434\n",
      "lambda=0.00200,degree=3, gamma=0.61000, Training Loss=41625961.76349627, Testing Loss=41625961.76349627\n",
      "lambda=0.00200,degree=3, gamma=0.81000, Training Loss=71711302.87720785, Testing Loss=71711302.87720785\n",
      "lambda=0.00200,degree=4, gamma=0.01000, Training Loss=10688.292333037734, Testing Loss=10688.292333037734\n",
      "lambda=0.00200,degree=4, gamma=0.21000, Training Loss=4627648.238235955, Testing Loss=4627648.238235955\n",
      "lambda=0.00200,degree=4, gamma=0.41000, Training Loss=17236687.765367504, Testing Loss=17236687.765367504\n",
      "lambda=0.00200,degree=4, gamma=0.61000, Training Loss=37279704.234081365, Testing Loss=37279704.234081365\n",
      "lambda=0.00200,degree=4, gamma=0.81000, Training Loss=64223911.23077082, Testing Loss=64223911.23077082\n",
      "lambda=0.00200,degree=5, gamma=0.01000, Training Loss=9555.531233950845, Testing Loss=9555.531233950845\n",
      "lambda=0.00200,degree=5, gamma=0.21000, Training Loss=4139789.507495491, Testing Loss=4139789.507495491\n",
      "lambda=0.00200,degree=5, gamma=0.41000, Training Loss=15419788.373746203, Testing Loss=15419788.373746203\n",
      "lambda=0.00200,degree=5, gamma=0.61000, Training Loss=33350270.187628757, Testing Loss=33350270.187628757\n",
      "lambda=0.00200,degree=5, gamma=0.81000, Training Loss=57454601.05019174, Testing Loss=57454601.05019174\n",
      "lambda=0.00200,degree=6, gamma=0.01000, Training Loss=8913.853982118279, Testing Loss=8913.853982118279\n",
      "lambda=0.00200,degree=6, gamma=0.21000, Training Loss=3863775.7462475174, Testing Loss=3863775.7462475174\n",
      "lambda=0.00200,degree=6, gamma=0.41000, Training Loss=14391881.175943684, Testing Loss=14391881.175943684\n",
      "lambda=0.00200,degree=6, gamma=0.61000, Training Loss=31127224.768343374, Testing Loss=31127224.768343374\n",
      "lambda=0.00200,degree=6, gamma=0.81000, Training Loss=53624939.7237172, Testing Loss=53624939.7237172\n",
      "lambda=0.00200,degree=7, gamma=0.01000, Training Loss=8341.112566230524, Testing Loss=8341.112566230524\n",
      "lambda=0.00200,degree=7, gamma=0.21000, Training Loss=3617324.8245509937, Testing Loss=3617324.8245509937\n",
      "lambda=0.00200,degree=7, gamma=0.41000, Training Loss=13474061.503526585, Testing Loss=13474061.503526585\n",
      "lambda=0.00200,degree=7, gamma=0.61000, Training Loss=29142258.74022271, Testing Loss=29142258.74022271\n",
      "lambda=0.00200,degree=7, gamma=0.81000, Training Loss=50205414.88169188, Testing Loss=50205414.88169188\n",
      "lambda=0.00200,degree=8, gamma=0.01000, Training Loss=7948.530745736542, Testing Loss=7948.530745736542\n",
      "lambda=0.00200,degree=8, gamma=0.21000, Training Loss=3448659.7617527107, Testing Loss=3448659.7617527107\n",
      "lambda=0.00200,degree=8, gamma=0.41000, Training Loss=12845952.489770794, Testing Loss=12845952.489770794\n",
      "lambda=0.00200,degree=8, gamma=0.61000, Training Loss=27783867.486836534, Testing Loss=27783867.486836534\n",
      "lambda=0.00200,degree=8, gamma=0.81000, Training Loss=47865313.941499226, Testing Loss=47865313.941499226\n",
      "lambda=0.00000,degree=1, gamma=0.01000, Training Loss=1.181739421193555, Testing Loss=1.181739421193555\n",
      "lambda=0.00000,degree=1, gamma=0.21000, Training Loss=526.1412224793443, Testing Loss=526.1412224793443\n",
      "lambda=0.00000,degree=1, gamma=0.41000, Training Loss=2005.984463949823, Testing Loss=2005.984463949823\n",
      "lambda=0.00000,degree=1, gamma=0.61000, Training Loss=4440.678233838055, Testing Loss=4440.678233838055\n",
      "lambda=0.00000,degree=1, gamma=0.81000, Training Loss=7830.189302907113, Testing Loss=7830.189302907113\n",
      "lambda=0.00000,degree=2, gamma=0.01000, Training Loss=1.1810366444503193, Testing Loss=1.1810366444503193\n",
      "lambda=0.00000,degree=2, gamma=0.21000, Training Loss=525.8180363244787, Testing Loss=525.8180363244787\n",
      "lambda=0.00000,degree=2, gamma=0.41000, Training Loss=2004.752469610838, Testing Loss=2004.752469610838\n",
      "lambda=0.00000,degree=2, gamma=0.61000, Training Loss=4437.951126913082, Testing Loss=4437.951126913082\n",
      "lambda=0.00000,degree=2, gamma=0.81000, Training Loss=7825.380799397935, Testing Loss=7825.380799397935\n",
      "lambda=0.00000,degree=3, gamma=0.01000, Training Loss=1.1539308365301817, Testing Loss=1.1539308365301817\n",
      "lambda=0.00000,degree=3, gamma=0.21000, Training Loss=513.8548409304306, Testing Loss=513.8548409304306\n",
      "lambda=0.00000,degree=3, gamma=0.41000, Training Loss=1959.152037021687, Testing Loss=1959.152037021687\n",
      "lambda=0.00000,degree=3, gamma=0.61000, Training Loss=4337.013064720695, Testing Loss=4337.013064720695\n",
      "lambda=0.00000,degree=3, gamma=0.81000, Training Loss=7647.405470377807, Testing Loss=7647.405470377807\n",
      "lambda=0.00000,degree=4, gamma=0.01000, Training Loss=0.9769258308433406, Testing Loss=0.9769258308433406\n",
      "lambda=0.00000,degree=4, gamma=0.21000, Training Loss=435.8158274152817, Testing Loss=435.8158274152817\n",
      "lambda=0.00000,degree=4, gamma=0.41000, Training Loss=1661.6899844367063, Testing Loss=1661.6899844367063\n",
      "lambda=0.00000,degree=4, gamma=0.61000, Training Loss=3678.5718688352904, Testing Loss=3678.5718688352904\n",
      "lambda=0.00000,degree=4, gamma=0.81000, Training Loss=6486.4339531788455, Testing Loss=6486.4339531788455\n",
      "lambda=0.00000,degree=5, gamma=0.01000, Training Loss=0.8905249862510511, Testing Loss=0.8905249862510511\n",
      "lambda=0.00000,degree=5, gamma=0.21000, Training Loss=397.76674833959504, Testing Loss=397.76674833959504\n",
      "lambda=0.00000,degree=5, gamma=0.41000, Training Loss=1516.6626086580302, Testing Loss=1516.6626086580302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00000,degree=5, gamma=0.61000, Training Loss=3357.5529796281344, Testing Loss=3357.5529796281344\n",
      "lambda=0.00000,degree=5, gamma=0.81000, Training Loss=5920.412735509366, Testing Loss=5920.412735509366\n",
      "lambda=0.00000,degree=6, gamma=0.01000, Training Loss=0.8383186531985164, Testing Loss=0.8383186531985164\n",
      "lambda=0.00000,degree=6, gamma=0.21000, Training Loss=374.8483619390147, Testing Loss=374.8483619390147\n",
      "lambda=0.00000,degree=6, gamma=0.41000, Training Loss=1429.3143574375197, Testing Loss=1429.3143574375197\n",
      "lambda=0.00000,degree=6, gamma=0.61000, Training Loss=3164.212625253264, Testing Loss=3164.212625253264\n",
      "lambda=0.00000,degree=6, gamma=0.81000, Training Loss=5579.519486030688, Testing Loss=5579.519486030688\n",
      "lambda=0.00000,degree=7, gamma=0.01000, Training Loss=0.7801374953626896, Testing Loss=0.7801374953626896\n",
      "lambda=0.00000,degree=7, gamma=0.21000, Training Loss=349.2620905093284, Testing Loss=349.2620905093284\n",
      "lambda=0.00000,degree=7, gamma=0.41000, Training Loss=1331.7937333638254, Testing Loss=1331.7937333638254\n",
      "lambda=0.00000,degree=7, gamma=0.61000, Training Loss=2948.35300110327, Testing Loss=2948.35300110327\n",
      "lambda=0.00000,degree=7, gamma=0.81000, Training Loss=5198.917829275157, Testing Loss=5198.917829275157\n",
      "lambda=0.00000,degree=8, gamma=0.01000, Training Loss=0.7412808890504392, Testing Loss=0.7412808890504392\n",
      "lambda=0.00000,degree=8, gamma=0.21000, Training Loss=332.2337340129206, Testing Loss=332.2337340129206\n",
      "lambda=0.00000,degree=8, gamma=0.41000, Training Loss=1266.8970536439595, Testing Loss=1266.8970536439595\n",
      "lambda=0.00000,degree=8, gamma=0.61000, Training Loss=2804.710249410929, Testing Loss=2804.710249410929\n",
      "lambda=0.00000,degree=8, gamma=0.81000, Training Loss=4945.65233142117, Testing Loss=4945.65233142117\n",
      "lambda=0.00100,degree=1, gamma=0.01000, Training Loss=1182.2353803667563, Testing Loss=1182.2353803667563\n",
      "lambda=0.00100,degree=1, gamma=0.21000, Training Loss=520290.8486114686, Testing Loss=520290.8486114686\n",
      "lambda=0.00100,degree=1, gamma=0.41000, Training Loss=1960794.3256478722, Testing Loss=1960794.3256478722\n",
      "lambda=0.00100,degree=1, gamma=0.61000, Training Loss=4290554.179041057, Testing Loss=4290554.179041057\n",
      "lambda=0.00100,degree=1, gamma=0.81000, Training Loss=7478163.284700646, Testing Loss=7478163.284700646\n",
      "lambda=0.00100,degree=2, gamma=0.01000, Training Loss=1181.5323081468339, Testing Loss=1181.5323081468339\n",
      "lambda=0.00100,degree=2, gamma=0.21000, Training Loss=519971.2561111248, Testing Loss=519971.2561111248\n",
      "lambda=0.00100,degree=2, gamma=0.41000, Training Loss=1959590.0853540548, Testing Loss=1959590.0853540548\n",
      "lambda=0.00100,degree=2, gamma=0.61000, Training Loss=4287919.26644299, Testing Loss=4287919.26644299\n",
      "lambda=0.00100,degree=2, gamma=0.81000, Training Loss=7473570.960065849, Testing Loss=7473570.960065849\n",
      "lambda=0.00100,degree=3, gamma=0.01000, Training Loss=1154.4151265084274, Testing Loss=1154.4151265084274\n",
      "lambda=0.00100,degree=3, gamma=0.21000, Training Loss=508141.0854631352, Testing Loss=508141.0854631352\n",
      "lambda=0.00100,degree=3, gamma=0.41000, Training Loss=1915016.9284422598, Testing Loss=1915016.9284422598\n",
      "lambda=0.00100,degree=3, gamma=0.61000, Training Loss=4190393.5829433515, Testing Loss=4190393.5829433515\n",
      "lambda=0.00100,degree=3, gamma=0.81000, Training Loss=7303596.980846301, Testing Loss=7303596.980846301\n",
      "lambda=0.00100,degree=4, gamma=0.01000, Training Loss=977.3358522740258, Testing Loss=977.3358522740258\n",
      "lambda=0.00100,degree=4, gamma=0.21000, Training Loss=430969.8268925792, Testing Loss=430969.8268925792\n",
      "lambda=0.00100,degree=4, gamma=0.41000, Training Loss=1624256.03058705, Testing Loss=1624256.03058705\n",
      "lambda=0.00100,degree=4, gamma=0.61000, Training Loss=3554212.085333124, Testing Loss=3554212.085333124\n",
      "lambda=0.00100,degree=4, gamma=0.81000, Training Loss=6194819.998508374, Testing Loss=6194819.998508374\n",
      "lambda=0.00100,degree=5, gamma=0.01000, Training Loss=890.8987561289315, Testing Loss=890.8987561289315\n",
      "lambda=0.00100,degree=5, gamma=0.21000, Training Loss=393343.8351360399, Testing Loss=393343.8351360399\n",
      "lambda=0.00100,degree=5, gamma=0.41000, Training Loss=1482495.7991786003, Testing Loss=1482495.7991786003\n",
      "lambda=0.00100,degree=5, gamma=0.61000, Training Loss=3244045.777191152, Testing Loss=3244045.777191152\n",
      "lambda=0.00100,degree=5, gamma=0.81000, Training Loss=5654245.764230381, Testing Loss=5654245.764230381\n",
      "lambda=0.00100,degree=6, gamma=0.01000, Training Loss=838.6705202592784, Testing Loss=838.6705202592784\n",
      "lambda=0.00100,degree=6, gamma=0.21000, Training Loss=370680.29088490957, Testing Loss=370680.29088490957\n",
      "lambda=0.00100,degree=6, gamma=0.41000, Training Loss=1397115.312899792, Testing Loss=1397115.312899792\n",
      "lambda=0.00100,degree=6, gamma=0.61000, Training Loss=3057241.6238472247, Testing Loss=3057241.6238472247\n",
      "lambda=0.00100,degree=6, gamma=0.81000, Training Loss=5328678.285451344, Testing Loss=5328678.285451344\n",
      "lambda=0.00100,degree=7, gamma=0.01000, Training Loss=780.464951870437, Testing Loss=780.464951870437\n",
      "lambda=0.00100,degree=7, gamma=0.21000, Training Loss=345378.52680289035, Testing Loss=345378.52680289035\n",
      "lambda=0.00100,degree=7, gamma=0.41000, Training Loss=1301791.613241907, Testing Loss=1301791.613241907\n",
      "lambda=0.00100,degree=7, gamma=0.61000, Training Loss=2848679.499126489, Testing Loss=2848679.499126489\n",
      "lambda=0.00100,degree=7, gamma=0.81000, Training Loss=4965187.590425431, Testing Loss=4965187.590425431\n",
      "lambda=0.00100,degree=8, gamma=0.01000, Training Loss=741.5920441602168, Testing Loss=741.5920441602168\n",
      "lambda=0.00100,degree=8, gamma=0.21000, Training Loss=328539.51831262035, Testing Loss=328539.51831262035\n",
      "lambda=0.00100,degree=8, gamma=0.41000, Training Loss=1238356.9149802194, Testing Loss=1238356.9149802194\n",
      "lambda=0.00100,degree=8, gamma=0.61000, Training Loss=2709892.8389131757, Testing Loss=2709892.8389131757\n",
      "lambda=0.00100,degree=8, gamma=0.81000, Training Loss=4723308.3275015075, Testing Loss=4723308.3275015075\n",
      "lambda=0.00200,degree=1, gamma=0.01000, Training Loss=2361.919612051044, Testing Loss=2361.919612051044\n",
      "lambda=0.00200,degree=1, gamma=0.21000, Training Loss=1027466.9644697118, Testing Loss=1027466.9644697118\n",
      "lambda=0.00200,degree=1, gamma=0.41000, Training Loss=3827464.8733580094, Testing Loss=3827464.8733580094\n",
      "lambda=0.00200,degree=1, gamma=0.61000, Training Loss=8278411.76622824, Testing Loss=8278411.76622824\n",
      "lambda=0.00200,degree=1, gamma=0.81000, Training Loss=14261986.005084166, Testing Loss=14261986.005084166\n",
      "lambda=0.00200,degree=2, gamma=0.01000, Training Loss=2360.5149837110303, Testing Loss=2360.5149837110303\n",
      "lambda=0.00200,degree=2, gamma=0.21000, Training Loss=1026835.8353279199, Testing Loss=1026835.8353279199\n",
      "lambda=0.00200,degree=2, gamma=0.41000, Training Loss=3825114.1999584627, Testing Loss=3825114.1999584627\n",
      "lambda=0.00200,degree=2, gamma=0.61000, Training Loss=8273327.833315089, Testing Loss=8273327.833315089\n",
      "lambda=0.00200,degree=2, gamma=0.81000, Training Loss=14253227.749692827, Testing Loss=14253227.749692827\n",
      "lambda=0.00200,degree=3, gamma=0.01000, Training Loss=2306.3391410686195, Testing Loss=2306.3391410686195\n",
      "lambda=0.00200,degree=3, gamma=0.21000, Training Loss=1003473.6941068771, Testing Loss=1003473.6941068771\n",
      "lambda=0.00200,degree=3, gamma=0.41000, Training Loss=3738107.5350567303, Testing Loss=3738107.5350567303\n",
      "lambda=0.00200,degree=3, gamma=0.61000, Training Loss=8085156.877083008, Testing Loss=8085156.877083008\n",
      "lambda=0.00200,degree=3, gamma=0.81000, Training Loss=13929061.751885181, Testing Loss=13929061.751885181\n",
      "lambda=0.00200,degree=4, gamma=0.01000, Training Loss=1952.5627482250368, Testing Loss=1952.5627482250368\n",
      "lambda=0.00200,degree=4, gamma=0.21000, Training Loss=851076.4134023559, Testing Loss=851076.4134023559\n",
      "lambda=0.00200,degree=4, gamma=0.41000, Training Loss=3170543.1596534075, Testing Loss=3170543.1596534075\n",
      "lambda=0.00200,degree=4, gamma=0.61000, Training Loss=6857676.317528719, Testing Loss=6857676.317528719\n",
      "lambda=0.00200,degree=4, gamma=0.81000, Training Loss=11814456.928637592, Testing Loss=11814456.928637592\n",
      "lambda=0.00200,degree=5, gamma=0.01000, Training Loss=1779.8750980375582, Testing Loss=1779.8750980375582\n",
      "lambda=0.00200,degree=5, gamma=0.21000, Training Loss=776772.8597917642, Testing Loss=776772.8597917642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00200,degree=5, gamma=0.41000, Training Loss=2893827.629219058, Testing Loss=2893827.629219058\n",
      "lambda=0.00200,degree=5, gamma=0.61000, Training Loss=6259225.860218038, Testing Loss=6259225.860218038\n",
      "lambda=0.00200,degree=5, gamma=0.81000, Training Loss=10783500.401382606, Testing Loss=10783500.401382606\n",
      "lambda=0.00200,degree=6, gamma=0.01000, Training Loss=1675.5313445948475, Testing Loss=1675.5313445948475\n",
      "lambda=0.00200,degree=6, gamma=0.21000, Training Loss=732017.0477262138, Testing Loss=732017.0477262138\n",
      "lambda=0.00200,degree=6, gamma=0.41000, Training Loss=2727165.1916783513, Testing Loss=2727165.1916783513\n",
      "lambda=0.00200,degree=6, gamma=0.61000, Training Loss=5898796.554716181, Testing Loss=5898796.554716181\n",
      "lambda=0.00200,degree=6, gamma=0.81000, Training Loss=10162594.17958707, Testing Loss=10162594.17958707\n",
      "lambda=0.00200,degree=7, gamma=0.01000, Training Loss=1559.2458242405723, Testing Loss=1559.2458242405723\n",
      "lambda=0.00200,degree=7, gamma=0.21000, Training Loss=682051.2962413154, Testing Loss=682051.2962413154\n",
      "lambda=0.00200,degree=7, gamma=0.41000, Training Loss=2541093.629699111, Testing Loss=2541093.629699111\n",
      "lambda=0.00200,degree=7, gamma=0.61000, Training Loss=5496386.319927421, Testing Loss=5496386.319927421\n",
      "lambda=0.00200,degree=7, gamma=0.81000, Training Loss=9469362.658809442, Testing Loss=9469362.658809442\n",
      "lambda=0.00200,degree=8, gamma=0.01000, Training Loss=1481.5839050820862, Testing Loss=1481.5839050820862\n",
      "lambda=0.00200,degree=8, gamma=0.21000, Training Loss=648797.7382019336, Testing Loss=648797.7382019336\n",
      "lambda=0.00200,degree=8, gamma=0.41000, Training Loss=2417269.3030517995, Testing Loss=2417269.3030517995\n",
      "lambda=0.00200,degree=8, gamma=0.61000, Training Loss=5228604.380175062, Testing Loss=5228604.380175062\n",
      "lambda=0.00200,degree=8, gamma=0.81000, Training Loss=9008062.479875848, Testing Loss=9008062.479875848\n",
      "Accuracy per jet nbr: \n",
      "\n",
      "[9.826820043199165, 6.945618653838199, 3.976889221662225, 0.7412808890504392]\n"
     ]
    }
   ],
   "source": [
    "#separate data with respect to column 24 and remove None\n",
    "split_x_test, _, split_ids_test =  separate(y_donotUse, tX_test, ids_test)\n",
    "\n",
    "\n",
    "split_x_cleaned_test = removeNone(split_x_test, dataStatistics(split_x_test))\n",
    "\n",
    "#median instead of None\n",
    "split_x_with_median = putMedianInsteadOfNone(split_x_cleaned_test)\n",
    "\n",
    "split_x_with_median_with_momentum = add_momentum_vector(split_x_with_median)\n",
    "\n",
    "#line dropped when None\n",
    "#split_x_drop_lines, split_y_dropped_split_indexes_dropped = dropLineIfNone(split_x_cleaned_test, _, split_ids_test)\n",
    "\n",
    "#degrees for polynomial feature expension\n",
    "degrees = [1,2,3,4,5,6,7,8]\n",
    "\n",
    "y_res = []\n",
    "\n",
    "acc = []\n",
    "\n",
    "plot_data_per_jetnum = []\n",
    "\n",
    "\n",
    "for i in range(len(cleaned_with_median)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #training: chose either cross calidation or cross validation for logistic regression with regularization\n",
    "    #w_star, d, accuracy, training_set, plot_data = crossValidation(cleaned_with_median[i], split_y[i], 0.98, degrees ,6)\n",
    "    w_star, d, accuracy, training_set, plot_data = crossValidationForLogistic_reg_with_loss(cleaned_with_median[i], split_y[i], 0.9, degrees ,6)\n",
    "    \n",
    "    \n",
    "    #polynomial feature expension and normalization using the training data\n",
    "    mean = np.mean(build_poly(training_set,d), axis = 0)\n",
    "    std = np.std(build_poly(training_set,d), axis = 0)\n",
    "    \n",
    "      \n",
    "    #put 1 if std = 0\n",
    "    std = std + (std == 0)\n",
    "    \n",
    "    extended_and_normalized = (build_poly(split_x_with_median[i], d) - mean) / std\n",
    "    \n",
    "    #adding bias term\n",
    "    bias = np.ones(shape=split_x_with_median[i].shape)          \n",
    "    x_test_ready = np.c_[bias, extended_and_normalized]\n",
    "    \n",
    "    #prediction for least squares\n",
    "    #y_res.append(predict_labels(w_star, x_test_ready))\n",
    "    \n",
    "    #prediction for logistic\n",
    "    y_res.append(predict_labels_logistic(w_star, x_test_ready))\n",
    "\n",
    "\n",
    "    acc.append(accuracy)\n",
    "    plot_data_per_jetnum.append(plot_data)\n",
    "\n",
    "print(\"Accuracy per jet nbr: \\n\")\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() got an unexpected keyword argument 'use_line_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-18701bf9b52e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_line_collection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hello\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cross_with_momentum_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stem() got an unexpected keyword argument 'use_line_collection'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "for i in range(len(plot_data_per_jetnum)):\n",
    "    jet_num = plot_data_per_jetnum[i]\n",
    "\n",
    "\n",
    "\n",
    "    X = np.array([x[0] for x in jet_num])\n",
    "    Y = np.array([x[1] for x in jet_num])\n",
    "    Z = np.array([x[3] for x in jet_num])\n",
    "    \n",
    "\n",
    "    plt.figure(dpi=120)\n",
    "    plt.title('Degree against accuracy for jet_num = %d' %i)\n",
    "    plt.xlabel('Degree of polynomial extension')\n",
    "    plt.ylabel('Testing Accuracy')\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.7,0.86])\n",
    "\n",
    "    plt.stem(Y, Z, use_line_collection=True, label=\"hello\")\n",
    "    plt.savefig(\"cross_with_momentum_\"+str(i))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "#reassemble the data for the submission\n",
    "y_pred = put_together(y_res, split_ids_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
