{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data according to the value of column 24 (PRI_jet_num) \n",
    "\n",
    "def separate(y, tX, ids):\n",
    "    \n",
    "    split_x = []\n",
    "    split_y = []\n",
    "    split_ids = []\n",
    "    \n",
    "    jet_column_nbr = 22\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        split_x.append(tX[np.where(tX[:,jet_column_nbr] == i)])\n",
    "        split_y.append(y[np.where(tX[:,jet_column_nbr] == i)])\n",
    "        split_ids.append(ids[np.where(tX[:,jet_column_nbr] == i)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return split_x, split_y, split_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_x, split_y, split_ids = separate(y, tX, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the columns from each set of data given a boolean array\n",
    "\n",
    "def removeNone(data, selection):\n",
    "   \n",
    "    cleaned=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        curr_data = data[i]\n",
    "        \n",
    "        cleaned.append(curr_data[:,selection[i]])\n",
    "      \n",
    "    return cleaned\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print statistics about the None values (-999) for each columns\n",
    "#returns a boolean array that can be used to filter the columns that have 100% of undefined values (-999)\n",
    "def dataStatistics(data):\n",
    "    \n",
    "    stats=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        print(\"Statistics \")\n",
    "        print(\"Type :\")\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "        nones = (data[i] == -999)\n",
    "    \n",
    "        mean = np.sum(nones, axis=0)/nones.shape[0]\n",
    "        print(mean) \n",
    "        stats.append(mean != 1)\n",
    "    \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics \n",
      "Type :\n",
      "0\n",
      "[0.26145747 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 1.         1.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "1\n",
      "[0.09751883 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "2\n",
      "[0.05859584 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "3\n",
      "[0.0666396 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "selection = dataStatistics(split_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = removeNone(split_x, selection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can either drop the lines with residual Nones or replace the Nones by the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the value of column 0 (can be None sometimes) by the median value of this column\n",
    "\n",
    "def putMedianInsteadOfNone(cleaned):\n",
    "    \n",
    "    completed_data = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        #current PRI_jet_num\n",
    "        current = cleaned[i]\n",
    "        \n",
    "        median = np.median(current[np.where(current[:,0] != -999)], axis = 0)\n",
    "        \n",
    "        #replace -999 by median value\n",
    "        current[np.where(current[:,0] == -999)] = median\n",
    "        \n",
    "        completed_data.append(current)\n",
    "    \n",
    "    \n",
    "    return completed_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_with_median = putMedianInsteadOfNone(cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of putting the median we can simply drop the data where columns 0 == -999\n",
    "def dropLineIfNone(cleaned, split_y, split_ids):\n",
    "    \n",
    "    res_x=[]\n",
    "    res_y=[]\n",
    "    res_ids=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        \n",
    "        current = cleaned[i]\n",
    "        \n",
    "        drop_indexes = np.where(current[:,0] != -999)\n",
    "        \n",
    "        res_x.append(current[drop_indexes])\n",
    "        res_y.append(current[drop_indexes])\n",
    "        res_ids.append(current[drop_indexes])\n",
    "        \n",
    "    return res_x, res_y, res_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropped_x, dropped_y, dropped_ids = dropLineIfNone(cleaned, split_y, split_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point, the first values in each of the split data has a PRI_jet_num = 0, then 1 and so on. The data is clean and we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(cleaned_with_median[0].shape[1])\n",
    "median_cleaned_x_0_lsq_GD = least_squares_GD(split_y[0], normalize(cleaned_with_median[0]), initial_w, 500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.2155689 , -0.53554557, -0.40401874,  0.03959931,  0.08147027,\n",
      "        0.03959934,  0.16148251,  0.03462872,  0.10957412,  0.5842968 ,\n",
      "        0.05218412,  0.04930115, -0.04715568,  0.05726908,  0.0508691 ,\n",
      "       -0.07238437,  0.03803752, -0.00064042,  0.05024209,  0.05024209]), 0.29714565802617193)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_lsq_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cleaned_x_0_lsq_SGD = least_squares_SGD(split_y[0], normalize(cleaned_with_median[0]), initial_w, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.04836316, -0.10000091, -0.02673626,  0.01805247,  0.02964008,\n",
      "        0.01805247, -0.01776028,  0.02912592,  0.03460342,  0.04191371,\n",
      "        0.03274352,  0.03205406, -0.02365191,  0.03306001,  0.03103124,\n",
      "       -0.00610077,  0.03342681, -0.05820995,  0.03231787,  0.03231787]), 0.3688807319654526)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_lsq_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cleaned_x_0_lsq = least_squares(split_y[0], normalize(cleaned_with_median[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1.19348797e-01, -3.20910781e-01, -7.11010616e-01, -3.61745390e+03,\n",
      "        2.92434098e+01,  3.61754007e+03, -7.97192079e+00, -1.48451124e+01,\n",
      "       -9.21399265e-01,  8.74154018e+00,  1.22199385e-02,  9.00441921e-03,\n",
      "        8.51383385e+00,  1.42330751e-01,  1.82847018e-02, -8.31032487e-02,\n",
      "       -1.72379531e-01,  3.24838123e-02, -9.72704906e+00, -9.72704906e+00]), 0.2599109628362648)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_lsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cleaned_x_0_ridge = ridge_regression(split_y[0], normalize(cleaned_with_median[0]), 0.037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.06227524, -0.46079671, -0.13201699,  0.0411997 ,  0.05966671,\n",
      "        0.04119971,  0.1212882 ,  0.04336166,  0.07570685,  0.32090765,\n",
      "        0.05564915,  0.05486386, -0.05369323,  0.05732194,  0.05516295,\n",
      "       -0.06514523,  0.05211816,  0.00402923,  0.05500482,  0.05500482]), 0.3046039439677196)\n"
     ]
    }
   ],
   "source": [
    "print(median_cleaned_x_0_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benoit/Documents/EPFL/Master/MA1/MachineLearning/project1/ML_course_project1/scripts/implementations.py:78: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-z))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0aec7208057b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmedian_cleaned_x_0_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_with_median\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/EPFL/Master/MA1/MachineLearning/project1/ML_course_project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/Master/MA1/MachineLearning/project1/ML_course_project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "median_cleaned_x_0_log = logistic_regression(split_y[0], normalize(cleaned_with_median[0]), initial_w, 10000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(median_cleaned_x_0_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Expension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "   \n",
    "    x_extended = np.ones(shape=x.shape)\n",
    "\n",
    "    for d in range (1, degree +1):\n",
    "        x_extended = np.c_[x_extended, x**d]\n",
    "        \n",
    "\n",
    "    return x_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.,  2.,  3.,  4.,  1.,  4.,  9., 16.],\n",
       "       [ 1.,  1.,  1.,  1.,  5.,  6.,  7.,  8., 25., 36., 49., 64.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "build_poly(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to split the training set into a (new) training set and a test set (same as in lab03)\n",
    "\n",
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    " \n",
    "    # split the data based on the given ratio\n",
    "\n",
    "    training_nbr = int(x.shape[0] * ratio)\n",
    "    indexes = np.random.choice(x.shape[0],training_nbr, replace=False)\n",
    "    \n",
    "    x_train = x[indexes]\n",
    "    y_train = y[indexes]\n",
    "    x_test = np.delete(x, indexes, axis = 0)\n",
    "    y_test = np.delete(y, indexes, axis = 0)\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross-validation \n",
    "\n",
    "def crossValidation(x, y, splitRatio, degrees, seed =1):\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = split_data(x, y, splitRatio, seed)\n",
    "    \n",
    "    a_training = []\n",
    "    a_testing = []\n",
    "    weights = []\n",
    "    degr = []\n",
    "    \n",
    "    # define parameter (just add more for loops if there are more parameters for the model)\n",
    "    lambdas = np.arange(0,0.03,0.0005)\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        \n",
    "        for ind_d, d in enumerate(degrees):\n",
    "            \n",
    "            \n",
    "            #perform polynomial feature expension\n",
    "            x_test_poly = build_poly(x_test,d)\n",
    "            x_train_poly = build_poly(x_train, d)\n",
    "            \n",
    "            #normalize data (DANGER: the test set must be normalized with the training set's mean and std)\n",
    "            mean = np.mean(x_train_poly)\n",
    "            std = np.std(x_train_poly)\n",
    "            \n",
    "            x_train_ready = (x_train_poly - mean) / std\n",
    "            x_test_ready = (x_test_poly - mean) / std\n",
    "           \n",
    "            \n",
    "            #Models\n",
    "        \n",
    "            #ideal : lambdas = np.arange(0,0.03,0.001)\n",
    "            w_star, e_tr = ridge_regression(y_train,x_train_ready, lambda_)\n",
    "        \n",
    "            #ideal : lambdas = np.arange(0,0.3,0.1)\n",
    "            #w_star, e_tr = logistic_regression(y_train, x_train_ready,np.ones(x_train_ready.shape[1])  ,400, lambda_)\n",
    "        \n",
    "            #don't usel least squares with lambda bigger than 0.35 ideal: lambdas = np.arange(0.001,0.13,0.01)\n",
    "            #w_star, e_tr = least_squares_GD(y_train, x_train_ready,np.ones(x_train_ready.shape[1])  ,400, lambda_)    \n",
    "            #w_star, e_tr = least_squares_SGD(y_train, x_train,np.ones(x_train.shape[1])  ,400, lambda_)\n",
    "        \n",
    "            #DON'T REALLY NEED TO DO CROSS VALIDATION FOR THIS ONE ;) BUT PRACTICAL TO RUN IT HERE\n",
    "            #w_star, e_tr = least_squares(y_train, x_train_ready)  \n",
    "        \n",
    "            degr.append(d)\n",
    "        \n",
    "            #compare the prediction with the reality\n",
    "            accuracy_training = np.count_nonzero(predict_labels(w_star, x_train_ready) + y_train)/len(y_train)\n",
    "            accuracy_testing = np.count_nonzero(predict_labels(w_star, x_test_ready) + y_test)/len(y_test)\n",
    "        \n",
    "            a_training.append(accuracy_training)\n",
    "            a_testing.append(accuracy_testing)\n",
    "            weights.append(w_star)\n",
    "            print(\"lambda={l:.5f},degree={deg}, Training Accuracy={tr}, Testing Accuracy={te}\".format(\n",
    "                   l=lambda_, tr=a_training[ind*len(degrees)+ind_d], te=a_testing[ind*len(degrees)+ind_d], deg=d))\n",
    "        \n",
    "            #plt.plot(lambdas, a_training,'r--' , lambdas, a_testing, 'g--')\n",
    "            #plt.show\n",
    "    \n",
    "    return weights[np.argmax(a_testing)], degr[np.argmax(a_testing)], a_testing[np.argmax(a_testing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross-validation \n",
    "\n",
    "def crossValidationForLogistic_reg(x, y, splitRatio, degrees, seed =1):\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = split_data(x, y, splitRatio, seed)\n",
    "    \n",
    "    a_training = []\n",
    "    a_testing = []\n",
    "    weights = []\n",
    "    degr = []\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    # define parameter (just add more for loops if there are more parameters for the model)\n",
    "    lambdas = np.arange(0,0.3,0.01)\n",
    "    gammas = np.arange(0,0.03,0.0005)\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        \n",
    "        for ind_d, d in enumerate(degrees):\n",
    "            \n",
    "            for ind_g, gamma in enumerate(gammas):\n",
    "            \n",
    "                #perform polynomial feature expension\n",
    "                x_test_poly = build_poly(x_test,d)\n",
    "                x_train_poly = build_poly(x_train, d)\n",
    "            \n",
    "                #normalize data (DANGER: the test set must be normalized with the training set's mean and std)\n",
    "                mean = np.mean(x_train_poly)\n",
    "                std = np.std(x_train_poly)\n",
    "            \n",
    "                x_train_ready = (x_train_poly - mean) / std\n",
    "                x_test_ready = (x_test_poly - mean) / std\n",
    "           \n",
    "            \n",
    "                #Model\n",
    "        \n",
    "                #ideal : lambdas = np.arange(0,0.03,0.001)\n",
    "                w_star, e_tr = reg_logistic_regression(y_train, x_train_ready, lambda_, np.ones(x_test_ready.shape[1]), 400, gamma)\n",
    "        \n",
    "           \n",
    "                degr.append(d)\n",
    "        \n",
    "                #compare the prediction with the reality\n",
    "                accuracy_training = np.count_nonzero(predict_labels(w_star, x_train_ready) + y_train)/len(y_train)\n",
    "                accuracy_testing = np.count_nonzero(predict_labels(w_star, x_test_ready) + y_test)/len(y_test)\n",
    "        \n",
    "                a_training.append(accuracy_training)\n",
    "                a_testing.append(accuracy_testing)\n",
    "                weights.append(w_star)\n",
    "                print(\"lambda={l:.5f},degree={deg}, Training Accuracy={tr}, Testing Accuracy={te}\".format(\n",
    "                       l=lambda_, tr=a_training[index], te=a_testing[index], deg=d))\n",
    "        \n",
    "                #increment index\n",
    "                index = index + 1\n",
    "    \n",
    "    return weights[np.argmax(a_testing)], degr[np.argmax(a_testing)], a_testing[np.argmax(a_testing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_together(labels, indices):\n",
    "    \n",
    "    #First build first chunk\n",
    "    ids_0 = np.matrix(indices[0]).T\n",
    "    lab_0 = np.matrix(labels[0]).T\n",
    "    \n",
    "    unsorted_res = np.concatenate((ids_0, lab_0), axis=1)\n",
    "    \n",
    "    for i in range(1,len(labels)):\n",
    "        ids = np.matrix(indices[i]).T\n",
    "        lab = np.matrix(labels[i]).T\n",
    "        by_jet_num = np.concatenate((ids, lab), axis=1)\n",
    "        unsorted_res = np.concatenate((unsorted_res, by_jet_num), axis=0)\n",
    "    \n",
    "    sorted_res = unsorted_res[np.lexsort(np.fliplr(unsorted_res).T)]\n",
    "    \n",
    "    return sorted_res[0,:,:][:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "y_donotUse, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics \n",
      "Type :\n",
      "0\n",
      "[0.2605448 0.        0.        0.        1.        1.        1.\n",
      " 0.        0.        0.        0.        0.        1.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        1.        1.        1.        1.        1.\n",
      " 1.        0.       ]\n",
      "Statistics \n",
      "Type :\n",
      "1\n",
      "[0.09834149 0.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "2\n",
      "[0.05881481 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "Statistics \n",
      "Type :\n",
      "3\n",
      "[0.06376737 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "lambda=0.00000,degree=1, Training Accuracy=0.8237207556612035, Testing Accuracy=0.8295050793174198\n",
      "lambda=0.00000,degree=2, Training Accuracy=0.8277367696734643, Testing Accuracy=0.8329079717760096\n",
      "lambda=0.00000,degree=3, Training Accuracy=0.8006881020893282, Testing Accuracy=0.807035980583496\n",
      "lambda=0.00000,degree=4, Training Accuracy=0.7430501688977855, Testing Accuracy=0.7494870640044038\n",
      "lambda=0.00000,degree=5, Training Accuracy=0.7432628549981234, Testing Accuracy=0.7495871490767152\n",
      "lambda=0.00000,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=7, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=8, Training Accuracy=0.7436381834104842, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=9, Training Accuracy=0.7436381834104842, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=10, Training Accuracy=0.7436381834104842, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=1, Training Accuracy=0.8051670211435006, Testing Accuracy=0.8097883200720613\n",
      "lambda=0.00050,degree=2, Training Accuracy=0.7572375828850244, Testing Accuracy=0.7652004203573037\n",
      "lambda=0.00050,degree=3, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00050,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00050,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=1, Training Accuracy=0.803678218441136, Testing Accuracy=0.8092378521743482\n",
      "lambda=0.00100,degree=2, Training Accuracy=0.7551232328287252, Testing Accuracy=0.7632988039833859\n",
      "lambda=0.00100,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00100,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00100,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=1, Training Accuracy=0.803227824346303, Testing Accuracy=0.8094380223189711\n",
      "lambda=0.00150,degree=2, Training Accuracy=0.7536219191792819, Testing Accuracy=0.7619476555071811\n",
      "lambda=0.00150,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00150,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00150,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=1, Training Accuracy=0.8026648317277618, Testing Accuracy=0.8095381073912826\n",
      "lambda=0.00200,degree=2, Training Accuracy=0.7527336419366946, Testing Accuracy=0.7612971025371565\n",
      "lambda=0.00200,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00200,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00200,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=1, Training Accuracy=0.8022144376329288, Testing Accuracy=0.8089876394935696\n",
      "lambda=0.00250,degree=2, Training Accuracy=0.7518703865882648, Testing Accuracy=0.7603462943501976\n",
      "lambda=0.00250,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00250,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00250,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00250,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=1, Training Accuracy=0.8020267734267484, Testing Accuracy=0.8085372566681679\n",
      "lambda=0.00300,degree=2, Training Accuracy=0.7509821093456774, Testing Accuracy=0.7596456988440174\n",
      "lambda=0.00300,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00300,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00300,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=1, Training Accuracy=0.8017765544851745, Testing Accuracy=0.808337086523545\n",
      "lambda=0.00350,degree=2, Training Accuracy=0.7506067809333167, Testing Accuracy=0.758594805584747\n",
      "lambda=0.00350,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00350,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00350,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=1, Training Accuracy=0.8014762917552859, Testing Accuracy=0.8082370014512336\n",
      "lambda=0.00400,degree=2, Training Accuracy=0.7499687226323033, Testing Accuracy=0.7579942951508782\n",
      "lambda=0.00400,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00400,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00400,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=1, Training Accuracy=0.801188539972476, Testing Accuracy=0.808136916378922\n",
      "lambda=0.00450,degree=2, Training Accuracy=0.7494933066433129, Testing Accuracy=0.757293699644698\n",
      "lambda=0.00450,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00450,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00450,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=1, Training Accuracy=0.8011510071312399, Testing Accuracy=0.8079867887704549\n",
      "lambda=0.00500,degree=2, Training Accuracy=0.7490429125484799, Testing Accuracy=0.7567932742831407\n",
      "lambda=0.00500,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00500,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00500,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=1, Training Accuracy=0.8009883648192169, Testing Accuracy=0.8078366611619877\n",
      "lambda=0.00550,degree=2, Training Accuracy=0.7485674965594895, Testing Accuracy=0.7560426362408047\n",
      "lambda=0.00550,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00550,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00550,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=1, Training Accuracy=0.800775678718879, Testing Accuracy=0.807586448481209\n",
      "lambda=0.00600,degree=2, Training Accuracy=0.7480420367821844, Testing Accuracy=0.7557423810238703\n",
      "lambda=0.00600,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00600,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00600,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00600,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=1, Training Accuracy=0.8005254597773052, Testing Accuracy=0.807586448481209\n",
      "lambda=0.00650,degree=2, Training Accuracy=0.7477417740522958, Testing Accuracy=0.7553920832707801\n",
      "lambda=0.00650,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00650,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00650,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=1, Training Accuracy=0.8004003503065182, Testing Accuracy=0.8071861081919631\n",
      "lambda=0.00700,degree=2, Training Accuracy=0.747403978481171, Testing Accuracy=0.7548916579092229\n",
      "lambda=0.00700,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00700,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00700,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=1, Training Accuracy=0.8003878393594395, Testing Accuracy=0.8069358955111845\n",
      "lambda=0.00750,degree=2, Training Accuracy=0.7472163142749906, Testing Accuracy=0.7542411049391983\n",
      "lambda=0.00750,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00750,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00750,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=1, Training Accuracy=0.8002752408357313, Testing Accuracy=0.8066856828304059\n",
      "lambda=0.00800,degree=2, Training Accuracy=0.7471662704866758, Testing Accuracy=0.7539408497222639\n",
      "lambda=0.00800,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00800,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00800,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=1, Training Accuracy=0.8002502189415739, Testing Accuracy=0.8065855977580944\n",
      "lambda=0.00850,degree=2, Training Accuracy=0.7470912048042037, Testing Accuracy=0.7533903818245509\n",
      "lambda=0.00850,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00850,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00850,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=1, Training Accuracy=0.8000250218941574, Testing Accuracy=0.8065355552219386\n",
      "lambda=0.00900,degree=2, Training Accuracy=0.7467909420743151, Testing Accuracy=0.7530400840714607\n",
      "lambda=0.00900,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00900,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00900,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=1, Training Accuracy=0.7998498686350557, Testing Accuracy=0.8063854276134714\n",
      "lambda=0.00950,degree=2, Training Accuracy=0.7465657450268985, Testing Accuracy=0.7526397437822149\n",
      "lambda=0.00950,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.00950,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00950,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00950,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=1, Training Accuracy=0.7996747153759539, Testing Accuracy=0.80628534254116\n",
      "lambda=0.01000,degree=2, Training Accuracy=0.7464031027148755, Testing Accuracy=0.7524896161737477\n",
      "lambda=0.01000,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01000,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01000,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=1, Training Accuracy=0.7996496934817966, Testing Accuracy=0.80628534254116\n",
      "lambda=0.01050,degree=2, Training Accuracy=0.7462279494557738, Testing Accuracy=0.752239403492969\n",
      "lambda=0.01050,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01050,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01050,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=1, Training Accuracy=0.7995120730639309, Testing Accuracy=0.8060851723965371\n",
      "lambda=0.01100,degree=2, Training Accuracy=0.7459527086200426, Testing Accuracy=0.7517389781314117\n",
      "lambda=0.01100,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01100,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01100,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=1, Training Accuracy=0.7995120730639309, Testing Accuracy=0.8058850022519142\n",
      "lambda=0.01150,degree=2, Training Accuracy=0.7457650444138622, Testing Accuracy=0.7515388079867887\n",
      "lambda=0.01150,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01150,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01150,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=1, Training Accuracy=0.7994995621168522, Testing Accuracy=0.805734874643447\n",
      "lambda=0.01200,degree=2, Training Accuracy=0.7455773802076817, Testing Accuracy=0.7513886803783216\n",
      "lambda=0.01200,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01200,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01200,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=1, Training Accuracy=0.7994119854873014, Testing Accuracy=0.8054846619626682\n",
      "lambda=0.01250,degree=2, Training Accuracy=0.7452896284248718, Testing Accuracy=0.7510383826252315\n",
      "lambda=0.01250,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01250,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01250,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=1, Training Accuracy=0.7992993869635932, Testing Accuracy=0.8053845768903568\n",
      "lambda=0.01300,degree=2, Training Accuracy=0.74511447516577, Testing Accuracy=0.7507881699444527\n",
      "lambda=0.01300,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01300,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01300,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=1, Training Accuracy=0.7990491680220193, Testing Accuracy=0.8052844918180453\n",
      "lambda=0.01350,degree=2, Training Accuracy=0.7449143000125109, Testing Accuracy=0.7507881699444527\n",
      "lambda=0.01350,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01350,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01350,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=1, Training Accuracy=0.7990867008632554, Testing Accuracy=0.8049341940649553\n",
      "lambda=0.01400,degree=2, Training Accuracy=0.7446765920180157, Testing Accuracy=0.7508382124806086\n",
      "lambda=0.01400,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01400,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01400,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=1, Training Accuracy=0.798899036657075, Testing Accuracy=0.8049341940649553\n",
      "lambda=0.01450,degree=2, Training Accuracy=0.7446015263355436, Testing Accuracy=0.7506880848721413\n",
      "lambda=0.01450,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01450,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01450,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=1, Training Accuracy=0.7987614162392093, Testing Accuracy=0.8047340239203323\n",
      "lambda=0.01500,degree=2, Training Accuracy=0.7445014387589141, Testing Accuracy=0.7506380423359856\n",
      "lambda=0.01500,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01500,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01500,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=1, Training Accuracy=0.7986863505567371, Testing Accuracy=0.8045838963118651\n",
      "lambda=0.01550,degree=2, Training Accuracy=0.7443638183410484, Testing Accuracy=0.7505379572636741\n",
      "lambda=0.01550,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01550,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01550,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=1, Training Accuracy=0.7985237082447141, Testing Accuracy=0.8044838112395536\n",
      "lambda=0.01600,degree=2, Training Accuracy=0.7442762417114975, Testing Accuracy=0.7502377020467397\n",
      "lambda=0.01600,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01600,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01600,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=1, Training Accuracy=0.7984611535093207, Testing Accuracy=0.8041835560226193\n",
      "lambda=0.01650,degree=2, Training Accuracy=0.7441135993994745, Testing Accuracy=0.7500875744382726\n",
      "lambda=0.01650,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01650,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01650,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01650,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=1, Training Accuracy=0.7983860878268485, Testing Accuracy=0.804033428414152\n",
      "lambda=0.01700,degree=2, Training Accuracy=0.7439509570874515, Testing Accuracy=0.749987489365961\n",
      "lambda=0.01700,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01700,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01700,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=1, Training Accuracy=0.7982734893031402, Testing Accuracy=0.8038332582695291\n",
      "lambda=0.01750,degree=2, Training Accuracy=0.7438383585637433, Testing Accuracy=0.7498874042936496\n",
      "lambda=0.01750,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01750,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01750,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=1, Training Accuracy=0.7981483798323533, Testing Accuracy=0.8035830455887505\n",
      "lambda=0.01800,degree=2, Training Accuracy=0.7437007381458777, Testing Accuracy=0.7499374468298053\n",
      "lambda=0.01800,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01800,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01800,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=1, Training Accuracy=0.7980232703615664, Testing Accuracy=0.8035830455887505\n",
      "lambda=0.01850,degree=2, Training Accuracy=0.7436381834104842, Testing Accuracy=0.7498874042936496\n",
      "lambda=0.01850,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01850,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01850,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=1, Training Accuracy=0.7978856499437007, Testing Accuracy=0.8034329179802833\n",
      "lambda=0.01900,degree=2, Training Accuracy=0.7435255848867759, Testing Accuracy=0.7497372766851824\n",
      "lambda=0.01900,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01900,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01900,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=1, Training Accuracy=0.7978105842612285, Testing Accuracy=0.8035330030525947\n",
      "lambda=0.01950,degree=2, Training Accuracy=0.7434129863630676, Testing Accuracy=0.7497873192213381\n",
      "lambda=0.01950,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.01950,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.01950,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=1, Training Accuracy=0.7976229200550482, Testing Accuracy=0.8035330030525947\n",
      "lambda=0.02000,degree=2, Training Accuracy=0.7433629425747529, Testing Accuracy=0.7495371065405595\n",
      "lambda=0.02000,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02000,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02000,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02000,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=1, Training Accuracy=0.7975853872138121, Testing Accuracy=0.8035330030525947\n",
      "lambda=0.02050,degree=2, Training Accuracy=0.7432253221568873, Testing Accuracy=0.7493869789320923\n",
      "lambda=0.02050,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02050,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02050,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=1, Training Accuracy=0.7974978105842613, Testing Accuracy=0.803482960516439\n",
      "lambda=0.02100,degree=2, Training Accuracy=0.7430251470036282, Testing Accuracy=0.7492868938597809\n",
      "lambda=0.02100,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02100,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02100,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=1, Training Accuracy=0.7974477667959464, Testing Accuracy=0.8034329179802833\n",
      "lambda=0.02150,degree=2, Training Accuracy=0.7429751032153133, Testing Accuracy=0.749236851323625\n",
      "lambda=0.02150,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02150,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02150,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=1, Training Accuracy=0.7972851244839234, Testing Accuracy=0.8031827052995045\n",
      "lambda=0.02200,degree=2, Training Accuracy=0.7429375703740774, Testing Accuracy=0.7491868087874693\n",
      "lambda=0.02200,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02200,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02200,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=1, Training Accuracy=0.79722256974853, Testing Accuracy=0.803282790371816\n",
      "lambda=0.02250,degree=2, Training Accuracy=0.7428875265857625, Testing Accuracy=0.7489365961066907\n",
      "lambda=0.02250,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02250,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02250,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=1, Training Accuracy=0.797059927436507, Testing Accuracy=0.8030826202271931\n",
      "lambda=0.02300,degree=2, Training Accuracy=0.7427624171149756, Testing Accuracy=0.7488865535705349\n",
      "lambda=0.02300,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02300,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02300,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=1, Training Accuracy=0.7969598398598774, Testing Accuracy=0.8029825351548816\n",
      "lambda=0.02350,degree=2, Training Accuracy=0.7427749280620543, Testing Accuracy=0.7487864684982235\n",
      "lambda=0.02350,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02350,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02350,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02350,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=1, Training Accuracy=0.7968222194420118, Testing Accuracy=0.8029324926187259\n",
      "lambda=0.02400,degree=2, Training Accuracy=0.7427123733266608, Testing Accuracy=0.7487364259620678\n",
      "lambda=0.02400,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02400,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02400,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=1, Training Accuracy=0.7967596647066183, Testing Accuracy=0.8029825351548816\n",
      "lambda=0.02450,degree=2, Training Accuracy=0.7426623295383461, Testing Accuracy=0.7486363408897563\n",
      "lambda=0.02450,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02450,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02450,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=1, Training Accuracy=0.7966595771299887, Testing Accuracy=0.802732322474103\n",
      "lambda=0.02500,degree=2, Training Accuracy=0.7426373076441887, Testing Accuracy=0.748686383425912\n",
      "lambda=0.02500,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02500,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02500,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=1, Training Accuracy=0.7965094457650445, Testing Accuracy=0.80253215232948\n",
      "lambda=0.02550,degree=2, Training Accuracy=0.7427123733266608, Testing Accuracy=0.748686383425912\n",
      "lambda=0.02550,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02550,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02550,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=1, Training Accuracy=0.7964093581884149, Testing Accuracy=0.8024320672571686\n",
      "lambda=0.02600,degree=2, Training Accuracy=0.7426873514325034, Testing Accuracy=0.7487364259620678\n",
      "lambda=0.02600,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02600,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02600,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=1, Training Accuracy=0.7963342925059427, Testing Accuracy=0.8023319821848571\n",
      "lambda=0.02650,degree=2, Training Accuracy=0.7426373076441887, Testing Accuracy=0.7486363408897563\n",
      "lambda=0.02650,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02650,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02650,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=1, Training Accuracy=0.7961216064056049, Testing Accuracy=0.8022318971125456\n",
      "lambda=0.02700,degree=2, Training Accuracy=0.74262479669711, Testing Accuracy=0.7486363408897563\n",
      "lambda=0.02700,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02700,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02700,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02700,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=1, Training Accuracy=0.795996496934818, Testing Accuracy=0.8020817695040785\n",
      "lambda=0.02750,degree=2, Training Accuracy=0.7426498185912673, Testing Accuracy=0.7485862983536006\n",
      "lambda=0.02750,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02750,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02750,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=1, Training Accuracy=0.7958463655698736, Testing Accuracy=0.8017314717509884\n",
      "lambda=0.02800,degree=2, Training Accuracy=0.74262479669711, Testing Accuracy=0.748686383425912\n",
      "lambda=0.02800,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02800,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02800,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=1, Training Accuracy=0.7957212560990867, Testing Accuracy=0.8016814292148327\n",
      "lambda=0.02850,degree=2, Training Accuracy=0.74262479669711, Testing Accuracy=0.7485362558174449\n",
      "lambda=0.02850,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02850,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02850,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=1, Training Accuracy=0.7956962342049293, Testing Accuracy=0.8015813441425211\n",
      "lambda=0.02900,degree=2, Training Accuracy=0.7425497310146378, Testing Accuracy=0.7484862132812891\n",
      "lambda=0.02900,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02900,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02900,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=1, Training Accuracy=0.7956962342049293, Testing Accuracy=0.8014812590702097\n",
      "lambda=0.02950,degree=2, Training Accuracy=0.7425372200675591, Testing Accuracy=0.7485362558174449\n",
      "lambda=0.02950,degree=3, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=4, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=5, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=6, Training Accuracy=0.7435756286750907, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=7, Training Accuracy=0.7435005629926186, Testing Accuracy=0.7496371916128709\n",
      "lambda=0.02950,degree=8, Training Accuracy=0.7436006505692481, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=9, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=10, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=11, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.02950,degree=12, Training Accuracy=0.7436256724634055, Testing Accuracy=0.7498373617574938\n",
      "lambda=0.00000,degree=1, Training Accuracy=0.7152413959861369, Testing Accuracy=0.7102327680701528\n",
      "lambda=0.00000,degree=2, Training Accuracy=0.7609575239783993, Testing Accuracy=0.7582049132761622\n",
      "lambda=0.00000,degree=3, Training Accuracy=0.7286531796566454, Testing Accuracy=0.7224192404410342\n",
      "lambda=0.00000,degree=4, Training Accuracy=0.6624486177158055, Testing Accuracy=0.6567799342317364\n",
      "lambda=0.00000,degree=5, Training Accuracy=0.6466833239300395, Testing Accuracy=0.644593461860855\n",
      "lambda=0.00000,degree=6, Training Accuracy=0.6448617715805594, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.00000,degree=7, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00000,degree=8, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00000,degree=9, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00000,degree=10, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00000,degree=11, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00000,degree=12, Training Accuracy=0.6431530587571532, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00050,degree=1, Training Accuracy=0.7038607237849601, Testing Accuracy=0.697014636662583\n",
      "lambda=0.00050,degree=2, Training Accuracy=0.6545014910937375, Testing Accuracy=0.6513637242891225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00050,degree=3, Training Accuracy=0.6456032884661884, Testing Accuracy=0.644528983171062\n",
      "lambda=0.00050,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6427235798568574\n",
      "lambda=0.00050,degree=5, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00050,degree=6, Training Accuracy=0.6431530587571532, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00050,degree=7, Training Accuracy=0.6430402192310792, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00050,degree=8, Training Accuracy=0.6430885790279681, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00050,degree=9, Training Accuracy=0.6430724590956718, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00050,degree=10, Training Accuracy=0.6430563391633756, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00050,degree=11, Training Accuracy=0.6429596195695978, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00050,degree=12, Training Accuracy=0.6429757395018941, Testing Accuracy=0.6427235798568574\n",
      "lambda=0.00100,degree=1, Training Accuracy=0.7016684129926655, Testing Accuracy=0.6954026694177574\n",
      "lambda=0.00100,degree=2, Training Accuracy=0.6535020552913677, Testing Accuracy=0.6506544587013992\n",
      "lambda=0.00100,degree=3, Training Accuracy=0.6454904489401144, Testing Accuracy=0.644528983171062\n",
      "lambda=0.00100,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00100,degree=5, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00100,degree=6, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00100,degree=7, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00100,degree=8, Training Accuracy=0.6431691786894495, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00100,degree=9, Training Accuracy=0.6431691786894495, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00100,degree=10, Training Accuracy=0.6431530587571532, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00100,degree=11, Training Accuracy=0.6430563391633756, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00100,degree=12, Training Accuracy=0.6430079793664867, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00150,degree=1, Training Accuracy=0.7003304586120739, Testing Accuracy=0.6946934038300342\n",
      "lambda=0.00150,degree=2, Training Accuracy=0.6531957765777384, Testing Accuracy=0.6496872783545038\n",
      "lambda=0.00150,degree=3, Training Accuracy=0.6455388087370033, Testing Accuracy=0.6442065897220969\n",
      "lambda=0.00150,degree=4, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00150,degree=5, Training Accuracy=0.6433787378093012, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00150,degree=6, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00150,degree=7, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00150,degree=8, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00150,degree=9, Training Accuracy=0.6432014185540421, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00150,degree=10, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00150,degree=11, Training Accuracy=0.6431369388248569, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00150,degree=12, Training Accuracy=0.6430079793664867, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00200,degree=1, Training Accuracy=0.699492222132667, Testing Accuracy=0.6934683087239667\n",
      "lambda=0.00200,degree=2, Training Accuracy=0.6526960586765536, Testing Accuracy=0.6494938422851247\n",
      "lambda=0.00200,degree=3, Training Accuracy=0.6454904489401144, Testing Accuracy=0.6441421110323038\n",
      "lambda=0.00200,degree=4, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00200,degree=5, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00200,degree=6, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00200,degree=7, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00200,degree=8, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00200,degree=9, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00200,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00200,degree=11, Training Accuracy=0.6432014185540421, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00200,degree=12, Training Accuracy=0.6431208188925607, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00250,degree=1, Training Accuracy=0.698750705247038, Testing Accuracy=0.6932103939647947\n",
      "lambda=0.00250,degree=2, Training Accuracy=0.6524220198275167, Testing Accuracy=0.6496872783545038\n",
      "lambda=0.00250,degree=3, Training Accuracy=0.6455065688724108, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.00250,degree=4, Training Accuracy=0.6438139759813009, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00250,degree=5, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00250,degree=6, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00250,degree=7, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00250,degree=8, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00250,degree=9, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00250,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00250,degree=11, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00250,degree=12, Training Accuracy=0.6431369388248569, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00300,degree=1, Training Accuracy=0.6983154670750383, Testing Accuracy=0.6923076923076923\n",
      "lambda=0.00300,degree=2, Training Accuracy=0.6519545417909245, Testing Accuracy=0.6491714488361596\n",
      "lambda=0.00300,degree=3, Training Accuracy=0.6453292496171517, Testing Accuracy=0.6444000257914759\n",
      "lambda=0.00300,degree=4, Training Accuracy=0.6438139759813009, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00300,degree=5, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00300,degree=6, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00300,degree=7, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00300,degree=8, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00300,degree=9, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00300,degree=10, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.00300,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00300,degree=12, Training Accuracy=0.6431691786894495, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00350,degree=1, Training Accuracy=0.6979124687676311, Testing Accuracy=0.6917918627893481\n",
      "lambda=0.00350,degree=2, Training Accuracy=0.6517288627387765, Testing Accuracy=0.6489780127667806\n",
      "lambda=0.00350,degree=3, Training Accuracy=0.6454259692109293, Testing Accuracy=0.6442065897220969\n",
      "lambda=0.00350,degree=4, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00350,degree=5, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00350,degree=6, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00350,degree=7, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00350,degree=8, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00350,degree=9, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00350,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.00350,degree=11, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00350,degree=12, Training Accuracy=0.6431691786894495, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00400,degree=1, Training Accuracy=0.6976867897154831, Testing Accuracy=0.691469469340383\n",
      "lambda=0.00400,degree=2, Training Accuracy=0.6514225840251471, Testing Accuracy=0.6488490553871945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00400,degree=3, Training Accuracy=0.6455065688724108, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.00400,degree=4, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00400,degree=5, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00400,degree=6, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00400,degree=7, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00400,degree=8, Training Accuracy=0.6433787378093012, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00400,degree=9, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00400,degree=10, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00400,degree=11, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00400,degree=12, Training Accuracy=0.6431852986217458, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00450,degree=1, Training Accuracy=0.697219311678891, Testing Accuracy=0.6911470758914179\n",
      "lambda=0.00450,degree=2, Training Accuracy=0.6513419843636656, Testing Accuracy=0.6485911406280225\n",
      "lambda=0.00450,degree=3, Training Accuracy=0.6455065688724108, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.00450,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00450,degree=5, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00450,degree=6, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00450,degree=7, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00450,degree=8, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00450,degree=9, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00450,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00450,degree=11, Training Accuracy=0.6431852986217458, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00450,degree=12, Training Accuracy=0.6431852986217458, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00500,degree=1, Training Accuracy=0.6969775126944466, Testing Accuracy=0.6912115545812109\n",
      "lambda=0.00500,degree=2, Training Accuracy=0.651132425243814, Testing Accuracy=0.6484621832484364\n",
      "lambda=0.00500,degree=3, Training Accuracy=0.6455388087370033, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.00500,degree=4, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00500,degree=5, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00500,degree=6, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00500,degree=7, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00500,degree=8, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00500,degree=9, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00500,degree=10, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00500,degree=11, Training Accuracy=0.6431852986217458, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00500,degree=12, Training Accuracy=0.6431852986217458, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00550,degree=1, Training Accuracy=0.6966712339808173, Testing Accuracy=0.6907602037526598\n",
      "lambda=0.00550,degree=2, Training Accuracy=0.6509228661239623, Testing Accuracy=0.6481397897994713\n",
      "lambda=0.00550,degree=3, Training Accuracy=0.6455388087370033, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.00550,degree=4, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00550,degree=5, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00550,degree=6, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00550,degree=7, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00550,degree=8, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00550,degree=9, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00550,degree=10, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00550,degree=11, Training Accuracy=0.6432014185540421, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00550,degree=12, Training Accuracy=0.6432014185540421, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00600,degree=1, Training Accuracy=0.6962682356734101, Testing Accuracy=0.6904378103036947\n",
      "lambda=0.00600,degree=2, Training Accuracy=0.6507777867332957, Testing Accuracy=0.6480753111096782\n",
      "lambda=0.00600,degree=3, Training Accuracy=0.6455065688724108, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.00600,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00600,degree=5, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00600,degree=6, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00600,degree=7, Training Accuracy=0.6433787378093012, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.00600,degree=8, Training Accuracy=0.6433787378093012, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00600,degree=9, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00600,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00600,degree=11, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00600,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00650,degree=1, Training Accuracy=0.6958813572982994, Testing Accuracy=0.6903088529241086\n",
      "lambda=0.00650,degree=2, Training Accuracy=0.6508583863947771, Testing Accuracy=0.6480753111096782\n",
      "lambda=0.00650,degree=3, Training Accuracy=0.6454259692109293, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.00650,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00650,degree=5, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.00650,degree=6, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00650,degree=7, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00650,degree=8, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00650,degree=9, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00650,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00650,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00650,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00700,degree=1, Training Accuracy=0.6955911985169663, Testing Accuracy=0.6903088529241086\n",
      "lambda=0.00700,degree=2, Training Accuracy=0.6508261465301846, Testing Accuracy=0.6480753111096782\n",
      "lambda=0.00700,degree=3, Training Accuracy=0.6453453695494479, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.00700,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00700,degree=5, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00700,degree=6, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00700,degree=7, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00700,degree=8, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00700,degree=9, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00700,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00700,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00700,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00750,degree=1, Training Accuracy=0.6953655194648183, Testing Accuracy=0.6899219807853505\n",
      "lambda=0.00750,degree=2, Training Accuracy=0.6508261465301846, Testing Accuracy=0.6478818750402991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00750,degree=3, Training Accuracy=0.6453292496171517, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.00750,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00750,degree=5, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00750,degree=6, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.00750,degree=7, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.00750,degree=8, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00750,degree=9, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00750,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00750,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00750,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00800,degree=1, Training Accuracy=0.6948658015636334, Testing Accuracy=0.6899219807853505\n",
      "lambda=0.00800,degree=2, Training Accuracy=0.6507133070041106, Testing Accuracy=0.647559481591334\n",
      "lambda=0.00800,degree=3, Training Accuracy=0.6453453695494479, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.00800,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00800,degree=5, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.00800,degree=6, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.00800,degree=7, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.00800,degree=8, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00800,degree=9, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00800,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00800,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.00800,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00850,degree=1, Training Accuracy=0.6945756427823003, Testing Accuracy=0.6897285447159713\n",
      "lambda=0.00850,degree=2, Training Accuracy=0.65045538808737, Testing Accuracy=0.647301566832162\n",
      "lambda=0.00850,degree=3, Training Accuracy=0.6453453695494479, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.00850,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00850,degree=5, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.00850,degree=6, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.00850,degree=7, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.00850,degree=8, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.00850,degree=9, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00850,degree=10, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00850,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00850,degree=12, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00900,degree=1, Training Accuracy=0.6942693640686709, Testing Accuracy=0.6895995873363854\n",
      "lambda=0.00900,degree=2, Training Accuracy=0.6501974691706295, Testing Accuracy=0.647108130762783\n",
      "lambda=0.00900,degree=3, Training Accuracy=0.645297009752559, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.00900,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00900,degree=5, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00900,degree=6, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.00900,degree=7, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.00900,degree=8, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00900,degree=9, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00900,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.00900,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00900,degree=12, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00950,degree=1, Training Accuracy=0.6941887644071895, Testing Accuracy=0.6894706299567993\n",
      "lambda=0.00950,degree=2, Training Accuracy=0.6500201499153704, Testing Accuracy=0.647108130762783\n",
      "lambda=0.00950,degree=3, Training Accuracy=0.6453131296848553, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.00950,degree=4, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.00950,degree=5, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.00950,degree=6, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.00950,degree=7, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.00950,degree=8, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.00950,degree=9, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.00950,degree=10, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00950,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.00950,degree=12, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.01000,degree=1, Training Accuracy=0.6937857660997824, Testing Accuracy=0.6892127151976272\n",
      "lambda=0.01000,degree=2, Training Accuracy=0.6499879100507778, Testing Accuracy=0.6469146946934038\n",
      "lambda=0.01000,degree=3, Training Accuracy=0.6453131296848553, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.01000,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.01000,degree=5, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01000,degree=6, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01000,degree=7, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01000,degree=8, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.01000,degree=9, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01000,degree=10, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01000,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01000,degree=12, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6427880585466503\n",
      "lambda=0.01050,degree=1, Training Accuracy=0.6934311275892642, Testing Accuracy=0.6888258430588691\n",
      "lambda=0.01050,degree=2, Training Accuracy=0.650004029983074, Testing Accuracy=0.6469146946934038\n",
      "lambda=0.01050,degree=3, Training Accuracy=0.6453292496171517, Testing Accuracy=0.6441421110323038\n",
      "lambda=0.01050,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.01050,degree=5, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01050,degree=6, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01050,degree=7, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01050,degree=8, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.01050,degree=9, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01050,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01050,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01050,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.01100,degree=1, Training Accuracy=0.6933182880631902, Testing Accuracy=0.688761364369076\n",
      "lambda=0.01100,degree=2, Training Accuracy=0.6500523897799629, Testing Accuracy=0.6470436520729899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01100,degree=3, Training Accuracy=0.6453614894817442, Testing Accuracy=0.6441421110323038\n",
      "lambda=0.01100,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.01100,degree=5, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01100,degree=6, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01100,degree=7, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01100,degree=8, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.01100,degree=9, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01100,degree=10, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01100,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01100,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.01150,degree=1, Training Accuracy=0.6930764890787459, Testing Accuracy=0.688761364369076\n",
      "lambda=0.01150,degree=2, Training Accuracy=0.6498750705247038, Testing Accuracy=0.6467857373138178\n",
      "lambda=0.01150,degree=3, Training Accuracy=0.645409849278633, Testing Accuracy=0.6442065897220969\n",
      "lambda=0.01150,degree=4, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01150,degree=5, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01150,degree=6, Training Accuracy=0.6434915773353752, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01150,degree=7, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01150,degree=8, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01150,degree=9, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01150,degree=10, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01150,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01150,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01200,degree=1, Training Accuracy=0.6928991698234868, Testing Accuracy=0.6881165774711457\n",
      "lambda=0.01200,degree=2, Training Accuracy=0.6497299911340373, Testing Accuracy=0.6467857373138178\n",
      "lambda=0.01200,degree=3, Training Accuracy=0.6453614894817442, Testing Accuracy=0.6442065897220969\n",
      "lambda=0.01200,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6433683667547876\n",
      "lambda=0.01200,degree=5, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01200,degree=6, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01200,degree=7, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01200,degree=8, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01200,degree=9, Training Accuracy=0.6433787378093012, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01200,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01200,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01200,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.01250,degree=1, Training Accuracy=0.6925606512452648, Testing Accuracy=0.6879231414017667\n",
      "lambda=0.01250,degree=2, Training Accuracy=0.649601031675667, Testing Accuracy=0.6467212586240247\n",
      "lambda=0.01250,degree=3, Training Accuracy=0.6453292496171517, Testing Accuracy=0.6442710684118899\n",
      "lambda=0.01250,degree=4, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01250,degree=5, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01250,degree=6, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01250,degree=7, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01250,degree=8, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01250,degree=9, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01250,degree=10, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01250,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01250,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.01300,degree=1, Training Accuracy=0.6922382525993391, Testing Accuracy=0.6876007479528016\n",
      "lambda=0.01300,degree=2, Training Accuracy=0.6496171516079633, Testing Accuracy=0.6467212586240247\n",
      "lambda=0.01300,degree=3, Training Accuracy=0.6453292496171517, Testing Accuracy=0.6442065897220969\n",
      "lambda=0.01300,degree=4, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01300,degree=5, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01300,degree=6, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01300,degree=7, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01300,degree=8, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01300,degree=9, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01300,degree=10, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01300,degree=11, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01300,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6428525372364433\n",
      "lambda=0.01350,degree=1, Training Accuracy=0.6920770532763763, Testing Accuracy=0.6869559610548713\n",
      "lambda=0.01350,degree=2, Training Accuracy=0.6494237124204079, Testing Accuracy=0.6465278225546457\n",
      "lambda=0.01350,degree=3, Training Accuracy=0.6453131296848553, Testing Accuracy=0.6442710684118899\n",
      "lambda=0.01350,degree=4, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01350,degree=5, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01350,degree=6, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01350,degree=7, Training Accuracy=0.6436205367937454, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01350,degree=8, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01350,degree=9, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01350,degree=10, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01350,degree=11, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01350,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01400,degree=1, Training Accuracy=0.6920448134117837, Testing Accuracy=0.6862466954671481\n",
      "lambda=0.01400,degree=2, Training Accuracy=0.6494398323527041, Testing Accuracy=0.6465923012444387\n",
      "lambda=0.01400,degree=3, Training Accuracy=0.645297009752559, Testing Accuracy=0.644335547101683\n",
      "lambda=0.01400,degree=4, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.01400,degree=5, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01400,degree=6, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01400,degree=7, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01400,degree=8, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.01400,degree=9, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01400,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01400,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01400,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01450,degree=1, Training Accuracy=0.6917707745627468, Testing Accuracy=0.6862466954671481\n",
      "lambda=0.01450,degree=2, Training Accuracy=0.6493108728943339, Testing Accuracy=0.6466567799342318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01450,degree=3, Training Accuracy=0.6452647698879664, Testing Accuracy=0.644335547101683\n",
      "lambda=0.01450,degree=4, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.01450,degree=5, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01450,degree=6, Training Accuracy=0.6436205367937454, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01450,degree=7, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01450,degree=8, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01450,degree=9, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01450,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01450,degree=11, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01450,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01500,degree=1, Training Accuracy=0.6916418151043766, Testing Accuracy=0.68585982332839\n",
      "lambda=0.01500,degree=2, Training Accuracy=0.6492786330297413, Testing Accuracy=0.6466567799342318\n",
      "lambda=0.01500,degree=3, Training Accuracy=0.6453131296848553, Testing Accuracy=0.644528983171062\n",
      "lambda=0.01500,degree=4, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01500,degree=5, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01500,degree=6, Training Accuracy=0.6436205367937454, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01500,degree=7, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01500,degree=8, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01500,degree=9, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01500,degree=10, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01500,degree=11, Training Accuracy=0.6432820182155234, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01500,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01550,degree=1, Training Accuracy=0.69149673571371, Testing Accuracy=0.6856663872590109\n",
      "lambda=0.01550,degree=2, Training Accuracy=0.6492302732328524, Testing Accuracy=0.6464633438648527\n",
      "lambda=0.01550,degree=3, Training Accuracy=0.6452808898202628, Testing Accuracy=0.644593461860855\n",
      "lambda=0.01550,degree=4, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01550,degree=5, Training Accuracy=0.6436205367937454, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01550,degree=6, Training Accuracy=0.6436527766583381, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01550,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01550,degree=8, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.01550,degree=9, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01550,degree=10, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01550,degree=11, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01550,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01600,degree=1, Training Accuracy=0.6911098573385992, Testing Accuracy=0.6855374298794249\n",
      "lambda=0.01600,degree=2, Training Accuracy=0.6491819134359635, Testing Accuracy=0.6465923012444387\n",
      "lambda=0.01600,degree=3, Training Accuracy=0.6452808898202628, Testing Accuracy=0.644593461860855\n",
      "lambda=0.01600,degree=4, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01600,degree=5, Training Accuracy=0.6436527766583381, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01600,degree=6, Training Accuracy=0.6436527766583381, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01600,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01600,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.01600,degree=9, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01600,degree=10, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01600,degree=11, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01600,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01650,degree=1, Training Accuracy=0.6908358184895623, Testing Accuracy=0.6848926429814947\n",
      "lambda=0.01650,degree=2, Training Accuracy=0.6491013137744821, Testing Accuracy=0.6465278225546457\n",
      "lambda=0.01650,degree=3, Training Accuracy=0.6452808898202628, Testing Accuracy=0.644593461860855\n",
      "lambda=0.01650,degree=4, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01650,degree=5, Training Accuracy=0.6436366567260418, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01650,degree=6, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01650,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01650,degree=8, Training Accuracy=0.6435560570645603, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.01650,degree=9, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.01650,degree=10, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01650,degree=11, Training Accuracy=0.6432981381478198, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01650,degree=12, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01700,degree=1, Training Accuracy=0.6905778995728218, Testing Accuracy=0.6851505577406667\n",
      "lambda=0.01700,degree=2, Training Accuracy=0.649149673571371, Testing Accuracy=0.6463988651750596\n",
      "lambda=0.01700,degree=3, Training Accuracy=0.6452647698879664, Testing Accuracy=0.644593461860855\n",
      "lambda=0.01700,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01700,degree=5, Training Accuracy=0.6436205367937454, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01700,degree=6, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01700,degree=7, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01700,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.01700,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.01700,degree=10, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01700,degree=11, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01700,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429170159262364\n",
      "lambda=0.01750,degree=1, Training Accuracy=0.6905617796405256, Testing Accuracy=0.6846992069121155\n",
      "lambda=0.01750,degree=2, Training Accuracy=0.6491013137744821, Testing Accuracy=0.6463343864852666\n",
      "lambda=0.01750,degree=3, Training Accuracy=0.6452002901587813, Testing Accuracy=0.644657940550648\n",
      "lambda=0.01750,degree=4, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01750,degree=5, Training Accuracy=0.6436527766583381, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01750,degree=6, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01750,degree=7, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01750,degree=8, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.01750,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.01750,degree=10, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01750,degree=11, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01750,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01800,degree=1, Training Accuracy=0.6901910211977109, Testing Accuracy=0.6850860790508737\n",
      "lambda=0.01800,degree=2, Training Accuracy=0.6490690739098895, Testing Accuracy=0.6462054291056806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01800,degree=3, Training Accuracy=0.6452002901587813, Testing Accuracy=0.644657940550648\n",
      "lambda=0.01800,degree=4, Training Accuracy=0.643765616184412, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01800,degree=5, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.01800,degree=6, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01800,degree=7, Training Accuracy=0.643765616184412, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01800,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.01800,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.01800,degree=10, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01800,degree=11, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01800,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01850,degree=1, Training Accuracy=0.6898041428226002, Testing Accuracy=0.6849571216712876\n",
      "lambda=0.01850,degree=2, Training Accuracy=0.6490045941807044, Testing Accuracy=0.6462699077954736\n",
      "lambda=0.01850,degree=3, Training Accuracy=0.645184170226485, Testing Accuracy=0.644657940550648\n",
      "lambda=0.01850,degree=4, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01850,degree=5, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01850,degree=6, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.01850,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01850,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.01850,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.01850,degree=10, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01850,degree=11, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01850,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01900,degree=1, Training Accuracy=0.6896590634319336, Testing Accuracy=0.6846347282223225\n",
      "lambda=0.01900,degree=2, Training Accuracy=0.6490207141130008, Testing Accuracy=0.6461409504158876\n",
      "lambda=0.01900,degree=3, Training Accuracy=0.6452002901587813, Testing Accuracy=0.644657940550648\n",
      "lambda=0.01900,degree=4, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01900,degree=5, Training Accuracy=0.6436527766583381, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01900,degree=6, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.01900,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01900,degree=8, Training Accuracy=0.6435560570645603, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.01900,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.01900,degree=10, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01900,degree=11, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01900,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01950,degree=1, Training Accuracy=0.6893205448537116, Testing Accuracy=0.6839899413243923\n",
      "lambda=0.01950,degree=2, Training Accuracy=0.6489401144515193, Testing Accuracy=0.6459475143465084\n",
      "lambda=0.01950,degree=3, Training Accuracy=0.6452002901587813, Testing Accuracy=0.644657940550648\n",
      "lambda=0.01950,degree=4, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01950,degree=5, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.01950,degree=6, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.01950,degree=7, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.01950,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.01950,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.01950,degree=10, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.01950,degree=11, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.01950,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02000,degree=1, Training Accuracy=0.6891432255984525, Testing Accuracy=0.6839899413243923\n",
      "lambda=0.02000,degree=2, Training Accuracy=0.6489078745869268, Testing Accuracy=0.6460119930363015\n",
      "lambda=0.02000,degree=3, Training Accuracy=0.645184170226485, Testing Accuracy=0.644593461860855\n",
      "lambda=0.02000,degree=4, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02000,degree=5, Training Accuracy=0.643765616184412, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02000,degree=6, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02000,degree=7, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.02000,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.02000,degree=9, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02000,degree=10, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02000,degree=11, Training Accuracy=0.6433464979447087, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02000,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02050,degree=1, Training Accuracy=0.6889497864108971, Testing Accuracy=0.6837965052550132\n",
      "lambda=0.02050,degree=2, Training Accuracy=0.6490529539775933, Testing Accuracy=0.6460764717260945\n",
      "lambda=0.02050,degree=3, Training Accuracy=0.6452325300233739, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02050,degree=4, Training Accuracy=0.6438623357781897, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02050,degree=5, Training Accuracy=0.643765616184412, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02050,degree=6, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02050,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02050,degree=8, Training Accuracy=0.6435560570645603, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.02050,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02050,degree=10, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02050,degree=11, Training Accuracy=0.6433142580801161, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02050,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02100,degree=1, Training Accuracy=0.6889014266140082, Testing Accuracy=0.6836030691856342\n",
      "lambda=0.02100,degree=2, Training Accuracy=0.6489884742484081, Testing Accuracy=0.6460119930363015\n",
      "lambda=0.02100,degree=3, Training Accuracy=0.6452647698879664, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02100,degree=4, Training Accuracy=0.6438945756427823, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02100,degree=5, Training Accuracy=0.6438139759813009, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02100,degree=6, Training Accuracy=0.6438300959135972, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02100,degree=7, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02100,degree=8, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02100,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02100,degree=10, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02100,degree=11, Training Accuracy=0.6433303780124123, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02100,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02150,degree=1, Training Accuracy=0.6886435076972677, Testing Accuracy=0.6837965052550132\n",
      "lambda=0.02150,degree=2, Training Accuracy=0.649036834045297, Testing Accuracy=0.6460119930363015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02150,degree=3, Training Accuracy=0.6452486499556702, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02150,degree=4, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02150,degree=5, Training Accuracy=0.6438300959135972, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02150,degree=6, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02150,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02150,degree=8, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02150,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02150,degree=10, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02150,degree=11, Training Accuracy=0.6433626178770049, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02150,degree=12, Training Accuracy=0.6432497783509309, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02200,degree=1, Training Accuracy=0.6883855887805271, Testing Accuracy=0.6836675478754272\n",
      "lambda=0.02200,degree=2, Training Accuracy=0.6489723543161119, Testing Accuracy=0.6460764717260945\n",
      "lambda=0.02200,degree=3, Training Accuracy=0.6452002901587813, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02200,degree=4, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02200,degree=5, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.02200,degree=6, Training Accuracy=0.643878455710486, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02200,degree=7, Training Accuracy=0.643765616184412, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.02200,degree=8, Training Accuracy=0.6436205367937454, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02200,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02200,degree=10, Training Accuracy=0.6434593374707827, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02200,degree=11, Training Accuracy=0.6433787378093012, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02200,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02250,degree=1, Training Accuracy=0.6882566293221568, Testing Accuracy=0.683345154426462\n",
      "lambda=0.02250,degree=2, Training Accuracy=0.6489562343838156, Testing Accuracy=0.6460764717260945\n",
      "lambda=0.02250,degree=3, Training Accuracy=0.645184170226485, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02250,degree=4, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02250,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02250,degree=6, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02250,degree=7, Training Accuracy=0.6437494962521157, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02250,degree=8, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02250,degree=9, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02250,degree=10, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02250,degree=11, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02250,degree=12, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02300,degree=1, Training Accuracy=0.6880793100668977, Testing Accuracy=0.683345154426462\n",
      "lambda=0.02300,degree=2, Training Accuracy=0.6489884742484081, Testing Accuracy=0.6460119930363015\n",
      "lambda=0.02300,degree=3, Training Accuracy=0.6452002901587813, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02300,degree=4, Training Accuracy=0.6438300959135972, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02300,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02300,degree=6, Training Accuracy=0.643878455710486, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02300,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02300,degree=8, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02300,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02300,degree=10, Training Accuracy=0.6434754574030789, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02300,degree=11, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02300,degree=12, Training Accuracy=0.6432175384863383, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02350,degree=1, Training Accuracy=0.6879019908116386, Testing Accuracy=0.68308723966729\n",
      "lambda=0.02350,degree=2, Training Accuracy=0.649036834045297, Testing Accuracy=0.6461409504158876\n",
      "lambda=0.02350,degree=3, Training Accuracy=0.6452164100910777, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02350,degree=4, Training Accuracy=0.643878455710486, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02350,degree=5, Training Accuracy=0.6438945756427823, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02350,degree=6, Training Accuracy=0.643878455710486, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02350,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.02350,degree=8, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02350,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02350,degree=10, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02350,degree=11, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02350,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02400,degree=1, Training Accuracy=0.6878536310147497, Testing Accuracy=0.6827648462183249\n",
      "lambda=0.02400,degree=2, Training Accuracy=0.6490529539775933, Testing Accuracy=0.6461409504158876\n",
      "lambda=0.02400,degree=3, Training Accuracy=0.6451680502941888, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02400,degree=4, Training Accuracy=0.643878455710486, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02400,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02400,degree=6, Training Accuracy=0.643878455710486, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02400,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.02400,degree=8, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02400,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02400,degree=10, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02400,degree=11, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02400,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02450,degree=1, Training Accuracy=0.6874345127750463, Testing Accuracy=0.6824424527693598\n",
      "lambda=0.02450,degree=2, Training Accuracy=0.6490529539775933, Testing Accuracy=0.6460764717260945\n",
      "lambda=0.02450,degree=3, Training Accuracy=0.6450874506327073, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02450,degree=4, Training Accuracy=0.643878455710486, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02450,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02450,degree=6, Training Accuracy=0.643878455710486, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02450,degree=7, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6436907602037527\n",
      "lambda=0.02450,degree=8, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02450,degree=9, Training Accuracy=0.6435076972676714, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02450,degree=10, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431104519956155\n",
      "lambda=0.02450,degree=11, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02450,degree=12, Training Accuracy=0.6432336584186347, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02500,degree=1, Training Accuracy=0.6872894333843798, Testing Accuracy=0.6824424527693598\n",
      "lambda=0.02500,degree=2, Training Accuracy=0.6490690739098895, Testing Accuracy=0.6461409504158876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02500,degree=3, Training Accuracy=0.6450874506327073, Testing Accuracy=0.6444000257914759\n",
      "lambda=0.02500,degree=4, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02500,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02500,degree=6, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02500,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02500,degree=8, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02500,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02500,degree=10, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02500,degree=11, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02500,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02550,degree=1, Training Accuracy=0.6871443539937132, Testing Accuracy=0.6823134953897737\n",
      "lambda=0.02550,degree=2, Training Accuracy=0.6490529539775933, Testing Accuracy=0.6463343864852666\n",
      "lambda=0.02550,degree=3, Training Accuracy=0.6451196904972999, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02550,degree=4, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02550,degree=5, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02550,degree=6, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02550,degree=7, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.02550,degree=8, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02550,degree=9, Training Accuracy=0.6435238171999678, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.02550,degree=10, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02550,degree=11, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02550,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6429814946160294\n",
      "lambda=0.02600,degree=1, Training Accuracy=0.6869831546707503, Testing Accuracy=0.6821845380101876\n",
      "lambda=0.02600,degree=2, Training Accuracy=0.6490851938421859, Testing Accuracy=0.6463988651750596\n",
      "lambda=0.02600,degree=3, Training Accuracy=0.6451196904972999, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02600,degree=4, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02600,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02600,degree=6, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02600,degree=7, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.02600,degree=8, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02600,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.02600,degree=10, Training Accuracy=0.6435560570645603, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02600,degree=11, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02600,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02650,degree=1, Training Accuracy=0.6868058354154912, Testing Accuracy=0.6818621445612225\n",
      "lambda=0.02650,degree=2, Training Accuracy=0.6490690739098895, Testing Accuracy=0.6464633438648527\n",
      "lambda=0.02650,degree=3, Training Accuracy=0.6450874506327073, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02650,degree=4, Training Accuracy=0.6439590553719674, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02650,degree=5, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02650,degree=6, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02650,degree=7, Training Accuracy=0.6437333763198194, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.02650,degree=8, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02650,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.02650,degree=10, Training Accuracy=0.6435560570645603, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02650,degree=11, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02650,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02700,degree=1, Training Accuracy=0.6864995567018618, Testing Accuracy=0.6814752724224644\n",
      "lambda=0.02700,degree=2, Training Accuracy=0.6490207141130008, Testing Accuracy=0.6464633438648527\n",
      "lambda=0.02700,degree=3, Training Accuracy=0.645071330700411, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02700,degree=4, Training Accuracy=0.6439590553719674, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02700,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02700,degree=6, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6441421110323038\n",
      "lambda=0.02700,degree=7, Training Accuracy=0.6437172563875232, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02700,degree=8, Training Accuracy=0.6436688965906343, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.02700,degree=9, Training Accuracy=0.6435399371322641, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.02700,degree=10, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02700,degree=11, Training Accuracy=0.6434109776738938, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02700,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02750,degree=1, Training Accuracy=0.6864189570403805, Testing Accuracy=0.6815397511122574\n",
      "lambda=0.02750,degree=2, Training Accuracy=0.6489723543161119, Testing Accuracy=0.6465278225546457\n",
      "lambda=0.02750,degree=3, Training Accuracy=0.6450552107681148, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02750,degree=4, Training Accuracy=0.6439590553719674, Testing Accuracy=0.6438841962731318\n",
      "lambda=0.02750,degree=5, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02750,degree=6, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6440776323425108\n",
      "lambda=0.02750,degree=7, Training Accuracy=0.643765616184412, Testing Accuracy=0.6435618028241666\n",
      "lambda=0.02750,degree=8, Training Accuracy=0.6436850165229306, Testing Accuracy=0.6434973241343735\n",
      "lambda=0.02750,degree=9, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.02750,degree=10, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02750,degree=11, Training Accuracy=0.6433948577415974, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02750,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02800,degree=1, Training Accuracy=0.686225517852825, Testing Accuracy=0.6810884002837062\n",
      "lambda=0.02800,degree=2, Training Accuracy=0.6489562343838156, Testing Accuracy=0.6464633438648527\n",
      "lambda=0.02800,degree=3, Training Accuracy=0.6450874506327073, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02800,degree=4, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02800,degree=5, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02800,degree=6, Training Accuracy=0.6438945756427823, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02800,degree=7, Training Accuracy=0.6437817361167083, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02800,degree=8, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.02800,degree=9, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.02800,degree=10, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02800,degree=11, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02800,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02850,degree=1, Training Accuracy=0.686112678326751, Testing Accuracy=0.6810884002837062\n",
      "lambda=0.02850,degree=2, Training Accuracy=0.6489401144515193, Testing Accuracy=0.6465923012444387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02850,degree=3, Training Accuracy=0.6450874506327073, Testing Accuracy=0.6444000257914759\n",
      "lambda=0.02850,degree=4, Training Accuracy=0.6439590553719674, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02850,degree=5, Training Accuracy=0.6439268155073749, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02850,degree=6, Training Accuracy=0.6438945756427823, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02850,degree=7, Training Accuracy=0.6437978560490046, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02850,degree=8, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.02850,degree=9, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.02850,degree=10, Training Accuracy=0.6435721769968566, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02850,degree=11, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02850,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02900,degree=1, Training Accuracy=0.6858708793423067, Testing Accuracy=0.680443613385776\n",
      "lambda=0.02900,degree=2, Training Accuracy=0.6489078745869268, Testing Accuracy=0.6466567799342318\n",
      "lambda=0.02900,degree=3, Training Accuracy=0.645071330700411, Testing Accuracy=0.6444645044812689\n",
      "lambda=0.02900,degree=4, Training Accuracy=0.6439429354396712, Testing Accuracy=0.6438197175833387\n",
      "lambda=0.02900,degree=5, Training Accuracy=0.6439590553719674, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02900,degree=6, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02900,degree=7, Training Accuracy=0.6438139759813009, Testing Accuracy=0.6436262815139596\n",
      "lambda=0.02900,degree=8, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.02900,degree=9, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6433038880649945\n",
      "lambda=0.02900,degree=10, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02900,degree=11, Training Accuracy=0.6434270976061901, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02900,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02950,degree=1, Training Accuracy=0.6855162408317885, Testing Accuracy=0.6801212199368109\n",
      "lambda=0.02950,degree=2, Training Accuracy=0.6488917546546304, Testing Accuracy=0.6466567799342318\n",
      "lambda=0.02950,degree=3, Training Accuracy=0.645071330700411, Testing Accuracy=0.644528983171062\n",
      "lambda=0.02950,degree=4, Training Accuracy=0.6439106955750786, Testing Accuracy=0.6439486749629247\n",
      "lambda=0.02950,degree=5, Training Accuracy=0.6439590553719674, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02950,degree=6, Training Accuracy=0.6438945756427823, Testing Accuracy=0.6440131536527178\n",
      "lambda=0.02950,degree=7, Training Accuracy=0.6438462158458934, Testing Accuracy=0.6437552388935457\n",
      "lambda=0.02950,degree=8, Training Accuracy=0.6437011364552269, Testing Accuracy=0.6434328454445806\n",
      "lambda=0.02950,degree=9, Training Accuracy=0.6436044168614492, Testing Accuracy=0.6432394093752015\n",
      "lambda=0.02950,degree=10, Training Accuracy=0.6435882969291529, Testing Accuracy=0.6431749306854084\n",
      "lambda=0.02950,degree=11, Training Accuracy=0.6434432175384863, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.02950,degree=12, Training Accuracy=0.6432658982832272, Testing Accuracy=0.6430459733058225\n",
      "lambda=0.00000,degree=1, Training Accuracy=0.7363719822345731, Testing Accuracy=0.732135768161969\n",
      "lambda=0.00000,degree=2, Training Accuracy=0.7593975634568146, Testing Accuracy=0.7531758634378721\n",
      "lambda=0.00000,degree=3, Training Accuracy=0.6791802099099322, Testing Accuracy=0.6719928543072647\n",
      "lambda=0.00000,degree=4, Training Accuracy=0.6540207924968364, Testing Accuracy=0.6498610559745931\n",
      "lambda=0.00000,degree=5, Training Accuracy=0.6230801677294494, Testing Accuracy=0.6184994045256054\n",
      "lambda=0.00000,degree=6, Training Accuracy=0.531399647668908, Testing Accuracy=0.5245136959110758\n",
      "lambda=0.00000,degree=7, Training Accuracy=0.5163883581867355, Testing Accuracy=0.5127034537514887\n",
      "lambda=0.00000,degree=8, Training Accuracy=0.5136342207776096, Testing Accuracy=0.5108177848352521\n",
      "lambda=0.00000,degree=9, Training Accuracy=0.5129394834131454, Testing Accuracy=0.5104208019055181\n",
      "lambda=0.00000,degree=10, Training Accuracy=0.511376324343101, Testing Accuracy=0.509229853116316\n",
      "lambda=0.00000,degree=11, Training Accuracy=0.5114011363918318, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00000,degree=12, Training Accuracy=0.5114259484405628, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00050,degree=1, Training Accuracy=0.7174900131503859, Testing Accuracy=0.7139737991266376\n",
      "lambda=0.00050,degree=2, Training Accuracy=0.6942659355382974, Testing Accuracy=0.6891623660182612\n",
      "lambda=0.00050,degree=3, Training Accuracy=0.657023050393271, Testing Accuracy=0.6497618102421596\n",
      "lambda=0.00050,degree=4, Training Accuracy=0.5358658164404635, Testing Accuracy=0.5279872965462485\n",
      "lambda=0.00050,degree=5, Training Accuracy=0.5123688062923356, Testing Accuracy=0.5095275903136165\n",
      "lambda=0.00050,degree=6, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00050,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00050,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00050,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00050,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00050,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00050,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=1, Training Accuracy=0.7160261022752649, Testing Accuracy=0.7118896387455339\n",
      "lambda=0.00100,degree=2, Training Accuracy=0.688162171550505, Testing Accuracy=0.6834061135371179\n",
      "lambda=0.00100,degree=3, Training Accuracy=0.6554102672257648, Testing Accuracy=0.6477768955934895\n",
      "lambda=0.00100,degree=4, Training Accuracy=0.5285462620648587, Testing Accuracy=0.5207423580786026\n",
      "lambda=0.00100,degree=5, Training Accuracy=0.5120710617075652, Testing Accuracy=0.509229853116316\n",
      "lambda=0.00100,degree=6, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00100,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=1, Training Accuracy=0.7155794853981093, Testing Accuracy=0.711294164350933\n",
      "lambda=0.00150,degree=2, Training Accuracy=0.6837456268764112, Testing Accuracy=0.677749106788408\n",
      "lambda=0.00150,degree=3, Training Accuracy=0.6552862069821105, Testing Accuracy=0.646685192536721\n",
      "lambda=0.00150,degree=4, Training Accuracy=0.5254199439247699, Testing Accuracy=0.5179634775704645\n",
      "lambda=0.00150,degree=5, Training Accuracy=0.5118973773664491, Testing Accuracy=0.509229853116316\n",
      "lambda=0.00150,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00150,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=1, Training Accuracy=0.715281740813339, Testing Accuracy=0.7100039698292974\n",
      "lambda=0.00200,degree=2, Training Accuracy=0.6813140461007865, Testing Accuracy=0.6737792774910679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00200,degree=3, Training Accuracy=0.6549636503486093, Testing Accuracy=0.6472806669313219\n",
      "lambda=0.00200,degree=4, Training Accuracy=0.523757536659802, Testing Accuracy=0.5169710202461294\n",
      "lambda=0.00200,degree=5, Training Accuracy=0.5118229412202565, Testing Accuracy=0.509229853116316\n",
      "lambda=0.00200,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00200,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=1, Training Accuracy=0.7151080564722229, Testing Accuracy=0.7094084954346963\n",
      "lambda=0.00250,degree=2, Training Accuracy=0.6797260749820113, Testing Accuracy=0.6720921000396983\n",
      "lambda=0.00250,degree=3, Training Accuracy=0.654095228643029, Testing Accuracy=0.6477768955934895\n",
      "lambda=0.00250,degree=4, Training Accuracy=0.5225417462719897, Testing Accuracy=0.5159785629217943\n",
      "lambda=0.00250,degree=5, Training Accuracy=0.511723693025333, Testing Accuracy=0.509229853116316\n",
      "lambda=0.00250,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00250,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=1, Training Accuracy=0.7154058010569933, Testing Accuracy=0.7091107582373958\n",
      "lambda=0.00300,degree=2, Training Accuracy=0.6784358484480063, Testing Accuracy=0.6707026597856293\n",
      "lambda=0.00300,degree=3, Training Accuracy=0.6535741756196809, Testing Accuracy=0.6483723699880906\n",
      "lambda=0.00300,degree=4, Training Accuracy=0.5214500161278317, Testing Accuracy=0.5152838427947598\n",
      "lambda=0.00300,degree=5, Training Accuracy=0.5116492568791405, Testing Accuracy=0.5091306073838825\n",
      "lambda=0.00300,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00300,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=1, Training Accuracy=0.7152073046671463, Testing Accuracy=0.7091107582373958\n",
      "lambda=0.00350,degree=2, Training Accuracy=0.6773937424013101, Testing Accuracy=0.6693132195315601\n",
      "lambda=0.00350,degree=3, Training Accuracy=0.6524824454755229, Testing Accuracy=0.6469829297340214\n",
      "lambda=0.00350,degree=4, Training Accuracy=0.5209041510557527, Testing Accuracy=0.5141921397379913\n",
      "lambda=0.00350,degree=5, Training Accuracy=0.5115996327816787, Testing Accuracy=0.5091306073838825\n",
      "lambda=0.00350,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00350,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=1, Training Accuracy=0.7151080564722229, Testing Accuracy=0.7093092497022628\n",
      "lambda=0.00400,degree=2, Training Accuracy=0.6759794556236508, Testing Accuracy=0.667129813418023\n",
      "lambda=0.00400,degree=3, Training Accuracy=0.6520854526958291, Testing Accuracy=0.6473799126637555\n",
      "lambda=0.00400,degree=4, Training Accuracy=0.5202590377887503, Testing Accuracy=0.5139936482731242\n",
      "lambda=0.00400,degree=5, Training Accuracy=0.5115748207329479, Testing Accuracy=0.5091306073838825\n",
      "lambda=0.00400,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00400,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=1, Training Accuracy=0.71473587574126, Testing Accuracy=0.7093092497022628\n",
      "lambda=0.00450,degree=2, Training Accuracy=0.6747884772845694, Testing Accuracy=0.665740373163954\n",
      "lambda=0.00450,degree=3, Training Accuracy=0.6519365804034439, Testing Accuracy=0.6465859468042874\n",
      "lambda=0.00450,degree=4, Training Accuracy=0.5198124209115946, Testing Accuracy=0.5138944025406907\n",
      "lambda=0.00450,degree=5, Training Accuracy=0.5115748207329479, Testing Accuracy=0.5091306073838825\n",
      "lambda=0.00450,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00450,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=1, Training Accuracy=0.714537379351413, Testing Accuracy=0.7097062326319968\n",
      "lambda=0.00500,degree=2, Training Accuracy=0.6738704314815275, Testing Accuracy=0.6660381103612545\n",
      "lambda=0.00500,degree=3, Training Accuracy=0.6521847008907525, Testing Accuracy=0.6469829297340214\n",
      "lambda=0.00500,degree=4, Training Accuracy=0.5192913678882465, Testing Accuracy=0.5134974196109567\n",
      "lambda=0.00500,degree=5, Training Accuracy=0.5115500086842171, Testing Accuracy=0.5091306073838825\n",
      "lambda=0.00500,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00500,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=1, Training Accuracy=0.714363695010297, Testing Accuracy=0.7099047240968638\n",
      "lambda=0.00550,degree=2, Training Accuracy=0.6734734387018336, Testing Accuracy=0.666732830488289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00550,degree=3, Training Accuracy=0.6523831972805995, Testing Accuracy=0.646685192536721\n",
      "lambda=0.00550,degree=4, Training Accuracy=0.5190432474009379, Testing Accuracy=0.5131996824136562\n",
      "lambda=0.00550,degree=5, Training Accuracy=0.5115500086842171, Testing Accuracy=0.5091306073838825\n",
      "lambda=0.00550,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00550,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=1, Training Accuracy=0.7141651986204501, Testing Accuracy=0.7097062326319968\n",
      "lambda=0.00600,degree=2, Training Accuracy=0.6724313326551373, Testing Accuracy=0.665938864628821\n",
      "lambda=0.00600,degree=3, Training Accuracy=0.6520606406470982, Testing Accuracy=0.647479158396189\n",
      "lambda=0.00600,degree=4, Training Accuracy=0.5188943751085527, Testing Accuracy=0.5131996824136562\n",
      "lambda=0.00600,degree=5, Training Accuracy=0.5115500086842171, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00600,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00600,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=1, Training Accuracy=0.7135448974021785, Testing Accuracy=0.7099047240968638\n",
      "lambda=0.00650,degree=2, Training Accuracy=0.6716621591444806, Testing Accuracy=0.6644501786423184\n",
      "lambda=0.00650,degree=3, Training Accuracy=0.6525816936704464, Testing Accuracy=0.647082175466455\n",
      "lambda=0.00650,degree=4, Training Accuracy=0.518646254621244, Testing Accuracy=0.5131004366812227\n",
      "lambda=0.00650,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00650,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00650,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=1, Training Accuracy=0.7133712130610624, Testing Accuracy=0.7104009527590314\n",
      "lambda=0.00700,degree=2, Training Accuracy=0.6714884748033645, Testing Accuracy=0.6631599841206828\n",
      "lambda=0.00700,degree=3, Training Accuracy=0.6524824454755229, Testing Accuracy=0.6473799126637555\n",
      "lambda=0.00700,degree=4, Training Accuracy=0.5183236979877428, Testing Accuracy=0.5130011909487892\n",
      "lambda=0.00700,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00700,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00700,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=1, Training Accuracy=0.7130486564275612, Testing Accuracy=0.7092100039698293\n",
      "lambda=0.00750,degree=2, Training Accuracy=0.6708681735850929, Testing Accuracy=0.6628622469233822\n",
      "lambda=0.00750,degree=3, Training Accuracy=0.6530034984988711, Testing Accuracy=0.6465859468042874\n",
      "lambda=0.00750,degree=4, Training Accuracy=0.518125201597896, Testing Accuracy=0.5129019452163557\n",
      "lambda=0.00750,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00750,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00750,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=1, Training Accuracy=0.7129245961839069, Testing Accuracy=0.7091107582373958\n",
      "lambda=0.00800,degree=2, Training Accuracy=0.6704711808053991, Testing Accuracy=0.6629614926558158\n",
      "lambda=0.00800,degree=3, Training Accuracy=0.6530531225963327, Testing Accuracy=0.6462882096069869\n",
      "lambda=0.00800,degree=4, Training Accuracy=0.5179018931593181, Testing Accuracy=0.5129019452163557\n",
      "lambda=0.00800,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00800,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00800,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=1, Training Accuracy=0.7127012877453291, Testing Accuracy=0.7090115125049623\n",
      "lambda=0.00850,degree=2, Training Accuracy=0.6698756916358584, Testing Accuracy=0.6628622469233822\n",
      "lambda=0.00850,degree=3, Training Accuracy=0.6529786864501402, Testing Accuracy=0.6468836840015879\n",
      "lambda=0.00850,degree=4, Training Accuracy=0.5178274570131256, Testing Accuracy=0.5129019452163557\n",
      "lambda=0.00850,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00850,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00850,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=1, Training Accuracy=0.7122050467707118, Testing Accuracy=0.7094084954346963\n",
      "lambda=0.00900,degree=2, Training Accuracy=0.6693298265637794, Testing Accuracy=0.6623660182612148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00900,degree=3, Training Accuracy=0.6530283105476019, Testing Accuracy=0.647082175466455\n",
      "lambda=0.00900,degree=4, Training Accuracy=0.5177033967694713, Testing Accuracy=0.5128026994839222\n",
      "lambda=0.00900,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00900,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00900,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=1, Training Accuracy=0.7120065503808649, Testing Accuracy=0.7092100039698293\n",
      "lambda=0.00950,degree=2, Training Accuracy=0.6694786988561645, Testing Accuracy=0.6623660182612148\n",
      "lambda=0.00950,degree=3, Training Accuracy=0.6529538744014093, Testing Accuracy=0.6471814211988884\n",
      "lambda=0.00950,degree=4, Training Accuracy=0.5176289606232787, Testing Accuracy=0.5128026994839222\n",
      "lambda=0.00950,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.00950,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00950,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=1, Training Accuracy=0.711634369649902, Testing Accuracy=0.7095077411671298\n",
      "lambda=0.01000,degree=2, Training Accuracy=0.6690817060764708, Testing Accuracy=0.6626637554585153\n",
      "lambda=0.01000,degree=3, Training Accuracy=0.6529538744014093, Testing Accuracy=0.64807463279079\n",
      "lambda=0.01000,degree=4, Training Accuracy=0.5175297124283552, Testing Accuracy=0.5127034537514887\n",
      "lambda=0.01000,degree=5, Training Accuracy=0.5115251966354862, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01000,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01000,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=1, Training Accuracy=0.7114606853087859, Testing Accuracy=0.7090115125049623\n",
      "lambda=0.01050,degree=2, Training Accuracy=0.6685358410043918, Testing Accuracy=0.6626637554585153\n",
      "lambda=0.01050,degree=3, Training Accuracy=0.6535493635709501, Testing Accuracy=0.6477768955934895\n",
      "lambda=0.01050,degree=4, Training Accuracy=0.5174304642334318, Testing Accuracy=0.5127034537514887\n",
      "lambda=0.01050,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01050,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01050,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=1, Training Accuracy=0.7113118130164008, Testing Accuracy=0.7086145295752283\n",
      "lambda=0.01100,degree=2, Training Accuracy=0.6684614048581992, Testing Accuracy=0.6629614926558158\n",
      "lambda=0.01100,degree=3, Training Accuracy=0.6537974840582587, Testing Accuracy=0.6483723699880906\n",
      "lambda=0.01100,degree=4, Training Accuracy=0.5173064039897775, Testing Accuracy=0.5127034537514887\n",
      "lambda=0.01100,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01100,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01100,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=1, Training Accuracy=0.7111877527727465, Testing Accuracy=0.7083167923779278\n",
      "lambda=0.01150,degree=2, Training Accuracy=0.6680644120785053, Testing Accuracy=0.6628622469233822\n",
      "lambda=0.01150,degree=3, Training Accuracy=0.6538967322531821, Testing Accuracy=0.648471615720524\n",
      "lambda=0.01150,degree=4, Training Accuracy=0.5171575316973922, Testing Accuracy=0.5127034537514887\n",
      "lambda=0.01150,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01150,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01150,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=1, Training Accuracy=0.7109396322854378, Testing Accuracy=0.7081183009130607\n",
      "lambda=0.01200,degree=2, Training Accuracy=0.6679651638835818, Testing Accuracy=0.6626637554585153\n",
      "lambda=0.01200,degree=3, Training Accuracy=0.6544177852765303, Testing Accuracy=0.648868598650258\n",
      "lambda=0.01200,degree=4, Training Accuracy=0.5171079075999305, Testing Accuracy=0.5127034537514887\n",
      "lambda=0.01200,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01200,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01200,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=1, Training Accuracy=0.7106666997493983, Testing Accuracy=0.7071258435887257\n",
      "lambda=0.01250,degree=2, Training Accuracy=0.6679651638835818, Testing Accuracy=0.6629614926558158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01250,degree=3, Training Accuracy=0.6547899660074933, Testing Accuracy=0.6490670901151251\n",
      "lambda=0.01250,degree=4, Training Accuracy=0.5170334714537379, Testing Accuracy=0.5125049622866217\n",
      "lambda=0.01250,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01250,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01250,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=1, Training Accuracy=0.7103441431158971, Testing Accuracy=0.7065303691941247\n",
      "lambda=0.01300,degree=2, Training Accuracy=0.6677666674937349, Testing Accuracy=0.6628622469233822\n",
      "lambda=0.01300,degree=3, Training Accuracy=0.6549388382998784, Testing Accuracy=0.6497618102421596\n",
      "lambda=0.01300,degree=4, Training Accuracy=0.5169342232588144, Testing Accuracy=0.5124057165541882\n",
      "lambda=0.01300,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01300,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01300,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=1, Training Accuracy=0.7102448949209736, Testing Accuracy=0.7059348947995236\n",
      "lambda=0.01350,degree=2, Training Accuracy=0.6676922313475424, Testing Accuracy=0.6629614926558158\n",
      "lambda=0.01350,degree=3, Training Accuracy=0.6550628985435327, Testing Accuracy=0.6498610559745931\n",
      "lambda=0.01350,degree=4, Training Accuracy=0.5167853509664293, Testing Accuracy=0.5123064708217546\n",
      "lambda=0.01350,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01350,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01350,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=1, Training Accuracy=0.7100960226285884, Testing Accuracy=0.7051409289400555\n",
      "lambda=0.01400,degree=2, Training Accuracy=0.6678411036399275, Testing Accuracy=0.6624652639936482\n",
      "lambda=0.01400,degree=3, Training Accuracy=0.6551125226409945, Testing Accuracy=0.6504565303691942\n",
      "lambda=0.01400,degree=4, Training Accuracy=0.5166364786740442, Testing Accuracy=0.5123064708217546\n",
      "lambda=0.01400,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01400,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01400,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=1, Training Accuracy=0.7097734659950872, Testing Accuracy=0.7049424374751886\n",
      "lambda=0.01450,degree=2, Training Accuracy=0.6677418554450041, Testing Accuracy=0.6632592298531164\n",
      "lambda=0.01450,degree=3, Training Accuracy=0.6554598913232266, Testing Accuracy=0.6506550218340611\n",
      "lambda=0.01450,degree=4, Training Accuracy=0.5165868545765824, Testing Accuracy=0.5122072250893211\n",
      "lambda=0.01450,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01450,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01450,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=1, Training Accuracy=0.709823090092549, Testing Accuracy=0.7046447002778881\n",
      "lambda=0.01500,degree=2, Training Accuracy=0.667568171103888, Testing Accuracy=0.6637554585152838\n",
      "lambda=0.01500,degree=3, Training Accuracy=0.655757635907997, Testing Accuracy=0.6504565303691942\n",
      "lambda=0.01500,degree=4, Training Accuracy=0.5165124184303898, Testing Accuracy=0.5121079793568877\n",
      "lambda=0.01500,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01500,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01500,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=1, Training Accuracy=0.7097238418976255, Testing Accuracy=0.7041484716157205\n",
      "lambda=0.01550,degree=2, Training Accuracy=0.667568171103888, Testing Accuracy=0.6640531957125844\n",
      "lambda=0.01550,degree=3, Training Accuracy=0.6562538768826142, Testing Accuracy=0.6503572846367606\n",
      "lambda=0.01550,degree=4, Training Accuracy=0.5164876063816589, Testing Accuracy=0.5120087336244541\n",
      "lambda=0.01550,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01550,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01550,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=1, Training Accuracy=0.7096494057514329, Testing Accuracy=0.703652242953553\n",
      "lambda=0.01600,degree=2, Training Accuracy=0.6674689229089646, Testing Accuracy=0.6630607383882493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01600,degree=3, Training Accuracy=0.6561298166389599, Testing Accuracy=0.6503572846367606\n",
      "lambda=0.01600,degree=4, Training Accuracy=0.5163883581867355, Testing Accuracy=0.5120087336244541\n",
      "lambda=0.01600,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01600,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01600,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=1, Training Accuracy=0.7094757214103169, Testing Accuracy=0.703255260023819\n",
      "lambda=0.01650,degree=2, Training Accuracy=0.6672208024216559, Testing Accuracy=0.6630607383882493\n",
      "lambda=0.01650,degree=3, Training Accuracy=0.6561794407364216, Testing Accuracy=0.6506550218340611\n",
      "lambda=0.01650,degree=4, Training Accuracy=0.5163139220405429, Testing Accuracy=0.5117109964271537\n",
      "lambda=0.01650,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01650,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01650,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=1, Training Accuracy=0.7092276009230082, Testing Accuracy=0.7030567685589519\n",
      "lambda=0.01700,degree=2, Training Accuracy=0.6669230578368855, Testing Accuracy=0.6628622469233822\n",
      "lambda=0.01700,degree=3, Training Accuracy=0.6562538768826142, Testing Accuracy=0.6509527590313616\n",
      "lambda=0.01700,degree=4, Training Accuracy=0.5163139220405429, Testing Accuracy=0.5117109964271537\n",
      "lambda=0.01700,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01700,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01700,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=1, Training Accuracy=0.7092027888742773, Testing Accuracy=0.7029575228265185\n",
      "lambda=0.01750,degree=2, Training Accuracy=0.6670967421780016, Testing Accuracy=0.6630607383882493\n",
      "lambda=0.01750,degree=3, Training Accuracy=0.6565516214673845, Testing Accuracy=0.6515482334259627\n",
      "lambda=0.01750,degree=4, Training Accuracy=0.5162642979430812, Testing Accuracy=0.5115125049622866\n",
      "lambda=0.01750,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01750,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01750,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=1, Training Accuracy=0.7088554201920453, Testing Accuracy=0.7027590313616514\n",
      "lambda=0.01800,degree=2, Training Accuracy=0.667022306031809, Testing Accuracy=0.6630607383882493\n",
      "lambda=0.01800,degree=3, Training Accuracy=0.6564523732724611, Testing Accuracy=0.6510520047637952\n",
      "lambda=0.01800,degree=4, Training Accuracy=0.5161898617968885, Testing Accuracy=0.5115125049622866\n",
      "lambda=0.01800,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01800,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01800,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=1, Training Accuracy=0.7084336153636206, Testing Accuracy=0.7031560142913855\n",
      "lambda=0.01850,degree=2, Training Accuracy=0.666674937349577, Testing Accuracy=0.6631599841206828\n",
      "lambda=0.01850,degree=3, Training Accuracy=0.6569238021983476, Testing Accuracy=0.6513497419610956\n",
      "lambda=0.01850,degree=4, Training Accuracy=0.516115425650696, Testing Accuracy=0.5115125049622866\n",
      "lambda=0.01850,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01850,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01850,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=1, Training Accuracy=0.7082103069250428, Testing Accuracy=0.7029575228265185\n",
      "lambda=0.01900,degree=2, Training Accuracy=0.6662283204724214, Testing Accuracy=0.6629614926558158\n",
      "lambda=0.01900,degree=3, Training Accuracy=0.6572463588318488, Testing Accuracy=0.6513497419610956\n",
      "lambda=0.01900,degree=4, Training Accuracy=0.5160658015532342, Testing Accuracy=0.5115125049622866\n",
      "lambda=0.01900,degree=5, Training Accuracy=0.5115003845867553, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01900,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01900,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=1, Training Accuracy=0.7082599310225045, Testing Accuracy=0.7029575228265185\n",
      "lambda=0.01950,degree=2, Training Accuracy=0.6660794481800362, Testing Accuracy=0.6620682810639142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01950,degree=3, Training Accuracy=0.6574944793191574, Testing Accuracy=0.6519452163556967\n",
      "lambda=0.01950,degree=4, Training Accuracy=0.5160161774557726, Testing Accuracy=0.5115125049622866\n",
      "lambda=0.01950,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.01950,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.01950,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=1, Training Accuracy=0.7080862466813885, Testing Accuracy=0.7025605398967845\n",
      "lambda=0.02000,degree=2, Training Accuracy=0.6660794481800362, Testing Accuracy=0.6623660182612148\n",
      "lambda=0.02000,degree=3, Training Accuracy=0.6576929757090043, Testing Accuracy=0.6518459706232632\n",
      "lambda=0.02000,degree=4, Training Accuracy=0.5159665533583108, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02000,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02000,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02000,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=1, Training Accuracy=0.7077140659504255, Testing Accuracy=0.7023620484319174\n",
      "lambda=0.02050,degree=2, Training Accuracy=0.6658313276927276, Testing Accuracy=0.6619690353314808\n",
      "lambda=0.02050,degree=3, Training Accuracy=0.6577922239039278, Testing Accuracy=0.6520444620881302\n",
      "lambda=0.02050,degree=4, Training Accuracy=0.5159169292608491, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02050,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02050,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02050,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=1, Training Accuracy=0.7074163213656551, Testing Accuracy=0.7017665740373163\n",
      "lambda=0.02100,degree=2, Training Accuracy=0.6657320794978041, Testing Accuracy=0.6618697895990472\n",
      "lambda=0.02100,degree=3, Training Accuracy=0.6577177877577352, Testing Accuracy=0.6524414450178643\n",
      "lambda=0.02100,degree=4, Training Accuracy=0.5158921172121183, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02100,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02100,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02100,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=1, Training Accuracy=0.7072922611220008, Testing Accuracy=0.7015680825724494\n",
      "lambda=0.02150,degree=2, Training Accuracy=0.6660794481800362, Testing Accuracy=0.6614728066693132\n",
      "lambda=0.02150,degree=3, Training Accuracy=0.6578170359526586, Testing Accuracy=0.6529376736800317\n",
      "lambda=0.02150,degree=4, Training Accuracy=0.5158424931146565, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02150,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02150,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02150,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=1, Training Accuracy=0.7071433888296157, Testing Accuracy=0.7013695911075823\n",
      "lambda=0.02200,degree=2, Training Accuracy=0.6661786963749596, Testing Accuracy=0.6608773322747122\n",
      "lambda=0.02200,degree=3, Training Accuracy=0.6582388407810833, Testing Accuracy=0.6528384279475983\n",
      "lambda=0.02200,degree=4, Training Accuracy=0.5157928690171948, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02200,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02200,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02200,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=1, Training Accuracy=0.7068704562935761, Testing Accuracy=0.7012703453751489\n",
      "lambda=0.02250,degree=2, Training Accuracy=0.666302756618614, Testing Accuracy=0.6606788408098452\n",
      "lambda=0.02250,degree=3, Training Accuracy=0.6586854576582388, Testing Accuracy=0.6531361651448988\n",
      "lambda=0.02250,degree=4, Training Accuracy=0.5157928690171948, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02250,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02250,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02250,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=1, Training Accuracy=0.7068456442448453, Testing Accuracy=0.7009726081778483\n",
      "lambda=0.02300,degree=2, Training Accuracy=0.6659801999851128, Testing Accuracy=0.6602818578801112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02300,degree=3, Training Accuracy=0.6588095179018931, Testing Accuracy=0.6524414450178643\n",
      "lambda=0.02300,degree=4, Training Accuracy=0.5156936208222713, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02300,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02300,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02300,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=1, Training Accuracy=0.706721584001191, Testing Accuracy=0.7008733624454149\n",
      "lambda=0.02350,degree=2, Training Accuracy=0.6660298240825745, Testing Accuracy=0.6600833664152441\n",
      "lambda=0.02350,degree=3, Training Accuracy=0.6589087660968166, Testing Accuracy=0.6521437078205637\n",
      "lambda=0.02350,degree=4, Training Accuracy=0.5156688087735404, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02350,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02350,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02350,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=1, Training Accuracy=0.7068704562935761, Testing Accuracy=0.7008733624454149\n",
      "lambda=0.02400,degree=2, Training Accuracy=0.6658065156439967, Testing Accuracy=0.6600833664152441\n",
      "lambda=0.02400,degree=3, Training Accuracy=0.6591320745353944, Testing Accuracy=0.6516474791583962\n",
      "lambda=0.02400,degree=4, Training Accuracy=0.5156439967248095, Testing Accuracy=0.5114132592298531\n",
      "lambda=0.02400,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02400,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02400,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=1, Training Accuracy=0.7067960201473835, Testing Accuracy=0.7007741167129813\n",
      "lambda=0.02450,degree=2, Training Accuracy=0.6654839590104955, Testing Accuracy=0.6597856292179436\n",
      "lambda=0.02450,degree=3, Training Accuracy=0.6597027516562043, Testing Accuracy=0.6524414450178643\n",
      "lambda=0.02450,degree=4, Training Accuracy=0.5156439967248095, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02450,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02450,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02450,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=1, Training Accuracy=0.7068208321961145, Testing Accuracy=0.7009726081778483\n",
      "lambda=0.02500,degree=2, Training Accuracy=0.6658065156439967, Testing Accuracy=0.6595871377530766\n",
      "lambda=0.02500,degree=3, Training Accuracy=0.6597027516562043, Testing Accuracy=0.6524414450178643\n",
      "lambda=0.02500,degree=4, Training Accuracy=0.5155943726273479, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02500,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02500,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02500,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=1, Training Accuracy=0.7064734635138823, Testing Accuracy=0.7010718539102818\n",
      "lambda=0.02550,degree=2, Training Accuracy=0.6657320794978041, Testing Accuracy=0.6596863834855101\n",
      "lambda=0.02550,degree=3, Training Accuracy=0.6598516239485894, Testing Accuracy=0.6524414450178643\n",
      "lambda=0.02550,degree=4, Training Accuracy=0.5155447485298861, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02550,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02550,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02550,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=1, Training Accuracy=0.7064734635138823, Testing Accuracy=0.7010718539102818\n",
      "lambda=0.02600,degree=2, Training Accuracy=0.6658561397414584, Testing Accuracy=0.6596863834855101\n",
      "lambda=0.02600,degree=3, Training Accuracy=0.6600253082897055, Testing Accuracy=0.6525406907502977\n",
      "lambda=0.02600,degree=4, Training Accuracy=0.5155199364811552, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02600,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02600,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02600,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=1, Training Accuracy=0.7061509068803811, Testing Accuracy=0.7010718539102818\n",
      "lambda=0.02650,degree=2, Training Accuracy=0.666129072277498, Testing Accuracy=0.6594878920206431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02650,degree=3, Training Accuracy=0.6601989926308215, Testing Accuracy=0.6529376736800317\n",
      "lambda=0.02650,degree=4, Training Accuracy=0.5155199364811552, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02650,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02650,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02650,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=1, Training Accuracy=0.7059772225392651, Testing Accuracy=0.7002778880508138\n",
      "lambda=0.02700,degree=2, Training Accuracy=0.665930575887651, Testing Accuracy=0.6597856292179436\n",
      "lambda=0.02700,degree=3, Training Accuracy=0.6602486167282833, Testing Accuracy=0.6533346566097658\n",
      "lambda=0.02700,degree=4, Training Accuracy=0.5155199364811552, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02700,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02700,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02700,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=1, Training Accuracy=0.7061260948316502, Testing Accuracy=0.7002778880508138\n",
      "lambda=0.02750,degree=2, Training Accuracy=0.6659057638389202, Testing Accuracy=0.6597856292179436\n",
      "lambda=0.02750,degree=3, Training Accuracy=0.6601989926308215, Testing Accuracy=0.6536323938070663\n",
      "lambda=0.02750,degree=4, Training Accuracy=0.5155199364811552, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02750,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02750,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02750,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=1, Training Accuracy=0.7061509068803811, Testing Accuracy=0.7004763795156809\n",
      "lambda=0.02800,degree=2, Training Accuracy=0.6658313276927276, Testing Accuracy=0.6596863834855101\n",
      "lambda=0.02800,degree=3, Training Accuracy=0.6605959854105153, Testing Accuracy=0.6536323938070663\n",
      "lambda=0.02800,degree=4, Training Accuracy=0.5154951244324244, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02800,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02800,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02800,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=1, Training Accuracy=0.7058531622956108, Testing Accuracy=0.7001786423183803\n",
      "lambda=0.02850,degree=2, Training Accuracy=0.6658065156439967, Testing Accuracy=0.6596863834855101\n",
      "lambda=0.02850,degree=3, Training Accuracy=0.6605711733617845, Testing Accuracy=0.6534339023421993\n",
      "lambda=0.02850,degree=4, Training Accuracy=0.5154951244324244, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02850,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02850,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02850,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=1, Training Accuracy=0.7059524104905343, Testing Accuracy=0.6999801508535133\n",
      "lambda=0.02900,degree=2, Training Accuracy=0.6657320794978041, Testing Accuracy=0.6594878920206431\n",
      "lambda=0.02900,degree=3, Training Accuracy=0.6607944818003623, Testing Accuracy=0.6537316395394998\n",
      "lambda=0.02900,degree=4, Training Accuracy=0.5154951244324244, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02900,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02900,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02900,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=1, Training Accuracy=0.7057539141006873, Testing Accuracy=0.7000793965859468\n",
      "lambda=0.02950,degree=2, Training Accuracy=0.6655583951566881, Testing Accuracy=0.6591901548233426\n",
      "lambda=0.02950,degree=3, Training Accuracy=0.6610674143364017, Testing Accuracy=0.6536323938070663\n",
      "lambda=0.02950,degree=4, Training Accuracy=0.5154951244324244, Testing Accuracy=0.5113140134974196\n",
      "lambda=0.02950,degree=5, Training Accuracy=0.5114755725380244, Testing Accuracy=0.509031361651449\n",
      "lambda=0.02950,degree=6, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=7, Training Accuracy=0.5113267002456393, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=8, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=9, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=10, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=11, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.02950,degree=12, Training Accuracy=0.5113018881969085, Testing Accuracy=0.508832870186582\n",
      "lambda=0.00000,degree=1, Training Accuracy=0.7266369635102363, Testing Accuracy=0.72546808030679\n",
      "lambda=0.00000,degree=2, Training Accuracy=0.7623371496249507, Testing Accuracy=0.7617866004962779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00000,degree=3, Training Accuracy=0.716203259827421, Testing Accuracy=0.7135122941574554\n",
      "lambda=0.00000,degree=4, Training Accuracy=0.7106198183971575, Testing Accuracy=0.7096774193548387\n",
      "lambda=0.00000,degree=5, Training Accuracy=0.705600360949749, Testing Accuracy=0.7051658019399955\n",
      "lambda=0.00000,degree=6, Training Accuracy=0.7014268794766229, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.00000,degree=7, Training Accuracy=0.6987761547572049, Testing Accuracy=0.7008797653958945\n",
      "lambda=0.00000,degree=8, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00000,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00000,degree=10, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00000,degree=11, Training Accuracy=0.6965766172240708, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00000,degree=12, Training Accuracy=0.6963510236309289, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00050,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.7144146176404241\n",
      "lambda=0.00050,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7096774193548387\n",
      "lambda=0.00050,degree=3, Training Accuracy=0.7036828154080425, Testing Accuracy=0.7047146401985112\n",
      "lambda=0.00050,degree=4, Training Accuracy=0.6978737803846371, Testing Accuracy=0.700203022783668\n",
      "lambda=0.00050,degree=5, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00050,degree=6, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00050,degree=7, Training Accuracy=0.696012633241216, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00050,degree=8, Training Accuracy=0.6958998364446449, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00050,degree=9, Training Accuracy=0.6958998364446449, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00050,degree=10, Training Accuracy=0.6958434380463595, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00050,degree=11, Training Accuracy=0.6956178444532175, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00050,degree=12, Training Accuracy=0.6955614460549321, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00100,degree=1, Training Accuracy=0.7178388133777001, Testing Accuracy=0.7137378750281976\n",
      "lambda=0.00100,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00100,degree=3, Training Accuracy=0.7037392138063279, Testing Accuracy=0.7024588314910896\n",
      "lambda=0.00100,degree=4, Training Accuracy=0.6982685691726355, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.00100,degree=5, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00100,degree=6, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00100,degree=7, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00100,degree=8, Training Accuracy=0.6962382268343579, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00100,degree=9, Training Accuracy=0.6959562348429305, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00100,degree=10, Training Accuracy=0.6958998364446449, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00100,degree=11, Training Accuracy=0.695787039648074, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00100,degree=12, Training Accuracy=0.695787039648074, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00150,degree=1, Training Accuracy=0.7174440245897017, Testing Accuracy=0.7137378750281976\n",
      "lambda=0.00150,degree=2, Training Accuracy=0.711014607185156, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00150,degree=3, Training Accuracy=0.7034008234166149, Testing Accuracy=0.7031355741033161\n",
      "lambda=0.00150,degree=4, Training Accuracy=0.6981557723760645, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.00150,degree=5, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00150,degree=6, Training Accuracy=0.6966894140206418, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00150,degree=7, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00150,degree=8, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00150,degree=9, Training Accuracy=0.6962382268343579, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00150,degree=10, Training Accuracy=0.696012633241216, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00150,degree=11, Training Accuracy=0.695787039648074, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00150,degree=12, Training Accuracy=0.695787039648074, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00200,degree=1, Training Accuracy=0.7177824149794145, Testing Accuracy=0.7137378750281976\n",
      "lambda=0.00200,degree=2, Training Accuracy=0.7109018103885849, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.00200,degree=3, Training Accuracy=0.7033444250183295, Testing Accuracy=0.7033611549740582\n",
      "lambda=0.00200,degree=4, Training Accuracy=0.697986577181208, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.00200,degree=5, Training Accuracy=0.6971406012069257, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00200,degree=6, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00200,degree=7, Training Accuracy=0.6966894140206418, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00200,degree=8, Training Accuracy=0.6964074220292144, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00200,degree=9, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00200,degree=10, Training Accuracy=0.6962382268343579, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00200,degree=11, Training Accuracy=0.6958998364446449, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00200,degree=12, Training Accuracy=0.695787039648074, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00250,degree=1, Training Accuracy=0.7176696181828436, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.00250,degree=2, Training Accuracy=0.7112965991765834, Testing Accuracy=0.7105797428378073\n",
      "lambda=0.00250,degree=3, Training Accuracy=0.702949636230331, Testing Accuracy=0.7026844123618318\n",
      "lambda=0.00250,degree=4, Training Accuracy=0.697986577181208, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00250,degree=5, Training Accuracy=0.6970278044103547, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00250,degree=6, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00250,degree=7, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00250,degree=8, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00250,degree=9, Training Accuracy=0.6962946252326434, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00250,degree=10, Training Accuracy=0.6962946252326434, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00250,degree=11, Training Accuracy=0.6960690316395014, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00250,degree=12, Training Accuracy=0.6958998364446449, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00300,degree=1, Training Accuracy=0.7175004229879871, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.00300,degree=2, Training Accuracy=0.7114093959731543, Testing Accuracy=0.7103541619670652\n",
      "lambda=0.00300,degree=3, Training Accuracy=0.702949636230331, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00300,degree=4, Training Accuracy=0.6982685691726355, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00300,degree=5, Training Accuracy=0.6971406012069257, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00300,degree=6, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00300,degree=7, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00300,degree=8, Training Accuracy=0.6966330156223564, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00300,degree=9, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00300,degree=10, Training Accuracy=0.6962946252326434, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00300,degree=11, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00300,degree=12, Training Accuracy=0.6959562348429305, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00350,degree=1, Training Accuracy=0.7175568213862726, Testing Accuracy=0.7135122941574554\n",
      "lambda=0.00350,degree=2, Training Accuracy=0.7114093959731543, Testing Accuracy=0.7094518384840965\n",
      "lambda=0.00350,degree=3, Training Accuracy=0.7030624330269021, Testing Accuracy=0.7029099932325739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00350,degree=4, Training Accuracy=0.698099373977779, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00350,degree=5, Training Accuracy=0.6971406012069257, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00350,degree=6, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00350,degree=7, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00350,degree=8, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00350,degree=9, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00350,degree=10, Training Accuracy=0.6962946252326434, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00350,degree=11, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00350,degree=12, Training Accuracy=0.6961254300377869, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00400,degree=1, Training Accuracy=0.7176132197845582, Testing Accuracy=0.7130611324159711\n",
      "lambda=0.00400,degree=2, Training Accuracy=0.7111274039817269, Testing Accuracy=0.7094518384840965\n",
      "lambda=0.00400,degree=3, Training Accuracy=0.7030060346286165, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00400,degree=4, Training Accuracy=0.6982685691726355, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00400,degree=5, Training Accuracy=0.6971406012069257, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00400,degree=6, Training Accuracy=0.6968586092154982, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00400,degree=7, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00400,degree=8, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00400,degree=9, Training Accuracy=0.6966330156223564, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00400,degree=10, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00400,degree=11, Training Accuracy=0.6961254300377869, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00400,degree=12, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00450,degree=1, Training Accuracy=0.7176696181828436, Testing Accuracy=0.7128355515452289\n",
      "lambda=0.00450,degree=2, Training Accuracy=0.711014607185156, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00450,degree=3, Training Accuracy=0.7031188314251875, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00450,degree=4, Training Accuracy=0.69821217077435, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.00450,degree=5, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00450,degree=6, Training Accuracy=0.6969714060120693, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00450,degree=7, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00450,degree=8, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00450,degree=9, Training Accuracy=0.6966894140206418, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00450,degree=10, Training Accuracy=0.6965766172240708, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00450,degree=11, Training Accuracy=0.6961254300377869, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00450,degree=12, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00500,degree=1, Training Accuracy=0.7177824149794145, Testing Accuracy=0.7123843898037446\n",
      "lambda=0.00500,degree=2, Training Accuracy=0.7111838023800124, Testing Accuracy=0.710128581096323\n",
      "lambda=0.00500,degree=3, Training Accuracy=0.7030624330269021, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00500,degree=4, Training Accuracy=0.69821217077435, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00500,degree=5, Training Accuracy=0.6972533980034967, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00500,degree=6, Training Accuracy=0.6969150076137838, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00500,degree=7, Training Accuracy=0.6969714060120693, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00500,degree=8, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00500,degree=9, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00500,degree=10, Training Accuracy=0.6966330156223564, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00500,degree=11, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00500,degree=12, Training Accuracy=0.6962382268343579, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00550,degree=1, Training Accuracy=0.7178952117759856, Testing Accuracy=0.7126099706744868\n",
      "lambda=0.00550,degree=2, Training Accuracy=0.7111274039817269, Testing Accuracy=0.7096774193548387\n",
      "lambda=0.00550,degree=3, Training Accuracy=0.7031188314251875, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00550,degree=4, Training Accuracy=0.69821217077435, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00550,degree=5, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00550,degree=6, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00550,degree=7, Training Accuracy=0.6969714060120693, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00550,degree=8, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00550,degree=9, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00550,degree=10, Training Accuracy=0.6966894140206418, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00550,degree=11, Training Accuracy=0.6962946252326434, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00550,degree=12, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00600,degree=1, Training Accuracy=0.7178952117759856, Testing Accuracy=0.7130611324159711\n",
      "lambda=0.00600,degree=2, Training Accuracy=0.7109018103885849, Testing Accuracy=0.7092262576133543\n",
      "lambda=0.00600,degree=3, Training Accuracy=0.7031188314251875, Testing Accuracy=0.7031355741033161\n",
      "lambda=0.00600,degree=4, Training Accuracy=0.6981557723760645, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00600,degree=5, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00600,degree=6, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00600,degree=7, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00600,degree=8, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00600,degree=9, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00600,degree=10, Training Accuracy=0.6966894140206418, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00600,degree=11, Training Accuracy=0.6962946252326434, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00600,degree=12, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00650,degree=1, Training Accuracy=0.717951610174271, Testing Accuracy=0.7130611324159711\n",
      "lambda=0.00650,degree=2, Training Accuracy=0.710789013592014, Testing Accuracy=0.7096774193548387\n",
      "lambda=0.00650,degree=3, Training Accuracy=0.7030624330269021, Testing Accuracy=0.7031355741033161\n",
      "lambda=0.00650,degree=4, Training Accuracy=0.69821217077435, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00650,degree=5, Training Accuracy=0.6976481867914951, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00650,degree=6, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00650,degree=7, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00650,degree=8, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00650,degree=9, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00650,degree=10, Training Accuracy=0.6967458124189273, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00650,degree=11, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00650,degree=12, Training Accuracy=0.6961818284360725, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00700,degree=1, Training Accuracy=0.7180644069708421, Testing Accuracy=0.7137378750281976\n",
      "lambda=0.00700,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7094518384840965\n",
      "lambda=0.00700,degree=3, Training Accuracy=0.7030060346286165, Testing Accuracy=0.7031355741033161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.00700,degree=4, Training Accuracy=0.6982685691726355, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00700,degree=5, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00700,degree=6, Training Accuracy=0.6973661948000677, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00700,degree=7, Training Accuracy=0.6970278044103547, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00700,degree=8, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00700,degree=9, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00700,degree=10, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00700,degree=11, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00700,degree=12, Training Accuracy=0.6962382268343579, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00750,degree=1, Training Accuracy=0.7180080085725565, Testing Accuracy=0.7141890367696819\n",
      "lambda=0.00750,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7096774193548387\n",
      "lambda=0.00750,degree=3, Training Accuracy=0.7032316282217586, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00750,degree=4, Training Accuracy=0.698324967570921, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00750,degree=5, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00750,degree=6, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00750,degree=7, Training Accuracy=0.6970278044103547, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00750,degree=8, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00750,degree=9, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00750,degree=10, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00750,degree=11, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00750,degree=12, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00800,degree=1, Training Accuracy=0.718177203767413, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.00800,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00800,degree=3, Training Accuracy=0.7030624330269021, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00800,degree=4, Training Accuracy=0.698324967570921, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00800,degree=5, Training Accuracy=0.6977045851897806, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00800,degree=6, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00800,degree=7, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00800,degree=8, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00800,degree=9, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00800,degree=10, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00800,degree=11, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00800,degree=12, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00850,degree=1, Training Accuracy=0.7182336021656985, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.00850,degree=2, Training Accuracy=0.710789013592014, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00850,degree=3, Training Accuracy=0.7030060346286165, Testing Accuracy=0.7031355741033161\n",
      "lambda=0.00850,degree=4, Training Accuracy=0.6983813659692065, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00850,degree=5, Training Accuracy=0.6977609835880662, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.00850,degree=6, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00850,degree=7, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00850,degree=8, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00850,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00850,degree=10, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00850,degree=11, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00850,degree=12, Training Accuracy=0.6963510236309289, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00900,degree=1, Training Accuracy=0.7182336021656985, Testing Accuracy=0.7137378750281976\n",
      "lambda=0.00900,degree=2, Training Accuracy=0.7108454119902995, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00900,degree=3, Training Accuracy=0.703175229823473, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00900,degree=4, Training Accuracy=0.6984377643674919, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00900,degree=5, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.00900,degree=6, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00900,degree=7, Training Accuracy=0.6973661948000677, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00900,degree=8, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00900,degree=9, Training Accuracy=0.6969714060120693, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00900,degree=10, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00900,degree=11, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00900,degree=12, Training Accuracy=0.6964638204274999, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.00950,degree=1, Training Accuracy=0.717951610174271, Testing Accuracy=0.7137378750281976\n",
      "lambda=0.00950,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7099030002255808\n",
      "lambda=0.00950,degree=3, Training Accuracy=0.7030060346286165, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.00950,degree=4, Training Accuracy=0.6984377643674919, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.00950,degree=5, Training Accuracy=0.6979301787829225, Testing Accuracy=0.700203022783668\n",
      "lambda=0.00950,degree=6, Training Accuracy=0.6977045851897806, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.00950,degree=7, Training Accuracy=0.6973661948000677, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.00950,degree=8, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00950,degree=9, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.00950,degree=10, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.00950,degree=11, Training Accuracy=0.6965766172240708, Testing Accuracy=0.698849537559215\n",
      "lambda=0.00950,degree=12, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.01000,degree=1, Training Accuracy=0.7178388133777001, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.01000,degree=2, Training Accuracy=0.7105634199988721, Testing Accuracy=0.7103541619670652\n",
      "lambda=0.01000,degree=3, Training Accuracy=0.702949636230331, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.01000,degree=4, Training Accuracy=0.6984941627657775, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01000,degree=5, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01000,degree=6, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01000,degree=7, Training Accuracy=0.6974225931983532, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01000,degree=8, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01000,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01000,degree=10, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01000,degree=11, Training Accuracy=0.6965766172240708, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01000,degree=12, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.01050,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.01050,degree=2, Training Accuracy=0.7106198183971575, Testing Accuracy=0.7103541619670652\n",
      "lambda=0.01050,degree=3, Training Accuracy=0.702949636230331, Testing Accuracy=0.7029099932325739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01050,degree=4, Training Accuracy=0.6985505611640629, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01050,degree=5, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01050,degree=6, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01050,degree=7, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01050,degree=8, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01050,degree=9, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01050,degree=10, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01050,degree=11, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01050,degree=12, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01100,degree=1, Training Accuracy=0.7175004229879871, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.01100,degree=2, Training Accuracy=0.710789013592014, Testing Accuracy=0.7096774193548387\n",
      "lambda=0.01100,degree=3, Training Accuracy=0.7028368394337601, Testing Accuracy=0.7029099932325739\n",
      "lambda=0.01100,degree=4, Training Accuracy=0.6985505611640629, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01100,degree=5, Training Accuracy=0.6980429755794936, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01100,degree=6, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01100,degree=7, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01100,degree=8, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01100,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01100,degree=10, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01100,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01100,degree=12, Training Accuracy=0.6965766172240708, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01150,degree=1, Training Accuracy=0.7176696181828436, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.01150,degree=2, Training Accuracy=0.710676216795443, Testing Accuracy=0.7094518384840965\n",
      "lambda=0.01150,degree=3, Training Accuracy=0.7027240426371891, Testing Accuracy=0.7024588314910896\n",
      "lambda=0.01150,degree=4, Training Accuracy=0.6988325531554904, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01150,degree=5, Training Accuracy=0.6980429755794936, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01150,degree=6, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01150,degree=7, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01150,degree=8, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01150,degree=9, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01150,degree=10, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01150,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01150,degree=12, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01200,degree=1, Training Accuracy=0.7176132197845582, Testing Accuracy=0.7144146176404241\n",
      "lambda=0.01200,degree=2, Training Accuracy=0.7108454119902995, Testing Accuracy=0.710128581096323\n",
      "lambda=0.01200,degree=3, Training Accuracy=0.7025548474423327, Testing Accuracy=0.7024588314910896\n",
      "lambda=0.01200,degree=4, Training Accuracy=0.6988889515537758, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01200,degree=5, Training Accuracy=0.6981557723760645, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01200,degree=6, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01200,degree=7, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01200,degree=8, Training Accuracy=0.6972533980034967, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01200,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01200,degree=10, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01200,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01200,degree=12, Training Accuracy=0.6965202188257853, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01250,degree=1, Training Accuracy=0.7176132197845582, Testing Accuracy=0.7139634558989397\n",
      "lambda=0.01250,degree=2, Training Accuracy=0.710789013592014, Testing Accuracy=0.710128581096323\n",
      "lambda=0.01250,degree=3, Training Accuracy=0.7026676442389036, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01250,degree=4, Training Accuracy=0.6989453499520614, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01250,degree=5, Training Accuracy=0.6981557723760645, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01250,degree=6, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01250,degree=7, Training Accuracy=0.6976481867914951, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01250,degree=8, Training Accuracy=0.6973097964017821, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01250,degree=9, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01250,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01250,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01250,degree=12, Training Accuracy=0.6965766172240708, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01300,degree=1, Training Accuracy=0.7173876261914162, Testing Accuracy=0.7141890367696819\n",
      "lambda=0.01300,degree=2, Training Accuracy=0.7105070216005865, Testing Accuracy=0.7105797428378073\n",
      "lambda=0.01300,degree=3, Training Accuracy=0.7027804410354745, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01300,degree=4, Training Accuracy=0.6991145451469178, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01300,degree=5, Training Accuracy=0.6981557723760645, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01300,degree=6, Training Accuracy=0.697986577181208, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01300,degree=7, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01300,degree=8, Training Accuracy=0.6973097964017821, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01300,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01300,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01300,degree=11, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01300,degree=12, Training Accuracy=0.6965766172240708, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01350,degree=1, Training Accuracy=0.7175004229879871, Testing Accuracy=0.7146401985111662\n",
      "lambda=0.01350,degree=2, Training Accuracy=0.7103942248040156, Testing Accuracy=0.7108053237085495\n",
      "lambda=0.01350,degree=3, Training Accuracy=0.7026676442389036, Testing Accuracy=0.7024588314910896\n",
      "lambda=0.01350,degree=4, Training Accuracy=0.6992273419434888, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01350,degree=5, Training Accuracy=0.698324967570921, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01350,degree=6, Training Accuracy=0.697986577181208, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01350,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01350,degree=8, Training Accuracy=0.6973661948000677, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01350,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01350,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01350,degree=11, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01350,degree=12, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01400,degree=1, Training Accuracy=0.7175568213862726, Testing Accuracy=0.7146401985111662\n",
      "lambda=0.01400,degree=2, Training Accuracy=0.7102250296091591, Testing Accuracy=0.7108053237085495\n",
      "lambda=0.01400,degree=3, Training Accuracy=0.7025548474423327, Testing Accuracy=0.7024588314910896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01400,degree=4, Training Accuracy=0.6993401387400597, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01400,degree=5, Training Accuracy=0.6985505611640629, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01400,degree=6, Training Accuracy=0.698099373977779, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01400,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01400,degree=8, Training Accuracy=0.6974225931983532, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01400,degree=9, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01400,degree=10, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01400,degree=11, Training Accuracy=0.6966330156223564, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01400,degree=12, Training Accuracy=0.6966330156223564, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01450,degree=1, Training Accuracy=0.7178388133777001, Testing Accuracy=0.7148657793819084\n",
      "lambda=0.01450,degree=2, Training Accuracy=0.7102250296091591, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.01450,degree=3, Training Accuracy=0.7024420506457617, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01450,degree=4, Training Accuracy=0.6993965371383453, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01450,degree=5, Training Accuracy=0.698663357960634, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01450,degree=6, Training Accuracy=0.69821217077435, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01450,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01450,degree=8, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01450,degree=9, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01450,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01450,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01450,degree=12, Training Accuracy=0.6966330156223564, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01500,degree=1, Training Accuracy=0.7178952117759856, Testing Accuracy=0.7148657793819084\n",
      "lambda=0.01500,degree=2, Training Accuracy=0.7102814280074445, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.01500,degree=3, Training Accuracy=0.7024984490440471, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01500,degree=4, Training Accuracy=0.6993965371383453, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01500,degree=5, Training Accuracy=0.698663357960634, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01500,degree=6, Training Accuracy=0.69821217077435, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01500,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01500,degree=8, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01500,degree=9, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01500,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01500,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01500,degree=12, Training Accuracy=0.6966330156223564, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01550,degree=1, Training Accuracy=0.7180080085725565, Testing Accuracy=0.7148657793819084\n",
      "lambda=0.01550,degree=2, Training Accuracy=0.7103378264057301, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.01550,degree=3, Training Accuracy=0.7025548474423327, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01550,degree=4, Training Accuracy=0.6993965371383453, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01550,degree=5, Training Accuracy=0.6987197563589194, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01550,degree=6, Training Accuracy=0.698324967570921, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01550,degree=7, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01550,degree=8, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01550,degree=9, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01550,degree=10, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01550,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01550,degree=12, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01600,degree=1, Training Accuracy=0.7181208053691275, Testing Accuracy=0.7148657793819084\n",
      "lambda=0.01600,degree=2, Training Accuracy=0.7103378264057301, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.01600,degree=3, Training Accuracy=0.7024984490440471, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01600,degree=4, Training Accuracy=0.6993965371383453, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01600,degree=5, Training Accuracy=0.6988889515537758, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01600,degree=6, Training Accuracy=0.6984941627657775, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01600,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01600,degree=8, Training Accuracy=0.6976481867914951, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01600,degree=9, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01600,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01600,degree=11, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01600,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01650,degree=1, Training Accuracy=0.7182336021656985, Testing Accuracy=0.7146401985111662\n",
      "lambda=0.01650,degree=2, Training Accuracy=0.710450623202301, Testing Accuracy=0.7112564854500338\n",
      "lambda=0.01650,degree=3, Training Accuracy=0.7024984490440471, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01650,degree=4, Training Accuracy=0.6994529355366308, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01650,degree=5, Training Accuracy=0.6990017483503469, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01650,degree=6, Training Accuracy=0.698663357960634, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01650,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01650,degree=8, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01650,degree=9, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01650,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01650,degree=11, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01650,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01700,degree=1, Training Accuracy=0.718290000563984, Testing Accuracy=0.7146401985111662\n",
      "lambda=0.01700,degree=2, Training Accuracy=0.7103942248040156, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.01700,degree=3, Training Accuracy=0.7026676442389036, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.01700,degree=4, Training Accuracy=0.6995657323332017, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01700,degree=5, Training Accuracy=0.6991145451469178, Testing Accuracy=0.7006541845251523\n",
      "lambda=0.01700,degree=6, Training Accuracy=0.6987197563589194, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01700,degree=7, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01700,degree=8, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01700,degree=9, Training Accuracy=0.6971406012069257, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01700,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01700,degree=11, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01700,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01750,degree=1, Training Accuracy=0.718290000563984, Testing Accuracy=0.7146401985111662\n",
      "lambda=0.01750,degree=2, Training Accuracy=0.7101686312108736, Testing Accuracy=0.7110309045792916\n",
      "lambda=0.01750,degree=3, Training Accuracy=0.7025548474423327, Testing Accuracy=0.7020076697496053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.01750,degree=4, Training Accuracy=0.6994529355366308, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01750,degree=5, Training Accuracy=0.6991709435452034, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.01750,degree=6, Training Accuracy=0.6987761547572049, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01750,degree=7, Training Accuracy=0.698099373977779, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01750,degree=8, Training Accuracy=0.6977045851897806, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01750,degree=9, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01750,degree=10, Training Accuracy=0.6969714060120693, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01750,degree=11, Training Accuracy=0.6967458124189273, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01750,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01800,degree=1, Training Accuracy=0.7181208053691275, Testing Accuracy=0.7144146176404241\n",
      "lambda=0.01800,degree=2, Training Accuracy=0.7102250296091591, Testing Accuracy=0.711482066320776\n",
      "lambda=0.01800,degree=3, Training Accuracy=0.7024984490440471, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.01800,degree=4, Training Accuracy=0.6995093339349162, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01800,degree=5, Training Accuracy=0.6992273419434888, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.01800,degree=6, Training Accuracy=0.6988325531554904, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01800,degree=7, Training Accuracy=0.698099373977779, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01800,degree=8, Training Accuracy=0.6977045851897806, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01800,degree=9, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01800,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01800,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01800,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01850,degree=1, Training Accuracy=0.718177203767413, Testing Accuracy=0.7146401985111662\n",
      "lambda=0.01850,degree=2, Training Accuracy=0.7102250296091591, Testing Accuracy=0.7117076471915181\n",
      "lambda=0.01850,degree=3, Training Accuracy=0.7024420506457617, Testing Accuracy=0.7015565080081209\n",
      "lambda=0.01850,degree=4, Training Accuracy=0.6996221307314873, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01850,degree=5, Training Accuracy=0.6992273419434888, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.01850,degree=6, Training Accuracy=0.6988889515537758, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01850,degree=7, Training Accuracy=0.6981557723760645, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01850,degree=8, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.01850,degree=9, Training Accuracy=0.6971969996052112, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01850,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01850,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01850,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.01900,degree=1, Training Accuracy=0.7181208053691275, Testing Accuracy=0.7148657793819084\n",
      "lambda=0.01900,degree=2, Training Accuracy=0.7099430376177317, Testing Accuracy=0.7117076471915181\n",
      "lambda=0.01900,degree=3, Training Accuracy=0.7023856522474762, Testing Accuracy=0.7015565080081209\n",
      "lambda=0.01900,degree=4, Training Accuracy=0.6997349275280582, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01900,degree=5, Training Accuracy=0.6994529355366308, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.01900,degree=6, Training Accuracy=0.6989453499520614, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01900,degree=7, Training Accuracy=0.6982685691726355, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01900,degree=8, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01900,degree=9, Training Accuracy=0.6973097964017821, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01900,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01900,degree=11, Training Accuracy=0.6969150076137838, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01900,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.01950,degree=1, Training Accuracy=0.7181208053691275, Testing Accuracy=0.7153169411233927\n",
      "lambda=0.01950,degree=2, Training Accuracy=0.7096610456263042, Testing Accuracy=0.7117076471915181\n",
      "lambda=0.01950,degree=3, Training Accuracy=0.7023292538491906, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.01950,degree=4, Training Accuracy=0.6996785291297727, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01950,degree=5, Training Accuracy=0.6995093339349162, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.01950,degree=6, Training Accuracy=0.6991709435452034, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.01950,degree=7, Training Accuracy=0.69821217077435, Testing Accuracy=0.700203022783668\n",
      "lambda=0.01950,degree=8, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.01950,degree=9, Training Accuracy=0.6973097964017821, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01950,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.01950,degree=11, Training Accuracy=0.6969150076137838, Testing Accuracy=0.698849537559215\n",
      "lambda=0.01950,degree=12, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02000,degree=1, Training Accuracy=0.7182336021656985, Testing Accuracy=0.7153169411233927\n",
      "lambda=0.02000,degree=2, Training Accuracy=0.7097174440245897, Testing Accuracy=0.7117076471915181\n",
      "lambda=0.02000,degree=3, Training Accuracy=0.7022728554509052, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.02000,degree=4, Training Accuracy=0.6997913259263437, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02000,degree=5, Training Accuracy=0.6995093339349162, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02000,degree=6, Training Accuracy=0.6991709435452034, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02000,degree=7, Training Accuracy=0.698324967570921, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02000,degree=8, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02000,degree=9, Training Accuracy=0.6972533980034967, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02000,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.02000,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.02000,degree=12, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02050,degree=1, Training Accuracy=0.717951610174271, Testing Accuracy=0.7150913602526505\n",
      "lambda=0.02050,degree=2, Training Accuracy=0.7095482488297332, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02050,degree=3, Training Accuracy=0.7022164570526197, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.02050,degree=4, Training Accuracy=0.6998477243246292, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02050,degree=5, Training Accuracy=0.6996221307314873, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02050,degree=6, Training Accuracy=0.6992837403417743, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02050,degree=7, Training Accuracy=0.6984377643674919, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02050,degree=8, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02050,degree=9, Training Accuracy=0.6973097964017821, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02050,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.02050,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02050,degree=12, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02100,degree=1, Training Accuracy=0.7177824149794145, Testing Accuracy=0.7153169411233927\n",
      "lambda=0.02100,degree=2, Training Accuracy=0.7096610456263042, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02100,degree=3, Training Accuracy=0.7021036602560488, Testing Accuracy=0.7017820888788631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02100,degree=4, Training Accuracy=0.6998477243246292, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02100,degree=5, Training Accuracy=0.6996785291297727, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02100,degree=6, Training Accuracy=0.6993401387400597, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02100,degree=7, Training Accuracy=0.6984377643674919, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02100,degree=8, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02100,degree=9, Training Accuracy=0.6973097964017821, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02100,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.02100,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02100,degree=12, Training Accuracy=0.6966894140206418, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02150,degree=1, Training Accuracy=0.7177824149794145, Testing Accuracy=0.7150913602526505\n",
      "lambda=0.02150,degree=2, Training Accuracy=0.7098866392194462, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02150,degree=3, Training Accuracy=0.7022164570526197, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.02150,degree=4, Training Accuracy=0.6999605211212001, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02150,degree=5, Training Accuracy=0.6996785291297727, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02150,degree=6, Training Accuracy=0.6993965371383453, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02150,degree=7, Training Accuracy=0.6986069595623484, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02150,degree=8, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02150,degree=9, Training Accuracy=0.6973661948000677, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02150,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.02150,degree=11, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02150,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02200,degree=1, Training Accuracy=0.7177824149794145, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02200,degree=2, Training Accuracy=0.7099430376177317, Testing Accuracy=0.7117076471915181\n",
      "lambda=0.02200,degree=3, Training Accuracy=0.7021600586543342, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.02200,degree=4, Training Accuracy=0.6999605211212001, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02200,degree=5, Training Accuracy=0.6997349275280582, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02200,degree=6, Training Accuracy=0.6995093339349162, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02200,degree=7, Training Accuracy=0.6987761547572049, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02200,degree=8, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02200,degree=9, Training Accuracy=0.6973661948000677, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02200,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6986239566884728\n",
      "lambda=0.02200,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02200,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02250,degree=1, Training Accuracy=0.7178388133777001, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02250,degree=2, Training Accuracy=0.7098866392194462, Testing Accuracy=0.7117076471915181\n",
      "lambda=0.02250,degree=3, Training Accuracy=0.7021600586543342, Testing Accuracy=0.7017820888788631\n",
      "lambda=0.02250,degree=4, Training Accuracy=0.6999605211212001, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02250,degree=5, Training Accuracy=0.6998477243246292, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02250,degree=6, Training Accuracy=0.6995657323332017, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02250,degree=7, Training Accuracy=0.6988325531554904, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02250,degree=8, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02250,degree=9, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02250,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02250,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02250,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02300,degree=1, Training Accuracy=0.717951610174271, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02300,degree=2, Training Accuracy=0.7098302408211606, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02300,degree=3, Training Accuracy=0.7021600586543342, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02300,degree=4, Training Accuracy=0.7000169195194856, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02300,degree=5, Training Accuracy=0.6999605211212001, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02300,degree=6, Training Accuracy=0.6996785291297727, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02300,degree=7, Training Accuracy=0.6988889515537758, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02300,degree=8, Training Accuracy=0.6979301787829225, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02300,degree=9, Training Accuracy=0.6974789915966386, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02300,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02300,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02300,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02350,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02350,degree=2, Training Accuracy=0.7098302408211606, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02350,degree=3, Training Accuracy=0.7021600586543342, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02350,degree=4, Training Accuracy=0.7000169195194856, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02350,degree=5, Training Accuracy=0.7000169195194856, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02350,degree=6, Training Accuracy=0.6996785291297727, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02350,degree=7, Training Accuracy=0.6988889515537758, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02350,degree=8, Training Accuracy=0.6978737803846371, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02350,degree=9, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02350,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02350,degree=11, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02350,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02400,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02400,degree=2, Training Accuracy=0.7098866392194462, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02400,degree=3, Training Accuracy=0.7022164570526197, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02400,degree=4, Training Accuracy=0.7001861147143421, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02400,degree=5, Training Accuracy=0.7000733179177712, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02400,degree=6, Training Accuracy=0.6996785291297727, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02400,degree=7, Training Accuracy=0.6989453499520614, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02400,degree=8, Training Accuracy=0.697986577181208, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02400,degree=9, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02400,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02400,degree=11, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02400,degree=12, Training Accuracy=0.6967458124189273, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02450,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.7153169411233927\n",
      "lambda=0.02450,degree=2, Training Accuracy=0.7098302408211606, Testing Accuracy=0.7121588089330024\n",
      "lambda=0.02450,degree=3, Training Accuracy=0.7022164570526197, Testing Accuracy=0.7020076697496053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02450,degree=4, Training Accuracy=0.7002989115109131, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02450,degree=5, Training Accuracy=0.7001861147143421, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02450,degree=6, Training Accuracy=0.6998477243246292, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02450,degree=7, Training Accuracy=0.6990017483503469, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02450,degree=8, Training Accuracy=0.697986577181208, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02450,degree=9, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02450,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02450,degree=11, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02450,degree=12, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02500,degree=1, Training Accuracy=0.7175568213862726, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02500,degree=2, Training Accuracy=0.7098302408211606, Testing Accuracy=0.7121588089330024\n",
      "lambda=0.02500,degree=3, Training Accuracy=0.7022164570526197, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02500,degree=4, Training Accuracy=0.7004117083074841, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02500,degree=5, Training Accuracy=0.7001861147143421, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02500,degree=6, Training Accuracy=0.6998477243246292, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02500,degree=7, Training Accuracy=0.6990017483503469, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02500,degree=8, Training Accuracy=0.697986577181208, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02500,degree=9, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02500,degree=10, Training Accuracy=0.6970278044103547, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02500,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02500,degree=12, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02550,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02550,degree=2, Training Accuracy=0.7099994360160171, Testing Accuracy=0.7121588089330024\n",
      "lambda=0.02550,degree=3, Training Accuracy=0.7023292538491906, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02550,degree=4, Training Accuracy=0.7004117083074841, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02550,degree=5, Training Accuracy=0.7002989115109131, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02550,degree=6, Training Accuracy=0.6999041227229147, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02550,degree=7, Training Accuracy=0.6990017483503469, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02550,degree=8, Training Accuracy=0.6980429755794936, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02550,degree=9, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6993006993006993\n",
      "lambda=0.02550,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02550,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02550,degree=12, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02600,degree=1, Training Accuracy=0.7177824149794145, Testing Accuracy=0.7159936837356192\n",
      "lambda=0.02600,degree=2, Training Accuracy=0.7098866392194462, Testing Accuracy=0.7121588089330024\n",
      "lambda=0.02600,degree=3, Training Accuracy=0.7024420506457617, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02600,degree=4, Training Accuracy=0.7004117083074841, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02600,degree=5, Training Accuracy=0.7005245051040551, Testing Accuracy=0.7011053462666366\n",
      "lambda=0.02600,degree=6, Training Accuracy=0.6999605211212001, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02600,degree=7, Training Accuracy=0.6990017483503469, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02600,degree=8, Training Accuracy=0.698099373977779, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02600,degree=9, Training Accuracy=0.6975353899949241, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02600,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02600,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02600,degree=12, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02650,degree=1, Training Accuracy=0.7177260165811291, Testing Accuracy=0.715768102864877\n",
      "lambda=0.02650,degree=2, Training Accuracy=0.7098866392194462, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02650,degree=3, Training Accuracy=0.7023856522474762, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02650,degree=4, Training Accuracy=0.7005809035023405, Testing Accuracy=0.7004286036544101\n",
      "lambda=0.02650,degree=5, Training Accuracy=0.7005809035023405, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02650,degree=6, Training Accuracy=0.7000733179177712, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02650,degree=7, Training Accuracy=0.6991145451469178, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02650,degree=8, Training Accuracy=0.6981557723760645, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02650,degree=9, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02650,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02650,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02650,degree=12, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02700,degree=1, Training Accuracy=0.7178952117759856, Testing Accuracy=0.7155425219941349\n",
      "lambda=0.02700,degree=2, Training Accuracy=0.7099994360160171, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02700,degree=3, Training Accuracy=0.7023856522474762, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02700,degree=4, Training Accuracy=0.700637301900626, Testing Accuracy=0.7008797653958945\n",
      "lambda=0.02700,degree=5, Training Accuracy=0.700637301900626, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02700,degree=6, Training Accuracy=0.7002425131126276, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02700,degree=7, Training Accuracy=0.6992837403417743, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02700,degree=8, Training Accuracy=0.6981557723760645, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02700,degree=9, Training Accuracy=0.6975917883932097, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02700,degree=10, Training Accuracy=0.6970842028086403, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02700,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02700,degree=12, Training Accuracy=0.6968022108172128, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02750,degree=1, Training Accuracy=0.717951610174271, Testing Accuracy=0.7155425219941349\n",
      "lambda=0.02750,degree=2, Training Accuracy=0.7100558344143026, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02750,degree=3, Training Accuracy=0.7023292538491906, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02750,degree=4, Training Accuracy=0.700637301900626, Testing Accuracy=0.7011053462666366\n",
      "lambda=0.02750,degree=5, Training Accuracy=0.700637301900626, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02750,degree=6, Training Accuracy=0.7001861147143421, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02750,degree=7, Training Accuracy=0.6992837403417743, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02750,degree=8, Training Accuracy=0.6981557723760645, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02750,degree=9, Training Accuracy=0.6977045851897806, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02750,degree=10, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02750,degree=11, Training Accuracy=0.6968022108172128, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02750,degree=12, Training Accuracy=0.6968586092154982, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02800,degree=1, Training Accuracy=0.7180644069708421, Testing Accuracy=0.7159936837356192\n",
      "lambda=0.02800,degree=2, Training Accuracy=0.7101122328125882, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02800,degree=3, Training Accuracy=0.7023292538491906, Testing Accuracy=0.7020076697496053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.02800,degree=4, Training Accuracy=0.7008064970954825, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02800,degree=5, Training Accuracy=0.700750098697197, Testing Accuracy=0.7015565080081209\n",
      "lambda=0.02800,degree=6, Training Accuracy=0.7001861147143421, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02800,degree=7, Training Accuracy=0.6993401387400597, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02800,degree=8, Training Accuracy=0.6982685691726355, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02800,degree=9, Training Accuracy=0.6977045851897806, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02800,degree=10, Training Accuracy=0.6971969996052112, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02800,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02800,degree=12, Training Accuracy=0.6969150076137838, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02850,degree=1, Training Accuracy=0.717951610174271, Testing Accuracy=0.7162192646063614\n",
      "lambda=0.02850,degree=2, Training Accuracy=0.7102250296091591, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02850,degree=3, Training Accuracy=0.7023292538491906, Testing Accuracy=0.7020076697496053\n",
      "lambda=0.02850,degree=4, Training Accuracy=0.700975692290339, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02850,degree=5, Training Accuracy=0.700750098697197, Testing Accuracy=0.7015565080081209\n",
      "lambda=0.02850,degree=6, Training Accuracy=0.7001861147143421, Testing Accuracy=0.6997518610421837\n",
      "lambda=0.02850,degree=7, Training Accuracy=0.6994529355366308, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02850,degree=8, Training Accuracy=0.6982685691726355, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02850,degree=9, Training Accuracy=0.6977609835880662, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02850,degree=10, Training Accuracy=0.6971406012069257, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02850,degree=11, Training Accuracy=0.6968586092154982, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02850,degree=12, Training Accuracy=0.6969150076137838, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02900,degree=1, Training Accuracy=0.7180644069708421, Testing Accuracy=0.7164448454771035\n",
      "lambda=0.02900,degree=2, Training Accuracy=0.7102814280074445, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02900,degree=3, Training Accuracy=0.7023856522474762, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.02900,degree=4, Training Accuracy=0.7010320906886245, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02900,degree=5, Training Accuracy=0.700862895493768, Testing Accuracy=0.7015565080081209\n",
      "lambda=0.02900,degree=6, Training Accuracy=0.7001861147143421, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02900,degree=7, Training Accuracy=0.6993965371383453, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02900,degree=8, Training Accuracy=0.6983813659692065, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02900,degree=9, Training Accuracy=0.6977609835880662, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02900,degree=10, Training Accuracy=0.6971406012069257, Testing Accuracy=0.6990751184299572\n",
      "lambda=0.02900,degree=11, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02900,degree=12, Training Accuracy=0.6969714060120693, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02950,degree=1, Training Accuracy=0.7181208053691275, Testing Accuracy=0.7166704263478457\n",
      "lambda=0.02950,degree=2, Training Accuracy=0.7102814280074445, Testing Accuracy=0.7119332280622603\n",
      "lambda=0.02950,degree=3, Training Accuracy=0.7023856522474762, Testing Accuracy=0.7022332506203474\n",
      "lambda=0.02950,degree=4, Training Accuracy=0.7010320906886245, Testing Accuracy=0.7013309271373788\n",
      "lambda=0.02950,degree=5, Training Accuracy=0.7011448874851954, Testing Accuracy=0.7015565080081209\n",
      "lambda=0.02950,degree=6, Training Accuracy=0.7002425131126276, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02950,degree=7, Training Accuracy=0.6993965371383453, Testing Accuracy=0.700203022783668\n",
      "lambda=0.02950,degree=8, Training Accuracy=0.6983813659692065, Testing Accuracy=0.6999774419129258\n",
      "lambda=0.02950,degree=9, Training Accuracy=0.6978173819863516, Testing Accuracy=0.6995262801714415\n",
      "lambda=0.02950,degree=10, Training Accuracy=0.6971969996052112, Testing Accuracy=0.698849537559215\n",
      "lambda=0.02950,degree=11, Training Accuracy=0.6969150076137838, Testing Accuracy=0.6983983758177307\n",
      "lambda=0.02950,degree=12, Training Accuracy=0.6969714060120693, Testing Accuracy=0.698849537559215\n",
      "Accuracy per jet nbr: \n",
      "\n",
      "[0.8329079717760096, 0.7582049132761622, 0.7531758634378721, 0.7617866004962779]\n"
     ]
    }
   ],
   "source": [
    "#separate data with respect to column 24 and remove None\n",
    "split_x_test, _, split_ids_test =  separate(y_donotUse, tX_test, ids_test)\n",
    "\n",
    "\n",
    "split_x_cleaned_test = removeNone(split_x_test, dataStatistics(split_x_test))\n",
    "\n",
    "#median instead of None\n",
    "split_x_with_median = putMedianInsteadOfNone(split_x_cleaned_test)\n",
    "\n",
    "#line dropped when None\n",
    "#split_x_drop_lines, split_y_dropped_split_indexes_dropped = dropLineIfNone(split_x_cleaned_test, _, split_ids_test)\n",
    "\n",
    "#degrees for polynomial feature expension\n",
    "degrees = [1,2,3,4,5,6,7,8]\n",
    "\n",
    "y_res = []\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in range(4):\n",
    "    #training\n",
    "    w_star, d, accuracy = crossValidation(cleaned_with_median[i], split_y[i], 0.8, degrees ,6)\n",
    "    \n",
    "    #prediction\n",
    "    y_res.append(predict_labels(w_star, normalize(build_poly(split_x_with_median[i], d))))\n",
    "\n",
    "\n",
    "    acc.append(accuracy)\n",
    "\n",
    "print(\"Accuracy per jet nbr: \\n\")\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/submission.csv'\n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "y_pred = put_together(y_res, split_ids_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
